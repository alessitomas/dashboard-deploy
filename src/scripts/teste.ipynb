{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"../notebooks/data/Ana Health_Tabela Modelo Previsão Churn - Tabela.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_preprocessing import preprocessing,mergeHeader_Columns\n",
    "from data_feature_engineering import feature_engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_merge = mergeHeader_Columns(df).iloc[50]\n",
    "\n",
    "data_dataframe = data_merge.to_json( force_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"PESSOA_PIPEDRIVE_id_person\":\"1080\",\"PESSOA_PIPEDRIVE_birthdate\":\"1991-11-20\",\"PESSOA_PIPEDRIVE_id_gender\":\"63\",\"PESSOA_PIPEDRIVE_id_marrital_status\":\"80\",\"PESSOA_PIPEDRIVE_state\":\"Pernambuco\",\"PESSOA_PIPEDRIVE_city\":\"Recife\",\"PESSOA_PIPEDRIVE_postal_code\":\"50070-045\",\"PESSOA_PIPEDRIVE_id_health_plan\":null,\"PESSOA_PIPEDRIVE_id_person_recommendation\":null,\"PESSOA_PIPEDRIVE_contract_start_date\":\"2021-07-19\",\"PESSOA_PIPEDRIVE_contract_end_date\":\"2023-08-18\",\"PESSOA_PIPEDRIVE_id_continuity_pf\":null,\"PESSOA_PIPEDRIVE_Canal de Preferência\":null,\"PESSOA_PIPEDRIVE_notes_count\":\"5\",\"PESSOA_PIPEDRIVE_done_activities_count\":\"50\",\"PESSOA_PIPEDRIVE_Recebe Comunicados?\":null,\"PESSOA_PIPEDRIVE_Interesses\":null,\"PESSOA_PIPEDRIVE_Pontos de Atenção\":null,\"FUNIL_ASSINATURA_PIPEDRIVE_id_stage\":\"64\",\"FUNIL_ASSINATURA_PIPEDRIVE_id_org\":null,\"FUNIL_ASSINATURA_PIPEDRIVE_status\":\"lost\",\"FUNIL_ASSINATURA_PIPEDRIVE_start_of_service\":\"2021-07-19\",\"FUNIL_ASSINATURA_PIPEDRIVE_lost_time\":\"2023-07-26 12:59:22\",\"FUNIL_ASSINATURA_PIPEDRIVE_lost_reason\":\"[Assinatura] Precisou cortar custos\",\"FUNIL_ONBOARDING_PIPEDRIVE_add_time\":\"2021-09-16 18:08:58\",\"FUNIL_ONBOARDING_PIPEDRIVE_status\":\"won\",\"FUNIL_ONBOARDING_PIPEDRIVE_id_label\":null,\"FUNIL_ONBOARDING_PIPEDRIVE_stay_in_pipeline_stages_welcome\":\"0\",\"FUNIL_ONBOARDING_PIPEDRIVE_stay_in_pipeline_stages_first_meeting\":\"0\",\"FUNIL_ONBOARDING_PIPEDRIVE_stay_in_pipeline_stages_whoqol\":\"314500\",\"FUNIL_ONBOARDING_PIPEDRIVE_won_time\":\"2022-04-18 15:07:13\",\"FUNIL_ONBOARDING_PIPEDRIVE_lost_time\":null,\"FUNIL_ONBOARDING_PIPEDRIVE_lost_reason\":null,\"FUNIL_ONBOARDING_PIPEDRIVE_activities_count\":\"0\",\"ATENDIMENTOS_AGENDA_Qde Todos Atendimentos\":\"20\",\"ATENDIMENTOS_AGENDA_Faltas Todos Atendimento\":\"9\",\"ATENDIMENTOS_AGENDA_Qde Atendimento Médico\":\"3\",\"ATENDIMENTOS_AGENDA_Faltas Atendimento Médico\":\"0\",\"ATENDIMENTOS_AGENDA_Datas Atendimento Médico\":\"2022-11-08 19:00:00; 2023-03-16 16:00:00; 2023-03-16 16:00:00\",\"ATENDIMENTOS_AGENDA_Qde Atendimentos Acolhimento\":\"1\",\"ATENDIMENTOS_AGENDA_Faltas Acolhimento\":\"1\",\"ATENDIMENTOS_AGENDA_Datas Acolhimento\":\"2022-04-14 20:00:00\",\"ATENDIMENTOS_AGENDA_Qde Psicoterapia\":\"16\",\"ATENDIMENTOS_AGENDA_Faltas Psicoterapia\":\"8\",\"ATENDIMENTOS_AGENDA_Datas Psicoterapia\":\"2022-09-27 15:00:00; 2022-10-05 15:00:00; 2022-10-19 10:00:00; 2022-11-16 15:00:00; 2022-11-23 15:00:00; 2022-11-30 15:00:00; 2022-12-14 15:00:00; 2023-01-16 19:00:00; 2023-01-23 19:00:00; 2023-02-06 19:00:00; 2023-02-14 17:00:00; 2023-03-27 19:00:00; 2023-04-10 19:00:00; 2023-04-10 19:00:00; 2023-04-17 19:00:00; 2023-06-12 19:00:00\",\"ATENDIMENTOS_AGENDA_Qde Prescrições\":\"2\",\"ATENDIMENTOS_AGENDA_Datas Prescrição\":\"10\\\\/11\\\\/2021; 26\\\\/09\\\\/2022\",\"WHOQOL_Qde Respostas WHOQOL\":\"3\",\"WHOQOL_Físico\":\"2,4; 4,1; 2,9\",\"WHOQOL_Psicológico\":\"1,8; 3,2; 1,7\",\"WHOQOL_Social\":\"2,7; 3,3; 4,0\",\"WHOQOL_Ambiental\":\"2,9; 3,9; 3,5\",\"COMUNICARE_Problemas Abertos\":\"obesidade (imc >= 30) devido a um excesso calórico T82 (CIAP-2); transtorno de ansiedade generalizado P74 (CIAP-2); depressão P76 (CIAP-2); sinais\\\\/sintomas da pele, outros S29 (CIAP-2); cariótipo 46, XX, de tipo klinefelter masculino A90 (CIAP-2); tabagismo crônico P17 (CIAP-2); etilismo P15 (CIAP-2); hábitos alimentares inadequados A23 (CIAP-2); mau sono P06 (CIAP-2); tabagismo crônico P17 (CIAP-2); etilismo P15 (CIAP-2); obesidade T82 (CIAP-2); tristeza\\\\/ sensação de depressão P03 (CIAP-2); ansiedade P01 (CIAP-2); Ansiedade generalizada F411 (CID-10); otite externa H70 (CIAP-2); sensação de ansiedade\\\\/nervosismo\\\\/tensão P01 (CIAP-2); sensação de obstrução dos ouvidos H13 (CIAP-2); insônia P06 (CIAP-2); sensação de ansiedade P01 (CIAP-2); infecção fúngica A78 (CIAP-2); dor de garganta R21 (CIAP-2); Abscesso cutâneo, furúnculo e antraz L02 (CID-10); escoriação S17 (CIAP-2); Pessoa com medo de uma queixa para a qual não foi feito diagnóstico Z711 (CID-10); Verrugas de origem viral B07 (CID-10); Transtornos mentais e comportamentais devidos ao uso de fumo F17 (CID-10); Outros transtornos ansiosos F41 (CID-10)\",\"TWILIO_Mensagens Inbound\":\"1436\",\"TWILIO_Data Última Mensagens Inbound\":\"2023-09-18 17:43:41\",\"TWILIO_Mensagens Outbound\":\"1230\",\"TWILIO_Data Última Mensagens Outbound\":\"2023-09-18 18:07:31\",\"TWILIO_Ligações Inbound\":\"80\",\"TWILIO_Data Última Ligações Inbound\":\"2023-07-16 16:36:24\",\"TWILIO_Ligações Outbound\":\"12\",\"TWILIO_Data Última Ligações Outbound\":\"2023-07-14 20:55:33\",\"COBRANÇA_VINDI_Qde Total de Faturas\":null,\"COBRANÇA_VINDI_Qde Total de Tentativas de Cobrança\":null,\"COBRANÇA_VINDI_Método de Pagamento\":null,\"COBRANÇA_VINDI_Valor Médio da Mensalidade\":null,\"COBRANÇA_VINDI_Qde Total de Faturas Pagas após Vencimento\":null,\"COBRANÇA_VINDI_Qde Total de Faturas Inadimpletes\":null,\"COBRANÇA_VINDI_Valor Total Inadimplência\":null,\"COBRANÇA_VINDI_Qde Perfis de Pagamento Inativos\":null}'"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dataframe = pd.DataFrame([data_merge])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PESSOA_PIPEDRIVE_id_person</th>\n",
       "      <th>PESSOA_PIPEDRIVE_birthdate</th>\n",
       "      <th>PESSOA_PIPEDRIVE_id_gender</th>\n",
       "      <th>PESSOA_PIPEDRIVE_id_marrital_status</th>\n",
       "      <th>PESSOA_PIPEDRIVE_state</th>\n",
       "      <th>PESSOA_PIPEDRIVE_city</th>\n",
       "      <th>PESSOA_PIPEDRIVE_postal_code</th>\n",
       "      <th>PESSOA_PIPEDRIVE_id_health_plan</th>\n",
       "      <th>PESSOA_PIPEDRIVE_id_person_recommendation</th>\n",
       "      <th>PESSOA_PIPEDRIVE_contract_start_date</th>\n",
       "      <th>...</th>\n",
       "      <th>TWILIO_Ligações Outbound</th>\n",
       "      <th>TWILIO_Data Última Ligações Outbound</th>\n",
       "      <th>COBRANÇA_VINDI_Qde Total de Faturas</th>\n",
       "      <th>COBRANÇA_VINDI_Qde Total de Tentativas de Cobrança</th>\n",
       "      <th>COBRANÇA_VINDI_Método de Pagamento</th>\n",
       "      <th>COBRANÇA_VINDI_Valor Médio da Mensalidade</th>\n",
       "      <th>COBRANÇA_VINDI_Qde Total de Faturas Pagas após Vencimento</th>\n",
       "      <th>COBRANÇA_VINDI_Qde Total de Faturas Inadimpletes</th>\n",
       "      <th>COBRANÇA_VINDI_Valor Total Inadimplência</th>\n",
       "      <th>COBRANÇA_VINDI_Qde Perfis de Pagamento Inativos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>1080</td>\n",
       "      <td>1991-11-20</td>\n",
       "      <td>63</td>\n",
       "      <td>80</td>\n",
       "      <td>Pernambuco</td>\n",
       "      <td>Recife</td>\n",
       "      <td>50070-045</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-07-19</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>2023-07-14 20:55:33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 69 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "0  PESSOA_PIPEDRIVE_id_person PESSOA_PIPEDRIVE_birthdate  \\\n",
       "51                       1080                 1991-11-20   \n",
       "\n",
       "0  PESSOA_PIPEDRIVE_id_gender PESSOA_PIPEDRIVE_id_marrital_status  \\\n",
       "51                         63                                  80   \n",
       "\n",
       "0  PESSOA_PIPEDRIVE_state PESSOA_PIPEDRIVE_city PESSOA_PIPEDRIVE_postal_code  \\\n",
       "51             Pernambuco                Recife                    50070-045   \n",
       "\n",
       "0   PESSOA_PIPEDRIVE_id_health_plan  \\\n",
       "51                              NaN   \n",
       "\n",
       "0   PESSOA_PIPEDRIVE_id_person_recommendation  \\\n",
       "51                                        NaN   \n",
       "\n",
       "0  PESSOA_PIPEDRIVE_contract_start_date  ... TWILIO_Ligações Outbound  \\\n",
       "51                           2021-07-19  ...                       12   \n",
       "\n",
       "0   TWILIO_Data Última Ligações Outbound  COBRANÇA_VINDI_Qde Total de Faturas  \\\n",
       "51                   2023-07-14 20:55:33                                  NaN   \n",
       "\n",
       "0  COBRANÇA_VINDI_Qde Total de Tentativas de Cobrança  \\\n",
       "51                                                NaN   \n",
       "\n",
       "0  COBRANÇA_VINDI_Método de Pagamento  \\\n",
       "51                                NaN   \n",
       "\n",
       "0   COBRANÇA_VINDI_Valor Médio da Mensalidade  \\\n",
       "51                                        NaN   \n",
       "\n",
       "0   COBRANÇA_VINDI_Qde Total de Faturas Pagas após Vencimento  \\\n",
       "51                                                NaN           \n",
       "\n",
       "0   COBRANÇA_VINDI_Qde Total de Faturas Inadimpletes  \\\n",
       "51                                               NaN   \n",
       "\n",
       "0  COBRANÇA_VINDI_Valor Total Inadimplência  \\\n",
       "51                                      NaN   \n",
       "\n",
       "0   COBRANÇA_VINDI_Qde Perfis de Pagamento Inativos  \n",
       "51                                              NaN  \n",
       "\n",
       "[1 rows x 69 columns]"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PESSOA_PIPEDRIVE_id_person</th>\n",
       "      <th>PESSOA_PIPEDRIVE_birthdate</th>\n",
       "      <th>PESSOA_PIPEDRIVE_id_gender</th>\n",
       "      <th>PESSOA_PIPEDRIVE_id_marrital_status</th>\n",
       "      <th>PESSOA_PIPEDRIVE_state</th>\n",
       "      <th>PESSOA_PIPEDRIVE_city</th>\n",
       "      <th>PESSOA_PIPEDRIVE_postal_code</th>\n",
       "      <th>PESSOA_PIPEDRIVE_id_health_plan</th>\n",
       "      <th>PESSOA_PIPEDRIVE_id_person_recommendation</th>\n",
       "      <th>PESSOA_PIPEDRIVE_contract_start_date</th>\n",
       "      <th>...</th>\n",
       "      <th>TWILIO_Ligações Outbound</th>\n",
       "      <th>TWILIO_Data Última Ligações Outbound</th>\n",
       "      <th>COBRANÇA_VINDI_Qde Total de Faturas</th>\n",
       "      <th>COBRANÇA_VINDI_Qde Total de Tentativas de Cobrança</th>\n",
       "      <th>COBRANÇA_VINDI_Método de Pagamento</th>\n",
       "      <th>COBRANÇA_VINDI_Valor Médio da Mensalidade</th>\n",
       "      <th>COBRANÇA_VINDI_Qde Total de Faturas Pagas após Vencimento</th>\n",
       "      <th>COBRANÇA_VINDI_Qde Total de Faturas Inadimpletes</th>\n",
       "      <th>COBRANÇA_VINDI_Valor Total Inadimplência</th>\n",
       "      <th>COBRANÇA_VINDI_Qde Perfis de Pagamento Inativos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>1080</td>\n",
       "      <td>1991-11-20</td>\n",
       "      <td>63</td>\n",
       "      <td>80</td>\n",
       "      <td>Pernambuco</td>\n",
       "      <td>Recife</td>\n",
       "      <td>50070-045</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-07-19</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>2023-07-14 20:55:33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 69 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "0  PESSOA_PIPEDRIVE_id_person PESSOA_PIPEDRIVE_birthdate  \\\n",
       "51                       1080                 1991-11-20   \n",
       "\n",
       "0  PESSOA_PIPEDRIVE_id_gender PESSOA_PIPEDRIVE_id_marrital_status  \\\n",
       "51                         63                                  80   \n",
       "\n",
       "0  PESSOA_PIPEDRIVE_state PESSOA_PIPEDRIVE_city PESSOA_PIPEDRIVE_postal_code  \\\n",
       "51             Pernambuco                Recife                    50070-045   \n",
       "\n",
       "0   PESSOA_PIPEDRIVE_id_health_plan  \\\n",
       "51                              NaN   \n",
       "\n",
       "0   PESSOA_PIPEDRIVE_id_person_recommendation  \\\n",
       "51                                        NaN   \n",
       "\n",
       "0  PESSOA_PIPEDRIVE_contract_start_date  ... TWILIO_Ligações Outbound  \\\n",
       "51                           2021-07-19  ...                       12   \n",
       "\n",
       "0   TWILIO_Data Última Ligações Outbound  COBRANÇA_VINDI_Qde Total de Faturas  \\\n",
       "51                   2023-07-14 20:55:33                                  NaN   \n",
       "\n",
       "0  COBRANÇA_VINDI_Qde Total de Tentativas de Cobrança  \\\n",
       "51                                                NaN   \n",
       "\n",
       "0  COBRANÇA_VINDI_Método de Pagamento  \\\n",
       "51                                NaN   \n",
       "\n",
       "0   COBRANÇA_VINDI_Valor Médio da Mensalidade  \\\n",
       "51                                        NaN   \n",
       "\n",
       "0   COBRANÇA_VINDI_Qde Total de Faturas Pagas após Vencimento  \\\n",
       "51                                                NaN           \n",
       "\n",
       "0   COBRANÇA_VINDI_Qde Total de Faturas Inadimpletes  \\\n",
       "51                                               NaN   \n",
       "\n",
       "0  COBRANÇA_VINDI_Valor Total Inadimplência  \\\n",
       "51                                      NaN   \n",
       "\n",
       "0   COBRANÇA_VINDI_Qde Perfis de Pagamento Inativos  \n",
       "51                                              NaN  \n",
       "\n",
       "[1 rows x 69 columns]"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51   NaN\n",
       "Name: PESSOA_PIPEDRIVE_id_health_plan, dtype: float64"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dataframe[\"PESSOA_PIPEDRIVE_id_health_plan\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51   NaN\n",
       "Name: PESSOA_PIPEDRIVE_id_person_recommendation, dtype: float64"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dataframe[\"PESSOA_PIPEDRIVE_id_person_recommendation\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5b/y5xgth0n79lbt3pkmgmjphzh0000gn/T/ipykernel_16215/3407921406.py:226: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'Processo concluído' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  data_dataframe.loc[indice, \"FUNIL_ONBOARDING_PIPEDRIVE_lost_reason\"] = \"Processo concluído\"\n"
     ]
    }
   ],
   "source": [
    "import datetime as dt\n",
    "from datetime import datetime\n",
    "from sklearn.impute import SimpleImputer\n",
    "import numpy as np\n",
    "\n",
    "data_dataframe = data_dataframe.drop([\"PESSOA_PIPEDRIVE_id_person_recommendation\",\"PESSOA_PIPEDRIVE_Recebe Comunicados?\", \"PESSOA_PIPEDRIVE_Interesses\", \"PESSOA_PIPEDRIVE_Pontos de Atenção\", \"FUNIL_ONBOARDING_PIPEDRIVE_id_label\"], axis=1)\n",
    "\n",
    "data_dataframe['PESSOA_PIPEDRIVE_birthdate'] = pd.to_datetime(data_dataframe['PESSOA_PIPEDRIVE_birthdate'])\n",
    "data_dataframe['PESSOA_PIPEDRIVE_age'] = data_dataframe['PESSOA_PIPEDRIVE_birthdate'].apply(\n",
    "    lambda x: datetime.today().year - x.year - ((datetime.today().month, datetime.today().day) < (x.month, x.day))\n",
    ")\n",
    "\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "data_dataframe['PESSOA_PIPEDRIVE_age'] = imputer.fit_transform(data_dataframe['PESSOA_PIPEDRIVE_age'].values.reshape(-1, 1))\n",
    "data_dataframe['PESSOA_PIPEDRIVE_age'] = np.round(data_dataframe['PESSOA_PIPEDRIVE_age']).astype(int)\n",
    "\n",
    "data_dataframe = data_dataframe.drop(['PESSOA_PIPEDRIVE_birthdate'], axis=1 )\n",
    "\n",
    "rows_to_drop = data_dataframe[data_dataframe[\"PESSOA_PIPEDRIVE_id_gender\"].isin([117,110,111])]\n",
    "data_dataframe = data_dataframe.drop(rows_to_drop.index, axis=0)\n",
    "data_dataframe[\"PESSOA_PIPEDRIVE_id_gender\"].fillna(64, inplace=True)\n",
    "data_dataframe[\"PESSOA_PIPEDRIVE_id_marrital_status\"].fillna(80, inplace=True)\n",
    "\n",
    "\n",
    "data_dataframe[\"PESSOA_PIPEDRIVE_state\"].fillna(data_dataframe[\"PESSOA_PIPEDRIVE_state\"].mode()[0], inplace=True)\n",
    "\n",
    "\n",
    "data_dataframe[\"PESSOA_PIPEDRIVE_city\"].fillna(data_dataframe[\"PESSOA_PIPEDRIVE_city\"].mode()[0], inplace=True)\n",
    "\n",
    "def convert_to_int(x):\n",
    "    if pd.notna(x) and int(x) == 412:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "mode_value = data_dataframe['PESSOA_PIPEDRIVE_id_health_plan'].mode()\n",
    "if not mode_value.empty:\n",
    "    data_dataframe['PESSOA_PIPEDRIVE_id_health_plan'].fillna(mode_value[0], inplace=True)\n",
    "data_dataframe['PESSOA_PIPEDRIVE_has_public_health_plan'] = data_dataframe['PESSOA_PIPEDRIVE_id_health_plan'].apply(convert_to_int)\n",
    "data_dataframe = data_dataframe.drop(['PESSOA_PIPEDRIVE_id_health_plan'], axis=1)\n",
    "data_dataframe[\"PESSOA_PIPEDRIVE_tem_data_dataframe_de_termino_de_contrato\"] = data_dataframe[\"PESSOA_PIPEDRIVE_contract_end_date\"].apply(lambda x: 0 if pd.isna(x) else 1)\n",
    "data_dataframe.drop([\"PESSOA_PIPEDRIVE_id_continuity_pf\"], axis=1, inplace=True)\n",
    "data_dataframe[\"PESSOA_PIPEDRIVE_Canal de Preferência\"].fillna(0, inplace=True)\n",
    "data_dataframe[\"PESSOA_PIPEDRIVE_Tem_Canal_de_Preferência\"] = data_dataframe[\"PESSOA_PIPEDRIVE_Canal de Preferência\"].apply(lambda x: 1 if int(x) > 0  else 0)\n",
    "data_dataframe[\"PESSOA_PIPEDRIVE_has_notes\"] = data_dataframe[\"PESSOA_PIPEDRIVE_notes_count\"].apply(lambda x: 1 if int(x) > 0 else 0)\n",
    "\n",
    "# preprocessing 2\n",
    "data_dataframe = data_dataframe.drop([\"ATENDIMENTOS_AGENDA_Faltas Psicoterapia\",\"TWILIO_Ligações Inbound\", \"TWILIO_Data Última Ligações Inbound\",\"COBRANÇA_VINDI_Qde Total de Faturas\",\"COBRANÇA_VINDI_Qde Total de Tentativas de Cobrança\",\"COBRANÇA_VINDI_Método de Pagamento\",\"COBRANÇA_VINDI_Valor Médio da Mensalidade\",\"COBRANÇA_VINDI_Qde Total de Faturas Pagas após Vencimento\",\"COBRANÇA_VINDI_Qde Total de Faturas Inadimpletes\",\"COBRANÇA_VINDI_Valor Total Inadimplência\"], axis=1)\n",
    "\n",
    "data_dataframe[\"ATENDIMENTOS_AGENDA_Qde Psicoterapia\"].fillna(0, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "data_dataframe = data_dataframe.drop(columns=\"WHOQOL_Qde Respostas WHOQOL\")\n",
    "\n",
    "data_dataframe[\"WHOQOL_Físico_New\"] = data_dataframe[\"WHOQOL_Físico\"].str.split(';').str[-1].str.strip()\n",
    "\n",
    "data_dataframe[\"WHOQOL_Físico_New\"] = data_dataframe[\"WHOQOL_Físico_New\"].str.replace(\",\",\".\")\n",
    "\n",
    "data_dataframe[\"WHOQOL_Físico_New\"] = data_dataframe[\"WHOQOL_Físico_New\"].astype(float) \n",
    "\n",
    "data_dataframe[\"WHOQOL_Físico_New\"] = data_dataframe[\"WHOQOL_Físico_New\"].fillna(data_dataframe[\"WHOQOL_Físico_New\"].median())\n",
    "\n",
    "data_dataframe[\"WHOQOL_Psicológico_New\"] = data_dataframe[\"WHOQOL_Psicológico\"].str.split(';').str[-1].str.strip()\n",
    "\n",
    "data_dataframe[\"WHOQOL_Psicológico_New\"] = data_dataframe[\"WHOQOL_Psicológico_New\"].str.replace(\",\",\".\")\n",
    "\n",
    "data_dataframe[\"WHOQOL_Psicológico_New\"] = data_dataframe[\"WHOQOL_Psicológico_New\"].astype(float) \n",
    "\n",
    "data_dataframe[\"WHOQOL_Psicológico_New\"] = data_dataframe[\"WHOQOL_Psicológico_New\"].fillna(data_dataframe[\"WHOQOL_Psicológico_New\"].median())\n",
    "\n",
    "data_dataframe[\"WHOQOL_Social_New\"] = data_dataframe[\"WHOQOL_Social\"].str.split(';').str[-1].str.strip()\n",
    "\n",
    "data_dataframe[\"WHOQOL_Social_New\"] = data_dataframe[\"WHOQOL_Social_New\"].str.replace(\",\",\".\")\n",
    "\n",
    "data_dataframe[\"WHOQOL_Social_New\"] = data_dataframe[\"WHOQOL_Social_New\"].astype(float) \n",
    "\n",
    "data_dataframe[\"WHOQOL_Social_New\"] = data_dataframe[\"WHOQOL_Social_New\"].fillna(data_dataframe[\"WHOQOL_Social_New\"].median())\n",
    "\n",
    "data_dataframe[\"WHOQOL_Ambiental_New\"] = data_dataframe[\"WHOQOL_Ambiental\"].str.split(';').str[-1].str.strip()\n",
    "\n",
    "data_dataframe[\"WHOQOL_Ambiental_New\"] = data_dataframe[\"WHOQOL_Ambiental_New\"].str.replace(\",\",\".\")\n",
    "\n",
    "data_dataframe[\"WHOQOL_Ambiental_New\"] = data_dataframe[\"WHOQOL_Ambiental_New\"].astype(float) \n",
    "\n",
    "data_dataframe[\"WHOQOL_Ambiental_New\"] = data_dataframe[\"WHOQOL_Ambiental_New\"].fillna(data_dataframe[\"WHOQOL_Ambiental_New\"].median())\n",
    "\n",
    "data_dataframe[\"COMUNICARE_Problemas Abertos Bool\"] = data_dataframe[\"COMUNICARE_Problemas Abertos\"].notnull().astype(int)\n",
    "\n",
    "data_dataframe[\"COMUNICARE_Problemas Abertos Bool\"].fillna(0, inplace=True)\n",
    "\n",
    "data_dataframe[\"TWILIO_Mensagens Inbound\"].fillna(0, inplace=True)\n",
    "\n",
    "data_dataframe[\"TWILIO_Data Última Mensagens Inbound\"] = pd.to_datetime(data_dataframe[\"TWILIO_Data Última Mensagens Inbound\"])\n",
    "\n",
    "data_dataframe[\"TWILIO_Data Última Mensagens Inbound Tempo Passado\"] = datetime.now() - data_dataframe[\"TWILIO_Data Última Mensagens Inbound\"]\n",
    "\n",
    "data_dataframe[\"TWILIO_Data Última Mensagens Inbound Tempo Passado\"].fillna('', inplace=True)\n",
    "\n",
    "data_dataframe[\"TWILIO_Data Última Mensagens Inbound Tempo Passado\"] = data_dataframe[\"TWILIO_Data Última Mensagens Inbound Tempo Passado\"].astype(str)\n",
    "\n",
    "data_dataframe[\"TWILIO_Data Última Mensagens Inbound Tempo Passado\"] = data_dataframe[\"TWILIO_Data Última Mensagens Inbound Tempo Passado\"].str.extract('(\\d+) days').astype(float)\n",
    "\n",
    "data_dataframe[\"TWILIO_Data Última Mensagens Inbound Recente\"] = data_dataframe[\"TWILIO_Data Última Mensagens Inbound Tempo Passado\"] < data_dataframe[\"TWILIO_Data Última Mensagens Inbound Tempo Passado\"].median()\n",
    "data_dataframe[\"TWILIO_Data Última Mensagens Inbound Recente\"].fillna(0)\n",
    "data_dataframe[\"TWILIO_Data Última Mensagens Inbound Recente\"].replace(True, 1, inplace=True)\n",
    "data_dataframe[\"TWILIO_Data Última Mensagens Inbound Recente\"].replace(False, 0, inplace=True)\n",
    "\n",
    "data_dataframe = data_dataframe.drop(columns=[\"WHOQOL_Ambiental\",\"WHOQOL_Social\",\"WHOQOL_Físico\",\"WHOQOL_Psicológico\",\"COMUNICARE_Problemas Abertos\",\"TWILIO_Data Última Mensagens Inbound\",\"ATENDIMENTOS_AGENDA_Datas Psicoterapia\",\"TWILIO_Data Última Mensagens Inbound Tempo Passado\"])\n",
    "\n",
    "# preprocessing 3\n",
    "for indice, valor in data_dataframe[\"FUNIL_ASSINATURA_PIPEDRIVE_lost_time\"].items():\n",
    "    if pd.notna(valor) == False: \n",
    "        if pd.notna(data_dataframe.loc[indice, \"PESSOA_PIPEDRIVE_contract_end_date\"]):\n",
    "            data_dataframe.loc[indice, \"FUNIL_ASSINATURA_PIPEDRIVE_lost_time\"] = data_dataframe.loc[indice, \"PESSOA_PIPEDRIVE_contract_end_date\"]\n",
    "\n",
    "data_dataframe[\"FUNIL_ASSINATURA_PIPEDRIVE_lost_time\"].fillna(dt.date.today(), inplace=True)\n",
    "\n",
    "for indice, valor in data_dataframe[\"FUNIL_ASSINATURA_PIPEDRIVE_lost_time\"].items():\n",
    "    index = str(data_dataframe.loc[indice, \"FUNIL_ASSINATURA_PIPEDRIVE_lost_time\"]).find(\";\")\n",
    "    if index != -1:\n",
    "        data_dataframe.loc[indice, \"FUNIL_ASSINATURA_PIPEDRIVE_lost_time\"] = data_dataframe.loc[indice, \"FUNIL_ASSINATURA_PIPEDRIVE_lost_time\"][:index]\n",
    "\n",
    "for indice, valor in data_dataframe[\"FUNIL_ASSINATURA_PIPEDRIVE_lost_time\"].items():\n",
    "    tamanho = len(str(data_dataframe.loc[indice, \"FUNIL_ASSINATURA_PIPEDRIVE_lost_time\"]))\n",
    "    if tamanho > 10:\n",
    "        data_dataframe.loc[indice, \"FUNIL_ASSINATURA_PIPEDRIVE_lost_time\"] = data_dataframe.loc[indice, \"FUNIL_ASSINATURA_PIPEDRIVE_lost_time\"][:10]\t\n",
    "\n",
    "for indice, valor in data_dataframe[\"FUNIL_ASSINATURA_PIPEDRIVE_lost_time\"].items():\n",
    "    data_dataframe.loc[indice, \"FUNIL_ASSINATURA_PIPEDRIVE_lost_time\"] = pd.to_datetime(data_dataframe.loc[indice, \"FUNIL_ASSINATURA_PIPEDRIVE_lost_time\"], format='%Y-%m-%d', errors='coerce')\n",
    "    data_dataframe.loc[indice, \"FUNIL_ASSINATURA_PIPEDRIVE_lost_time\"] = data_dataframe.loc[indice, \"FUNIL_ASSINATURA_PIPEDRIVE_lost_time\"].strftime('%Y-%m-%d')\n",
    "\n",
    "tempo_permanencia = []\n",
    "\n",
    "for indice, valor in data_dataframe[\"FUNIL_ASSINATURA_PIPEDRIVE_start_of_service\"].items():\n",
    "    if pd.notna(valor):\n",
    "        index = data_dataframe.loc[indice, \"FUNIL_ASSINATURA_PIPEDRIVE_start_of_service\"].find(\";\")\n",
    "        if index != -1:\n",
    "            data_dataframe.loc[indice, \"FUNIL_ASSINATURA_PIPEDRIVE_start_of_service\"] = data_dataframe.loc[indice, \"FUNIL_ASSINATURA_PIPEDRIVE_start_of_service\"][:index]\n",
    "\n",
    "for indice, valor in data_dataframe[\"FUNIL_ASSINATURA_PIPEDRIVE_lost_time\"].items():\n",
    "    if pd.notna(data_dataframe.loc[indice, \"FUNIL_ASSINATURA_PIPEDRIVE_start_of_service\"]):\n",
    "        tempo_1 = datetime.strptime(data_dataframe.loc[indice, \"FUNIL_ASSINATURA_PIPEDRIVE_lost_time\"], '%Y-%m-%d')\n",
    "        tempo_2 = datetime.strptime(data_dataframe.loc[indice, \"FUNIL_ASSINATURA_PIPEDRIVE_start_of_service\"], '%Y-%m-%d')\n",
    "        tempo_permanencia.append(str(tempo_1 - tempo_2))\n",
    "    else:\n",
    "        tempo_1 = datetime.strptime(data_dataframe.loc[indice, \"FUNIL_ASSINATURA_PIPEDRIVE_lost_time\"], '%Y-%m-%d')\n",
    "        tempo_2 = datetime.strptime(data_dataframe.loc[indice, \"PESSOA_PIPEDRIVE_contract_start_date\"], '%Y-%m-%d')\n",
    "        tempo_permanencia.append(str(tempo_1 - tempo_2))\n",
    "\n",
    "data_dataframe['stay_time'] = tempo_permanencia\n",
    "\n",
    "for indice, valor in data_dataframe[\"stay_time\"].items():\n",
    "    index = data_dataframe.loc[indice, \"stay_time\"].find(\",\")\n",
    "    if index != -1:\n",
    "        data_dataframe.loc[indice, \"stay_time\"] = data_dataframe.loc[indice, \"stay_time\"][:index]\n",
    "\n",
    "for indice, valor in data_dataframe[\"FUNIL_ASSINATURA_PIPEDRIVE_lost_reason\"].items():\n",
    "    if pd.notna(valor):  \n",
    "        index = data_dataframe.loc[indice, \"FUNIL_ASSINATURA_PIPEDRIVE_lost_reason\"].find(\";\")\n",
    "        if index != -1: \n",
    "            data_dataframe.loc[indice, \"FUNIL_ASSINATURA_PIPEDRIVE_lost_reason\"] = data_dataframe.loc[indice, \"FUNIL_ASSINATURA_PIPEDRIVE_lost_reason\"][:index]\n",
    "    else:\n",
    "        data_dataframe.loc[indice, \"FUNIL_ASSINATURA_PIPEDRIVE_lost_reason\"] = \"Assinatura ativa\"\n",
    "        \n",
    "    contagem = data_dataframe[\"FUNIL_ASSINATURA_PIPEDRIVE_lost_reason\"].value_counts()\n",
    "\n",
    "    agrupamento = contagem[contagem < 20].index\n",
    "    data_dataframe.loc[data_dataframe[\"FUNIL_ASSINATURA_PIPEDRIVE_lost_reason\"].isin(agrupamento), \"FUNIL_ASSINATURA_PIPEDRIVE_lost_reason\"] = \"Outro\"\n",
    "\n",
    "data_dataframe['FUNIL_ONBOARDING_PIPEDRIVE_add_time'].fillna('Não iniciado', inplace=True)\n",
    "\n",
    "ultimos_estados = []\n",
    "\n",
    "for indice, valor in data_dataframe[\"FUNIL_ONBOARDING_PIPEDRIVE_add_time\"].items():\n",
    "    if valor != \"Não iniciado\":\n",
    "        if pd.notna(data_dataframe.loc[indice, \"FUNIL_ONBOARDING_PIPEDRIVE_stay_in_pipeline_stages_welcome\"]):\n",
    "            if pd.notna(data_dataframe.loc[indice, \"FUNIL_ONBOARDING_PIPEDRIVE_stay_in_pipeline_stages_first_meeting\"]):\n",
    "                if pd.notna(data_dataframe.loc[indice, \"FUNIL_ONBOARDING_PIPEDRIVE_stay_in_pipeline_stages_whoqol\"]):\n",
    "                    ultimos_estados.append(\"Questionário\")\n",
    "                else:\n",
    "                    ultimos_estados.append(\"Primeira reunião\")\n",
    "            else:\n",
    "                ultimos_estados.append(\"Boas-vindas\")\n",
    "        \n",
    "    else:\n",
    "        ultimos_estados.append(\"Não iniciado\")\n",
    "\n",
    "data_dataframe[\"last_stage_concluded\"] = ultimos_estados\n",
    "\n",
    "data_dataframe.drop([\"FUNIL_ONBOARDING_PIPEDRIVE_stay_in_pipeline_stages_welcome\", \"FUNIL_ONBOARDING_PIPEDRIVE_stay_in_pipeline_stages_first_meeting\", \"FUNIL_ONBOARDING_PIPEDRIVE_stay_in_pipeline_stages_whoqol\"], axis=1, inplace=True)\n",
    "\n",
    "data_dataframe[\"FUNIL_ONBOARDING_PIPEDRIVE_status\"].fillna(\"Não iniciado\", inplace=True)\n",
    "\n",
    "tempo = []\n",
    "\n",
    "for indice, valor in data_dataframe[\"FUNIL_ONBOARDING_PIPEDRIVE_add_time\"].items():\n",
    "    if valor != \"Não iniciado\":\n",
    "        if pd.notna(data_dataframe.loc[indice, \"FUNIL_ONBOARDING_PIPEDRIVE_lost_time\"]) == True:\n",
    "            tempo.append(data_dataframe.loc[indice, \"FUNIL_ONBOARDING_PIPEDRIVE_lost_time\"])\n",
    "        elif pd.notna(data_dataframe.loc[indice, \"FUNIL_ONBOARDING_PIPEDRIVE_won_time\"]) == True:\n",
    "            tempo.append(data_dataframe.loc[indice, \"FUNIL_ONBOARDING_PIPEDRIVE_won_time\"])\n",
    "        else:\n",
    "            tempo.append(\"Em aberto\")\n",
    "    else:\n",
    "        tempo.append(\"Não iniciado\")\n",
    "\n",
    "data_dataframe['process_time'] = tempo\n",
    "\n",
    "data_dataframe.drop([\"FUNIL_ONBOARDING_PIPEDRIVE_won_time\", \"FUNIL_ONBOARDING_PIPEDRIVE_lost_time\"], axis=1, inplace=True)\n",
    "\n",
    "data_dataframe[\"FUNIL_ONBOARDING_PIPEDRIVE_activities_count\"] = data_dataframe[\"FUNIL_ONBOARDING_PIPEDRIVE_activities_count\"].fillna(0)\n",
    "\n",
    "data_dataframe[\"ATENDIMENTOS_AGENDA_Qde Atendimento Médico\"] = data_dataframe[\"ATENDIMENTOS_AGENDA_Qde Atendimento Médico\"].fillna(0)\n",
    "\n",
    "data_dataframe[\"ATENDIMENTOS_AGENDA_Faltas Atendimento Médico\"] = data_dataframe[\"ATENDIMENTOS_AGENDA_Faltas Atendimento Médico\"].fillna(0)\n",
    "\n",
    "data_dataframe[\"ATENDIMENTOS_AGENDA_Datas Atendimento Médico\"] = data_dataframe[\"ATENDIMENTOS_AGENDA_Datas Atendimento Médico\"].fillna(\"Nunca ocorreu\")\n",
    "\n",
    "for indice, valor in data_dataframe[\"FUNIL_ONBOARDING_PIPEDRIVE_lost_reason\"].items():\n",
    "    if pd.notna(valor) == False:\n",
    "        if pd.notna(data_dataframe.loc[indice, \"FUNIL_ONBOARDING_PIPEDRIVE_status\"]) == False and pd.notna(data_dataframe.loc[indice, \"FUNIL_ONBOARDING_PIPEDRIVE_add_time\"]):\n",
    "            data_dataframe.loc[indice, \"FUNIL_ONBOARDING_PIPEDRIVE_lost_reason\"] = \"Processo em aberto\"\n",
    "        if data_dataframe.loc[indice, \"FUNIL_ONBOARDING_PIPEDRIVE_status\"] == \"won\":\n",
    "            data_dataframe.loc[indice, \"FUNIL_ONBOARDING_PIPEDRIVE_lost_reason\"] = \"Processo concluído\"\n",
    "        else:\n",
    "            data_dataframe.loc[indice, \"FUNIL_ONBOARDING_PIPEDRIVE_lost_reason\"] = \"Processo não iniciado\"\n",
    "\n",
    "    contagem = data_dataframe[\"FUNIL_ONBOARDING_PIPEDRIVE_lost_reason\"].value_counts()\n",
    "\n",
    "    agrupamento = contagem[contagem < 23].index\n",
    "    data_dataframe.loc[data_dataframe[\"FUNIL_ONBOARDING_PIPEDRIVE_lost_reason\"].isin(agrupamento), \"FUNIL_ONBOARDING_PIPEDRIVE_lost_reason\"] = \"Outro\"\n",
    "\n",
    "data_dataframe[\"ATENDIMENTOS_AGENDA_Qde Atendimentos Acolhimento\"] = data_dataframe[\"ATENDIMENTOS_AGENDA_Qde Atendimentos Acolhimento\"].fillna(0)\n",
    "\n",
    "data_dataframe[\"ATENDIMENTOS_AGENDA_Faltas Acolhimento\"] = data_dataframe[\"ATENDIMENTOS_AGENDA_Faltas Acolhimento\"].fillna(0)\n",
    "\n",
    "data_dataframe[\"ATENDIMENTOS_AGENDA_Datas Acolhimento\"] = data_dataframe[\"ATENDIMENTOS_AGENDA_Datas Acolhimento\"].fillna(\"Nunca ocorreu\")\n",
    "\n",
    "data_dataframe[\"ATENDIMENTOS_AGENDA_Qde Psicoterapia\"] = data_dataframe[\"ATENDIMENTOS_AGENDA_Qde Psicoterapia\"].fillna(0)\n",
    "\n",
    "# preprocessing 4\n",
    "\n",
    "data_dataframe[\"TWILIO_Mensagens Outbound\"].fillna(0, inplace=True)\n",
    "\n",
    "data_dataframe[\"TWILIO_Data Última Mensagens Outbound\"] = pd.to_datetime(data_dataframe[\"TWILIO_Data Última Mensagens Outbound\"])\n",
    "\n",
    "data_dataframe[\"TWILIO_Data Última Mensagens Outbound Tempo passado\"] = datetime.now() - data_dataframe[\"TWILIO_Data Última Mensagens Outbound\"]\n",
    "\n",
    "data_dataframe[\"TWILIO_Data Última Mensagens Outbound Tempo passado\"].fillna('', inplace=True)\n",
    "\n",
    "data_dataframe[\"TWILIO_Data Última Mensagens Outbound Tempo passado\"] = data_dataframe[\"TWILIO_Data Última Mensagens Outbound Tempo passado\"].astype(str)\n",
    "\n",
    "data_dataframe[\"TWILIO_Data Última Mensagens Outbound Tempo passado\"] = data_dataframe[\"TWILIO_Data Última Mensagens Outbound Tempo passado\"].str.extract('(\\d+) days').astype(float)\n",
    "\n",
    "data_dataframe = data_dataframe.drop([\"TWILIO_Data Última Mensagens Outbound\"], axis=1)\n",
    "\n",
    "data_dataframe[\"TWILIO_Data Última Mensagens Outbound Recente\"] = data_dataframe[\"TWILIO_Data Última Mensagens Outbound Tempo passado\"] < data_dataframe[\"TWILIO_Data Última Mensagens Outbound Tempo passado\"].median()\n",
    "data_dataframe[\"TWILIO_Data Última Mensagens Outbound Recente\"].fillna(0)\n",
    "data_dataframe[\"TWILIO_Data Última Mensagens Outbound Recente\"].replace(True, 1, inplace=True)\n",
    "data_dataframe[\"TWILIO_Data Última Mensagens Outbound Recente\"].replace(False, 0, inplace=True)\n",
    "\n",
    "data_dataframe = data_dataframe.drop([\"TWILIO_Data Última Mensagens Outbound Tempo passado\"], axis=1)\n",
    "\n",
    "data_dataframe[\"TWILIO_Ligações Outbound\"].fillna(0, inplace=True)\n",
    "\n",
    "data_dataframe[\"TWILIO_Data Última Ligações Outbound\"] = pd.to_datetime(data_dataframe[\"TWILIO_Data Última Ligações Outbound\"])\n",
    "\n",
    "data_dataframe[\"TWILIO_Data Última Ligações Outbound Tempo passado\"] = datetime.now() - data_dataframe[\"TWILIO_Data Última Ligações Outbound\"]\n",
    "\n",
    "data_dataframe[\"TWILIO_Data Última Ligações Outbound Tempo passado\"].fillna('', inplace=True)\n",
    "\n",
    "data_dataframe[\"TWILIO_Data Última Ligações Outbound Tempo passado\"] = data_dataframe[\"TWILIO_Data Última Ligações Outbound Tempo passado\"].astype(str)\n",
    "\n",
    "data_dataframe[\"TWILIO_Data Última Ligações Outbound Tempo passado\"] = data_dataframe[\"TWILIO_Data Última Ligações Outbound Tempo passado\"].str.extract('(\\d+) days').astype(float)\n",
    "\n",
    "data_dataframe = data_dataframe.drop([\"TWILIO_Data Última Ligações Outbound\"], axis=1)\n",
    "\n",
    "data_dataframe[\"TWILIO_Data Última Ligações Outbound Recente\"] = data_dataframe[\"TWILIO_Data Última Ligações Outbound Tempo passado\"] < data_dataframe[\"TWILIO_Data Última Ligações Outbound Tempo passado\"].median()\n",
    "data_dataframe[\"TWILIO_Data Última Ligações Outbound Recente\"].fillna(0)\n",
    "data_dataframe[\"TWILIO_Data Última Ligações Outbound Recente\"].replace(True, 1, inplace=True)\n",
    "data_dataframe[\"TWILIO_Data Última Ligações Outbound Recente\"].replace(False, 0, inplace=True)\n",
    "\n",
    "data_dataframe = data_dataframe.drop([\"TWILIO_Data Última Ligações Outbound Tempo passado\"], axis=1)\n",
    "\n",
    "data_dataframe = data_dataframe.drop([\"COBRANÇA_VINDI_Qde Perfis de Pagamento Inativos\"], axis=1)\n",
    "\n",
    "# preprocessing especials \n",
    "\n",
    "data_dataframe = data_dataframe[data_dataframe['FUNIL_ASSINATURA_PIPEDRIVE_status'].isin(['won', 'lost'])]\n",
    "\n",
    "data_dataframe = data_dataframe.drop(data_dataframe[(data_dataframe['FUNIL_ASSINATURA_PIPEDRIVE_status'] == 'won') & (~data_dataframe['PESSOA_PIPEDRIVE_contract_end_date'].isnull())].index)\n",
    "\n",
    "data_dataframe = data_dataframe.drop(data_dataframe[(data_dataframe['FUNIL_ASSINATURA_PIPEDRIVE_status'] == 'lost') & (data_dataframe['PESSOA_PIPEDRIVE_contract_end_date'].isnull())].index)\n",
    "\n",
    "#exportando df pronto\n",
    "\n",
    "data_dataframe.to_csv('../notebooks/data/data-preprocessed.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 51)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dataframe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51    2.9\n",
       "Name: WHOQOL_Físico_New, dtype: float64"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dataframe[\"WHOQOL_Físico_New\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from category_encoders import CountEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from scipy import stats\n",
    "from sklearn.utils import resample\n",
    "from sqlalchemy import false\n",
    "\n",
    "dataframe = pd.read_csv(\"../notebooks/data/data-preprocessed.csv\")\n",
    "\n",
    "\n",
    "dataframe[\"stay_time\"] = dataframe[\"stay_time\"].str.extract('(\\d+) days').astype(float)\n",
    "\n",
    "dataframe[\"stay_time\"].fillna(0,inplace=True)\n",
    "\n",
    "dataframe[\"ATENDIMENTOS_AGENDA_Qde Atendimentos Acolhimento\"].fillna(0,inplace=True)\n",
    "dataframe[\"ATENDIMENTOS_AGENDA_Faltas Acolhimento\"].fillna(0,inplace=True)\n",
    "dataframe[\"ATENDIMENTOS_AGENDA_Datas Acolhimento\"].fillna(\"Nunca ocorreu\",inplace=True)\n",
    "\n",
    "# dataframe = dataframe[~dataframe['ATENDIMENTOS_AGENDA_Datas Acolhimento'].astype(str).str.contains(\"Nunca ocorreu\")]\n",
    "\n",
    "# dataframe = dataframe.explode('ATENDIMENTOS_AGENDA_Datas Acolhimento')\n",
    "\n",
    "dataframe[\"TWILIO_Mensagens Já Enviou\"] = dataframe[\"TWILIO_Mensagens Inbound\"] > 0\n",
    "dataframe[\"TWILIO_Mensagens Razão\"] = dataframe[\"TWILIO_Mensagens Outbound\"] / dataframe[\"TWILIO_Mensagens Inbound\"].where(dataframe[\"TWILIO_Mensagens Já Enviou\"], 1)\n",
    "\n",
    "dataframe[\"PESSOA_PIPEDRIVE CRIANÇA\"] = dataframe[\"PESSOA_PIPEDRIVE_age\"] <= 16\n",
    "dataframe[\"PESSOA_PIPEDRIVE CRIANÇA\"].fillna(0)\n",
    "dataframe[\"PESSOA_PIPEDRIVE CRIANÇA\"].replace(True, 1, inplace=True)\n",
    "dataframe[\"PESSOA_PIPEDRIVE CRIANÇA\"].replace(False, 0, inplace=True)\n",
    "\n",
    "dataframe[\"PESSOA_PIPEDRIVE JOVEM\"] = (dataframe[\"PESSOA_PIPEDRIVE_age\"] > 16) & (dataframe[\"PESSOA_PIPEDRIVE_age\"] <= 30)\n",
    "dataframe[\"PESSOA_PIPEDRIVE JOVEM\"].fillna(0)\n",
    "dataframe[\"PESSOA_PIPEDRIVE JOVEM\"].replace(True, 1, inplace=True)\n",
    "dataframe[\"PESSOA_PIPEDRIVE JOVEM\"].replace(False, 0, inplace=True)\n",
    "\n",
    "dataframe[\"PESSOA_PIPEDRIVE ADULTO\"] = (dataframe[\"PESSOA_PIPEDRIVE_age\"] > 30) & (dataframe[\"PESSOA_PIPEDRIVE_age\"] <= 60)\n",
    "dataframe[\"PESSOA_PIPEDRIVE ADULTO\"].fillna(0)\n",
    "dataframe[\"PESSOA_PIPEDRIVE ADULTO\"].replace(True, 1, inplace=True)\n",
    "dataframe[\"PESSOA_PIPEDRIVE ADULTO\"].replace(False, 0, inplace=True)\n",
    "\n",
    "dataframe[\"PESSOA_PIPEDRIVE IDOSO\"] = dataframe[\"PESSOA_PIPEDRIVE_age\"] > 60\n",
    "dataframe[\"PESSOA_PIPEDRIVE IDOSO\"].fillna(0)\n",
    "dataframe[\"PESSOA_PIPEDRIVE IDOSO\"].replace(True, 1, inplace=True)\n",
    "dataframe[\"PESSOA_PIPEDRIVE IDOSO\"].replace(False, 0, inplace=True)\n",
    "\n",
    "\n",
    "dataframe[\"TWILIO_Ligações Outbound Qtd Significativa\"] = dataframe[\"TWILIO_Ligações Outbound\"] >= dataframe[\"TWILIO_Ligações Outbound\"].mean()\n",
    "dataframe[\"TWILIO_Ligações Outbound Qtd Significativa\"].fillna(0)\n",
    "dataframe[\"TWILIO_Ligações Outbound Qtd Significativa\"].replace(True, 1, inplace=True)\n",
    "dataframe[\"TWILIO_Ligações Outbound Qtd Significativa\"].replace(False, 0, inplace=True)\n",
    "\n",
    "dataframe[\"ATENDIMENTOS_AGENDA_Qde Psicoterapia Nenhum\"] = dataframe[\"ATENDIMENTOS_AGENDA_Qde Psicoterapia\"] == 0\n",
    "dataframe[\"ATENDIMENTOS_AGENDA_Qde Psicoterapia Nenhum\"].fillna(0)\n",
    "dataframe[\"ATENDIMENTOS_AGENDA_Qde Psicoterapia Nenhum\"].replace(True, 1, inplace=True)\n",
    "dataframe[\"ATENDIMENTOS_AGENDA_Qde Psicoterapia Nenhum\"].replace(False, 0, inplace=True)\n",
    "\n",
    "dataframe[\"ATENDIMENTOS_AGENDA_Qde Psicoterapia Pouco\"] = (dataframe[\"ATENDIMENTOS_AGENDA_Qde Psicoterapia\"] > 0) & (dataframe[\"ATENDIMENTOS_AGENDA_Qde Psicoterapia\"] <= dataframe[\"ATENDIMENTOS_AGENDA_Qde Psicoterapia\"].mean() )\n",
    "dataframe[\"ATENDIMENTOS_AGENDA_Qde Psicoterapia Pouco\"].fillna(0)\n",
    "dataframe[\"ATENDIMENTOS_AGENDA_Qde Psicoterapia Pouco\"].replace(True, 1, inplace=True)\n",
    "dataframe[\"ATENDIMENTOS_AGENDA_Qde Psicoterapia Pouco\"].replace(False, 0, inplace=True)\n",
    "\n",
    "dataframe[\"ATENDIMENTOS_AGENDA_Qde Psicoterapia Muito\"] = dataframe[\"ATENDIMENTOS_AGENDA_Qde Psicoterapia\"] > dataframe[\"ATENDIMENTOS_AGENDA_Qde Psicoterapia\"].mean() \n",
    "dataframe[\"ATENDIMENTOS_AGENDA_Qde Psicoterapia Muito\"].fillna(0)\n",
    "dataframe[\"ATENDIMENTOS_AGENDA_Qde Psicoterapia Muito\"].replace(True, 1, inplace=True)\n",
    "dataframe[\"ATENDIMENTOS_AGENDA_Qde Psicoterapia Muito\"].replace(False, 0, inplace=True)\n",
    "\n",
    "dataframe[\"ATENDIMENTOS_AGENDA_Qde Prescrições\"].fillna(0,inplace=True)\n",
    "\n",
    "dataframe = dataframe.drop([\"ATENDIMENTOS_AGENDA_Datas Prescrição\"],axis=1)\n",
    "\n",
    "dataframe = dataframe[dataframe[\"PESSOA_PIPEDRIVE_id_gender\"].isin([64,63])]   \n",
    "dataframe[\"PESSOA_PIPEDRIVE_id_gender Binário\"] = dataframe[\"PESSOA_PIPEDRIVE_id_gender\"].map({64: 0, 63: 1})\n",
    "\n",
    "dataframe = dataframe[dataframe[\"FUNIL_ASSINATURA_PIPEDRIVE_id_stage\"].isin([65,64])]   \n",
    "dataframe[\"FUNIL_ASSINATURA_PIPEDRIVE_id_stage Binário\"] = dataframe[\"FUNIL_ASSINATURA_PIPEDRIVE_id_stage\"].map({65: 0, 64: 1})\n",
    "\n",
    "\n",
    "\n",
    "dataframe = pd.get_dummies(dataframe, columns=['PESSOA_PIPEDRIVE_id_marrital_status'], prefix='Status')\n",
    "dataframe = pd.get_dummies(dataframe, columns=['PESSOA_PIPEDRIVE_state'], prefix='Estado')\n",
    "\n",
    "ce = CountEncoder()\n",
    "dataframe['PESSOA_PIPEDRIVE_city Codificada'] = ce.fit_transform(dataframe['PESSOA_PIPEDRIVE_city'])\n",
    "\n",
    "\n",
    "dataframe = dataframe.drop(columns=[\"PESSOA_PIPEDRIVE_postal_code\",\"PESSOA_PIPEDRIVE_id_person\",\"PESSOA_PIPEDRIVE_city\",\"PESSOA_PIPEDRIVE_id_gender\",\"PESSOA_PIPEDRIVE_contract_start_date\",\"PESSOA_PIPEDRIVE_contract_end_date\",\"FUNIL_ASSINATURA_PIPEDRIVE_id_stage\",\"FUNIL_ASSINATURA_PIPEDRIVE_id_org\",\"FUNIL_ASSINATURA_PIPEDRIVE_lost_time\",\"FUNIL_ASSINATURA_PIPEDRIVE_start_of_service\",\"FUNIL_ONBOARDING_PIPEDRIVE_add_time\",\"ATENDIMENTOS_AGENDA_Datas Atendimento Médico\",\"ATENDIMENTOS_AGENDA_Datas Acolhimento\",\"process_time\"])\n",
    "\n",
    "\n",
    "# feature engineering 2 + 3\n",
    "\n",
    "dataframe = pd.get_dummies(dataframe,columns=[\"FUNIL_ASSINATURA_PIPEDRIVE_status\"], prefix='status')\n",
    "\n",
    "\n",
    "dataframe = pd.get_dummies(dataframe,columns=['FUNIL_ASSINATURA_PIPEDRIVE_lost_reason'], prefix='lost_reason')\n",
    "\n",
    "dataframe = pd.get_dummies(dataframe,columns=['PESSOA_PIPEDRIVE_Canal de Preferência'], prefix='canal_preferencia')    \n",
    "\n",
    "dataframe = pd.get_dummies(dataframe,columns=['FUNIL_ONBOARDING_PIPEDRIVE_status'], prefix='Status')\n",
    "\n",
    "\n",
    "dataframe = pd.get_dummies(dataframe,columns=['FUNIL_ONBOARDING_PIPEDRIVE_lost_reason'], prefix='lost_reason')\n",
    "\n",
    "\n",
    "dataframe.drop('ATENDIMENTOS_AGENDA_Qde Todos Atendimentos', axis='columns', inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "# feature engineering 4 + 3\n",
    "\n",
    "if dataframe['WHOQOL_Físico_New'].dtype == 'object':\n",
    "    # Aplicando codificação one-hot para variáveis categóricas\n",
    "    encoder = OneHotEncoder()\n",
    "    encoded = encoder.fit_transform(dataframe[['WHOQOL_Físico_New']])\n",
    "    encoded_df = pd.DataFrame(encoded.toarray(), columns=encoder.get_feature_names_out(['WHOQOL_Físico_New']))\n",
    "    dataframe = dataframe.join(encoded_df)\n",
    "else:\n",
    "    # Aplicando normalização ou padronização para variáveis numéricas\n",
    "    scaler = StandardScaler()\n",
    "    if dataframe['WHOQOL_Físico_New'].count() >= 2:\n",
    "        dataframe['WHOQOL_Físico_New'] = scaler.fit_transform(dataframe[['WHOQOL_Físico_New']])\n",
    "    else:\n",
    "        # Lide com o caso de ter apenas uma linha ou todos os valores NaN\n",
    "        dataframe['WHOQOL_Físico_New'] = dataframe['WHOQOL_Físico_New'].fillna(0)\n",
    "\n",
    "# Calculando o intervalo interquartil\n",
    "Q1 = dataframe['WHOQOL_Físico_New'].quantile(0.25)\n",
    "Q3 = dataframe['WHOQOL_Físico_New'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Removendo os outliers\n",
    "dataframe = dataframe[(dataframe['WHOQOL_Físico_New'] >= Q1 - 1.5 * IQR) & (dataframe['WHOQOL_Físico_New'] <= Q3 + 1.5 * IQR)]\n",
    "\n",
    "\n",
    "\n",
    "# Verificando se é categórica ou numérica\n",
    "if dataframe['WHOQOL_Psicológico_New'].dtype == 'object':\n",
    "    # Aplicando codificação one-hot para variáveis categóricas\n",
    "    encoder = OneHotEncoder()\n",
    "    encoded = encoder.fit_transform(dataframe[['WHOQOL_Psicológico_New']])\n",
    "    encoded_df = pd.DataFrame(encoded.toarray(), columns=encoder.get_feature_names_out(['WHOQOL_Psicológico_New']))\n",
    "    dataframe = dataframe.join(encoded_df)\n",
    "else:\n",
    "    # Aplicando normalização ou padronização para variáveis numéricas\n",
    "    scaler = StandardScaler()\n",
    "    if dataframe['WHOQOL_Psicológico_New'].count() >= 2:\n",
    "        dataframe['WHOQOL_Psicológico_New'] = scaler.fit_transform(dataframe[['WHOQOL_Psicológico_New']])\n",
    "    else:\n",
    "        # Lide com o caso de ter apenas uma linha ou todos os valores NaN\n",
    "        dataframe['WHOQOL_Psicológico_New'] = dataframe['WHOQOL_Psicológico_New'].fillna(0)\n",
    "\n",
    "    # Calculando o intervalo interquartil\n",
    "    Q1 = dataframe['WHOQOL_Psicológico_New'].quantile(0.25)\n",
    "    Q3 = dataframe['WHOQOL_Psicológico_New'].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "\n",
    "    # Removendo os outliers\n",
    "    dataframe = dataframe[(dataframe['WHOQOL_Psicológico_New'] >= Q1 - 1 * IQR) & (dataframe['WHOQOL_Psicológico_New'] <= Q3 + 1 * IQR)]\n",
    "\n",
    "# Verificando se é categórica ou numérica\n",
    "if dataframe['WHOQOL_Social_New'].dtype == 'object':\n",
    "    # Aplicando codificação one-hot para variáveis categóricas\n",
    "    encoder = OneHotEncoder()\n",
    "    encoded = encoder.fit_transform(dataframe[['WHOQOL_Social_New']])\n",
    "    encoded_df = pd.DataFrame(encoded.toarray(), columns=encoder.get_feature_names_out(['WHOQOL_Social_New']))\n",
    "    data = data.join(encoded_df)\n",
    "else:\n",
    "    # Aplicando normalização ou padronização para variáveis numéricas\n",
    "    scaler = StandardScaler()\n",
    "    if dataframe['WHOQOL_Social_New'].count() >= 2:\n",
    "        dataframe['WHOQOL_Social_New'] = scaler.fit_transform(dataframe[['WHOQOL_Social_New']])\n",
    "    else:\n",
    "        # Lide com o caso de ter apenas uma linha ou todos os valores NaN\n",
    "        dataframe['WHOQOL_Social_New'] = dataframe['WHOQOL_Social_New'].fillna(0)\n",
    "\n",
    "Q1 = dataframe['WHOQOL_Social_New'].quantile(0.25)\n",
    "Q3 = dataframe['WHOQOL_Social_New'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Removendo os outliers\n",
    "dataframe = dataframe[(dataframe['WHOQOL_Social_New'] >= Q1 - 1 * IQR) & (dataframe['WHOQOL_Social_New'] <= Q3 + 1 * IQR)]\n",
    "\n",
    "dataframe = pd.get_dummies(dataframe, columns=['last_stage_concluded'], prefix='stage')\n",
    "\n",
    "dataframe.to_csv('../notebooks/data/data-engineering.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PESSOA_PIPEDRIVE_id_person</th>\n",
       "      <th>PESSOA_PIPEDRIVE_id_gender</th>\n",
       "      <th>PESSOA_PIPEDRIVE_id_marrital_status</th>\n",
       "      <th>PESSOA_PIPEDRIVE_state</th>\n",
       "      <th>PESSOA_PIPEDRIVE_city</th>\n",
       "      <th>PESSOA_PIPEDRIVE_postal_code</th>\n",
       "      <th>PESSOA_PIPEDRIVE_contract_start_date</th>\n",
       "      <th>PESSOA_PIPEDRIVE_contract_end_date</th>\n",
       "      <th>PESSOA_PIPEDRIVE_Canal de Preferência</th>\n",
       "      <th>PESSOA_PIPEDRIVE_notes_count</th>\n",
       "      <th>...</th>\n",
       "      <th>WHOQOL_Psicológico_New</th>\n",
       "      <th>WHOQOL_Social_New</th>\n",
       "      <th>WHOQOL_Ambiental_New</th>\n",
       "      <th>COMUNICARE_Problemas Abertos Bool</th>\n",
       "      <th>TWILIO_Data Última Mensagens Inbound Recente</th>\n",
       "      <th>stay_time</th>\n",
       "      <th>last_stage_concluded</th>\n",
       "      <th>process_time</th>\n",
       "      <th>TWILIO_Data Última Mensagens Outbound Recente</th>\n",
       "      <th>TWILIO_Data Última Ligações Outbound Recente</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1080</td>\n",
       "      <td>63</td>\n",
       "      <td>80</td>\n",
       "      <td>Pernambuco</td>\n",
       "      <td>Recife</td>\n",
       "      <td>50070-045</td>\n",
       "      <td>2021-07-19</td>\n",
       "      <td>2023-08-18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>1.7</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>737 days</td>\n",
       "      <td>Questionário</td>\n",
       "      <td>2022-04-18 15:07:13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   PESSOA_PIPEDRIVE_id_person  PESSOA_PIPEDRIVE_id_gender  \\\n",
       "0                        1080                          63   \n",
       "\n",
       "   PESSOA_PIPEDRIVE_id_marrital_status PESSOA_PIPEDRIVE_state  \\\n",
       "0                                   80             Pernambuco   \n",
       "\n",
       "  PESSOA_PIPEDRIVE_city PESSOA_PIPEDRIVE_postal_code  \\\n",
       "0                Recife                    50070-045   \n",
       "\n",
       "  PESSOA_PIPEDRIVE_contract_start_date PESSOA_PIPEDRIVE_contract_end_date  \\\n",
       "0                           2021-07-19                         2023-08-18   \n",
       "\n",
       "   PESSOA_PIPEDRIVE_Canal de Preferência  PESSOA_PIPEDRIVE_notes_count  ...  \\\n",
       "0                                    0.0                             5  ...   \n",
       "\n",
       "   WHOQOL_Psicológico_New  WHOQOL_Social_New  WHOQOL_Ambiental_New  \\\n",
       "0                     1.7                4.0                   3.5   \n",
       "\n",
       "  COMUNICARE_Problemas Abertos Bool  \\\n",
       "0                                 1   \n",
       "\n",
       "  TWILIO_Data Última Mensagens Inbound Recente stay_time last_stage_concluded  \\\n",
       "0                                            0  737 days         Questionário   \n",
       "\n",
       "          process_time TWILIO_Data Última Mensagens Outbound Recente  \\\n",
       "0  2022-04-18 15:07:13                                             0   \n",
       "\n",
       "  TWILIO_Data Última Ligações Outbound Recente  \n",
       "0                                            0  \n",
       "\n",
       "[1 rows x 51 columns]"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.read_csv(\"../notebooks/data/data-preprocessed.csv\")\n",
    "\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"../notebooks/data/data-engineering.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "single positional indexer is out-of-bounds",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/st4pzz/Desktop/insper_2023.2/SPRINT/sprint4-support-vector-team/src/scripts/teste.ipynb Célula 17\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/st4pzz/Desktop/insper_2023.2/SPRINT/sprint4-support-vector-team/src/scripts/teste.ipynb#X33sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m data \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(df\u001b[39m.\u001b[39;49miloc[\u001b[39m50\u001b[39;49m])\n",
      "File \u001b[0;32m~/Desktop/insper_2023.2/SPRINT/sprint4-support-vector-team/env/lib/python3.9/site-packages/pandas/core/indexing.py:1153\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1150\u001b[0m axis \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxis \u001b[39mor\u001b[39;00m \u001b[39m0\u001b[39m\n\u001b[1;32m   1152\u001b[0m maybe_callable \u001b[39m=\u001b[39m com\u001b[39m.\u001b[39mapply_if_callable(key, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj)\n\u001b[0;32m-> 1153\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem_axis(maybe_callable, axis\u001b[39m=\u001b[39;49maxis)\n",
      "File \u001b[0;32m~/Desktop/insper_2023.2/SPRINT/sprint4-support-vector-team/env/lib/python3.9/site-packages/pandas/core/indexing.py:1714\u001b[0m, in \u001b[0;36m_iLocIndexer._getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1711\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCannot index by location index with a non-integer key\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1713\u001b[0m \u001b[39m# validate the location\u001b[39;00m\n\u001b[0;32m-> 1714\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_integer(key, axis)\n\u001b[1;32m   1716\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_ixs(key, axis\u001b[39m=\u001b[39maxis)\n",
      "File \u001b[0;32m~/Desktop/insper_2023.2/SPRINT/sprint4-support-vector-team/env/lib/python3.9/site-packages/pandas/core/indexing.py:1647\u001b[0m, in \u001b[0;36m_iLocIndexer._validate_integer\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1645\u001b[0m len_axis \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_get_axis(axis))\n\u001b[1;32m   1646\u001b[0m \u001b[39mif\u001b[39;00m key \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m len_axis \u001b[39mor\u001b[39;00m key \u001b[39m<\u001b[39m \u001b[39m-\u001b[39mlen_axis:\n\u001b[0;32m-> 1647\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mIndexError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39msingle positional indexer is out-of-bounds\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mIndexError\u001b[0m: single positional indexer is out-of-bounds"
     ]
    }
   ],
   "source": [
    "data = pd.DataFrame(df.iloc[50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'preprocessing' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/st4pzz/Desktop/insper_2023.2/SPRINT/sprint4-support-vector-team/src/scripts/teste.ipynb Célula 14\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/st4pzz/Desktop/insper_2023.2/SPRINT/sprint4-support-vector-team/src/scripts/teste.ipynb#X34sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m preprocessing(data)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'preprocessing' is not defined"
     ]
    }
   ],
   "source": [
    "preprocessing(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PESSOA_PIPEDRIVE_notes_count</th>\n",
       "      <th>PESSOA_PIPEDRIVE_done_activities_count</th>\n",
       "      <th>FUNIL_ONBOARDING_PIPEDRIVE_activities_count</th>\n",
       "      <th>ATENDIMENTOS_AGENDA_Faltas Todos Atendimento</th>\n",
       "      <th>ATENDIMENTOS_AGENDA_Qde Atendimento Médico</th>\n",
       "      <th>ATENDIMENTOS_AGENDA_Faltas Atendimento Médico</th>\n",
       "      <th>ATENDIMENTOS_AGENDA_Qde Atendimentos Acolhimento</th>\n",
       "      <th>ATENDIMENTOS_AGENDA_Faltas Acolhimento</th>\n",
       "      <th>ATENDIMENTOS_AGENDA_Qde Psicoterapia</th>\n",
       "      <th>ATENDIMENTOS_AGENDA_Qde Prescrições</th>\n",
       "      <th>...</th>\n",
       "      <th>FUNIL_ASSINATURA_PIPEDRIVE_id_stage Binário</th>\n",
       "      <th>Status_80</th>\n",
       "      <th>Estado_Santa Catarina</th>\n",
       "      <th>PESSOA_PIPEDRIVE_city Codificada</th>\n",
       "      <th>status_lost</th>\n",
       "      <th>lost_reason_Outro</th>\n",
       "      <th>canal_preferencia_0</th>\n",
       "      <th>Status_lost</th>\n",
       "      <th>lost_reason_Outro.1</th>\n",
       "      <th>stage_Boas-vindas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   PESSOA_PIPEDRIVE_notes_count  PESSOA_PIPEDRIVE_done_activities_count  \\\n",
       "0                             0                                       0   \n",
       "\n",
       "   FUNIL_ONBOARDING_PIPEDRIVE_activities_count  \\\n",
       "0                                            0   \n",
       "\n",
       "   ATENDIMENTOS_AGENDA_Faltas Todos Atendimento  \\\n",
       "0                                             0   \n",
       "\n",
       "   ATENDIMENTOS_AGENDA_Qde Atendimento Médico  \\\n",
       "0                                           0   \n",
       "\n",
       "   ATENDIMENTOS_AGENDA_Faltas Atendimento Médico  \\\n",
       "0                                              0   \n",
       "\n",
       "   ATENDIMENTOS_AGENDA_Qde Atendimentos Acolhimento  \\\n",
       "0                                                 0   \n",
       "\n",
       "   ATENDIMENTOS_AGENDA_Faltas Acolhimento  \\\n",
       "0                                       0   \n",
       "\n",
       "   ATENDIMENTOS_AGENDA_Qde Psicoterapia  ATENDIMENTOS_AGENDA_Qde Prescrições  \\\n",
       "0                                     0                                  0.0   \n",
       "\n",
       "   ...  FUNIL_ASSINATURA_PIPEDRIVE_id_stage Binário  Status_80  \\\n",
       "0  ...                                            0       True   \n",
       "\n",
       "   Estado_Santa Catarina  PESSOA_PIPEDRIVE_city Codificada  status_lost  \\\n",
       "0                   True                                 1         True   \n",
       "\n",
       "   lost_reason_Outro  canal_preferencia_0  Status_lost  lost_reason_Outro.1  \\\n",
       "0               True                 True         True                 True   \n",
       "\n",
       "   stage_Boas-vindas  \n",
       "0               True  \n",
       "\n",
       "[1 rows x 48 columns]"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEU RUIM\n"
     ]
    }
   ],
   "source": [
    "df_pimba = preprocessing(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data-engineering.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/st4pzz/Desktop/insper_2023.2/SPRINT/sprint4-support-vector-team/src/scripts/teste.ipynb Célula 16\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/st4pzz/Desktop/insper_2023.2/SPRINT/sprint4-support-vector-team/src/scripts/teste.ipynb#W3sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39m\"\u001b[39;49m\u001b[39mdata-engineering.csv\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m~/Desktop/insper_2023.2/SPRINT/sprint4-support-vector-team/env/lib/python3.9/site-packages/pandas/io/parsers/readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    944\u001b[0m     dtype_backend\u001b[39m=\u001b[39mdtype_backend,\n\u001b[1;32m    945\u001b[0m )\n\u001b[1;32m    946\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 948\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/Desktop/insper_2023.2/SPRINT/sprint4-support-vector-team/env/lib/python3.9/site-packages/pandas/io/parsers/readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    608\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m    610\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 611\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    613\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[1;32m    614\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/Desktop/insper_2023.2/SPRINT/sprint4-support-vector-team/env/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1445\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m   1447\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1448\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[0;32m~/Desktop/insper_2023.2/SPRINT/sprint4-support-vector-team/env/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1703\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode:\n\u001b[1;32m   1704\u001b[0m         mode \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m-> 1705\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[1;32m   1706\u001b[0m     f,\n\u001b[1;32m   1707\u001b[0m     mode,\n\u001b[1;32m   1708\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1709\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1710\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[1;32m   1711\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[1;32m   1712\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1713\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1714\u001b[0m )\n\u001b[1;32m   1715\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1716\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/Desktop/insper_2023.2/SPRINT/sprint4-support-vector-team/env/lib/python3.9/site-packages/pandas/io/common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    858\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    859\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    860\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[1;32m    862\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[0;32m--> 863\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[1;32m    864\u001b[0m             handle,\n\u001b[1;32m    865\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[1;32m    866\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[1;32m    867\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[1;32m    868\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    869\u001b[0m         )\n\u001b[1;32m    870\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    871\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[1;32m    872\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data-engineering.csv'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"data-engineering.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'FUNIL_ASSINATURA_PIPEDRIVE_id_stage'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/Desktop/insper_2023.2/SPRINT/sprint4-support-vector-team/env/lib/python3.9/site-packages/pandas/core/indexes/base.py:3790\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3789\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3790\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   3791\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:152\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:181\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'FUNIL_ASSINATURA_PIPEDRIVE_id_stage'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/Users/st4pzz/Desktop/insper_2023.2/SPRINT/sprint4-support-vector-team/src/scripts/teste.ipynb Célula 5\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/st4pzz/Desktop/insper_2023.2/SPRINT/sprint4-support-vector-team/src/scripts/teste.ipynb#X24sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m df[\u001b[39m\"\u001b[39;49m\u001b[39mFUNIL_ASSINATURA_PIPEDRIVE_id_stage\u001b[39;49m\u001b[39m\"\u001b[39;49m]\u001b[39m.\u001b[39mvalue_counts()\n",
      "File \u001b[0;32m~/Desktop/insper_2023.2/SPRINT/sprint4-support-vector-team/env/lib/python3.9/site-packages/pandas/core/frame.py:3893\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3891\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   3892\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3893\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[1;32m   3894\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3895\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/Desktop/insper_2023.2/SPRINT/sprint4-support-vector-team/env/lib/python3.9/site-packages/pandas/core/indexes/base.py:3797\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3792\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(casted_key, \u001b[39mslice\u001b[39m) \u001b[39mor\u001b[39;00m (\n\u001b[1;32m   3793\u001b[0m         \u001b[39misinstance\u001b[39m(casted_key, abc\u001b[39m.\u001b[39mIterable)\n\u001b[1;32m   3794\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39many\u001b[39m(\u001b[39misinstance\u001b[39m(x, \u001b[39mslice\u001b[39m) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m casted_key)\n\u001b[1;32m   3795\u001b[0m     ):\n\u001b[1;32m   3796\u001b[0m         \u001b[39mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3797\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3798\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3799\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3800\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3801\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3802\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'FUNIL_ASSINATURA_PIPEDRIVE_id_stage'"
     ]
    }
   ],
   "source": [
    "df[\"FUNIL_ASSINATURA_PIPEDRIVE_id_stage\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PESSOA_PIPEDRIVE_Canal de Preferência\n",
       "0      571\n",
       "239    379\n",
       "238     12\n",
       "360     11\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"PESSOA_PIPEDRIVE_Canal de Preferência\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Estado_Mato Grosso do Sul</th>\n",
       "      <th>Estado_Minas Gerais</th>\n",
       "      <th>Estado_Paraná</th>\n",
       "      <th>Estado_Paraíba</th>\n",
       "      <th>Estado_Pará</th>\n",
       "      <th>Estado_Pernambuco</th>\n",
       "      <th>Estado_Piauí</th>\n",
       "      <th>Estado_Rio Grande do Norte</th>\n",
       "      <th>Estado_Rio Grande do Sul</th>\n",
       "      <th>Estado_Rio de Janeiro</th>\n",
       "      <th>Estado_Santa Catarina</th>\n",
       "      <th>Estado_Sergipe</th>\n",
       "      <th>Estado_State of Amazonas</th>\n",
       "      <th>Estado_São Paulo</th>\n",
       "      <th>PESSOA_PIPEDRIVE_city Codificada</th>\n",
       "      <th>status_lost</th>\n",
       "      <th>status_won</th>\n",
       "      <th>lost_reason_Outro</th>\n",
       "      <th>lost_reason_[Assinatura] Cancelamento por inadimplência</th>\n",
       "      <th>lost_reason_[Assinatura] Desligamento</th>\n",
       "      <th>lost_reason_[Assinatura] Empresa cancelou o benefício da Ana</th>\n",
       "      <th>lost_reason_[Assinatura] Está sem tempo para conciliar os atendimentos</th>\n",
       "      <th>lost_reason_[Assinatura] Não quer seguir com a Ana</th>\n",
       "      <th>lost_reason_[Assinatura] Precisou cortar custos</th>\n",
       "      <th>Status_Não iniciado</th>\n",
       "      <th>Status_lost</th>\n",
       "      <th>Status_open</th>\n",
       "      <th>Status_won</th>\n",
       "      <th>lost_reason_Outro.1</th>\n",
       "      <th>lost_reason_[Associade] Cancelou assinatura</th>\n",
       "      <th>lost_reason_[Onboarding] Não retornou aos contatos de resgate</th>\n",
       "      <th>lost_reason_[Onboarding] Não tem interesse em seguir nas etapas do onboarding</th>\n",
       "      <th>stage_Boas-vindas</th>\n",
       "      <th>stage_Não iniciado</th>\n",
       "      <th>stage_Primeira reunião</th>\n",
       "      <th>stage_Questionário</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>32</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>32</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Estado_Mato Grosso do Sul  ...  stage_Questionário\n",
       "0                      False  ...                True\n",
       "1                      False  ...                True\n",
       "2                      False  ...                True\n",
       "3                      False  ...                True\n",
       "4                      False  ...                True\n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[:,60:].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "\n",
    "def column_label_to_index(col_label):\n",
    "    col_index = 0\n",
    "    for c in col_label.upper():\n",
    "        col_index = col_index * 26 + (ord(c) - ord('A') + 1)\n",
    "    return col_index - 1\n",
    "\n",
    "def add_prefix_to_columns(dataframe, prefix):\n",
    "    for col in dataframe.columns:\n",
    "        new_col_name = prefix + str(col)\n",
    "        dataframe.rename(columns={col: new_col_name}, inplace=True)\n",
    "\n",
    "\n",
    "def mergeHeader_Columns(data):\n",
    "    add_prefix_to_columns(data, 'PESSOA_PIPEDRIVE_')\n",
    "    add_prefix_to_columns(data, 'FUNIL_ASSINATURA_PIPEDRIVE_')\n",
    "    add_prefix_to_columns(data, 'FUNIL_ONBOARDING_PIPEDRIVE_')\n",
    "    add_prefix_to_columns(data, 'ATENDIMENTOS_AGENDA_')\n",
    "    add_prefix_to_columns(data, 'WHOQOL_')\n",
    "    add_prefix_to_columns(data, 'COMUNICARE_')\n",
    "    add_prefix_to_columns(data, 'TWILIO_')\n",
    "    add_prefix_to_columns(data, 'COBRANÇA_VINDI_')\n",
    "\n",
    "    return data\n",
    "\n",
    "def preprocessing(data_dataframe):\n",
    "    from sklearn.impute import SimpleImputer\n",
    "\n",
    "    # try:\n",
    "    data_dataframe = mergeHeader_Columns(data_dataframe)\n",
    "    data_dataframe = pd.DataFrame(data_dataframe.iloc[50])\n",
    "    # preprocessing 1\n",
    "    data_dataframe = data_dataframe.drop([\"PESSOA_PIPEDRIVE_id_person_recommendation\",\"PESSOA_PIPEDRIVE_Recebe Comunicados?\", \"PESSOA_PIPEDRIVE_Interesses\", \"PESSOA_PIPEDRIVE_Pontos de Atenção\", \"FUNIL_ONBOARDING_PIPEDRIVE_id_label\"], axis=1)\n",
    "\n",
    "    data_dataframe['PESSOA_PIPEDRIVE_birthdate'] = pd.to_datetime(data_dataframe['PESSOA_PIPEDRIVE_birthdate'])\n",
    "    data_dataframe['PESSOA_PIPEDRIVE_age'] = data_dataframe['PESSOA_PIPEDRIVE_birthdate'].apply(\n",
    "        lambda x: datetime.today().year - x.year - ((datetime.today().month, datetime.today().day) < (x.month, x.day))\n",
    "    )\n",
    "\n",
    "    imputer = SimpleImputer(strategy='mean')\n",
    "    data_dataframe['PESSOA_PIPEDRIVE_age'] = imputer.fit_transform(data_dataframe['PESSOA_PIPEDRIVE_age'].values.reshape(-1, 1))\n",
    "    data_dataframe['PESSOA_PIPEDRIVE_age'] = np.round(data_dataframe['PESSOA_PIPEDRIVE_age']).astype(int)\n",
    "\n",
    "    data_dataframe = data_dataframe.drop(['PESSOA_PIPEDRIVE_birthdate'], axis=1 )\n",
    "\n",
    "    rows_to_drop = data_dataframe[data_dataframe[\"PESSOA_PIPEDRIVE_id_gender\"].isin([117,110,111])]\n",
    "    data_dataframe = data_dataframe.drop(rows_to_drop.index, axis=0)\n",
    "    data_dataframe[\"PESSOA_PIPEDRIVE_id_gender\"].fillna(64, inplace=True)\n",
    "    data_dataframe[\"PESSOA_PIPEDRIVE_id_marrital_status\"].fillna(80, inplace=True)\n",
    "\n",
    "    \n",
    "    data_dataframe[\"PESSOA_PIPEDRIVE_state\"].fillna(data_dataframe[\"PESSOA_PIPEDRIVE_state\"].mode()[0], inplace=True)\n",
    "\n",
    "\n",
    "    data_dataframe[\"PESSOA_PIPEDRIVE_city\"].fillna(data_dataframe[\"PESSOA_PIPEDRIVE_city\"].mode()[0], inplace=True)\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    if data_dataframe.shape[0] == 1 and data_dataframe['PESSOA_PIPEDRIVE_id_health_plan'].isna().any():\n",
    "        data_dataframe['PESSOA_PIPEDRIVE_id_health_plan'].fillna(data_dataframe['PESSOA_PIPEDRIVE_id_health_plan'].mode()[0], inplace=True)\n",
    "    data_dataframe['PESSOA_PIPEDRIVE_has_public_health_plan'] = data_dataframe['PESSOA_PIPEDRIVE_id_health_plan'].apply(lambda x: 1 if int(x) == 412 else 0)\n",
    "    data_dataframe = data_dataframe.drop(['PESSOA_PIPEDRIVE_id_health_plan'], axis=1)\n",
    "    data_dataframe[\"PESSOA_PIPEDRIVE_tem_data_dataframe_de_termino_de_contrato\"] = data_dataframe[\"PESSOA_PIPEDRIVE_contract_end_date\"].apply(lambda x: 0 if pd.isna(x) else 1)\n",
    "    data_dataframe.drop([\"PESSOA_PIPEDRIVE_id_continuity_pf\"], axis=1, inplace=True)\n",
    "    data_dataframe[\"PESSOA_PIPEDRIVE_Canal de Preferência\"].fillna(0, inplace=True)\n",
    "    data_dataframe[\"PESSOA_PIPEDRIVE_Tem_Canal_de_Preferência\"] = data_dataframe[\"PESSOA_PIPEDRIVE_Canal de Preferência\"].apply(lambda x: 1 if int(x) > 0  else 0)\n",
    "    data_dataframe[\"PESSOA_PIPEDRIVE_has_notes\"] = data_dataframe[\"PESSOA_PIPEDRIVE_notes_count\"].apply(lambda x: 1 if int(x) > 0 else 0)\n",
    "    \n",
    "    # preprocessing 2\n",
    "    data_dataframe = data_dataframe.drop([\"ATENDIMENTOS_AGENDA_Faltas Psicoterapia\",\"TWILIO_Ligações Inbound\", \"TWILIO_Data Última Ligações Inbound\",\"COBRANÇA_VINDI_Qde Total de Faturas\",\"COBRANÇA_VINDI_Qde Total de Tentativas de Cobrança\",\"COBRANÇA_VINDI_Método de Pagamento\",\"COBRANÇA_VINDI_Valor Médio da Mensalidade\",\"COBRANÇA_VINDI_Qde Total de Faturas Pagas após Vencimento\",\"COBRANÇA_VINDI_Qde Total de Faturas Inadimpletes\",\"COBRANÇA_VINDI_Valor Total Inadimplência\"], axis=1)\n",
    "\n",
    "    data_dataframe[\"ATENDIMENTOS_AGENDA_Qde Psicoterapia\"].fillna(0, inplace=True)\n",
    "    \n",
    "\n",
    "\n",
    "    data_dataframe = data_dataframe.drop(columns=\"WHOQOL_Qde Respostas WHOQOL\")\n",
    "\n",
    "    data_dataframe[\"WHOQOL_Físico_New\"] = data_dataframe[\"WHOQOL_Físico\"].str.split(';').str[-1].str.strip()\n",
    "\n",
    "    data_dataframe[\"WHOQOL_Físico_New\"] = data_dataframe[\"WHOQOL_Físico_New\"].str.replace(\",\",\".\")\n",
    "\n",
    "    data_dataframe[\"WHOQOL_Físico_New\"] = data_dataframe[\"WHOQOL_Físico_New\"].astype(float) \n",
    "\n",
    "    data_dataframe[\"WHOQOL_Físico_New\"] = data_dataframe[\"WHOQOL_Físico_New\"].fillna(data_dataframe[\"WHOQOL_Físico_New\"].median())\n",
    "\n",
    "    data_dataframe[\"WHOQOL_Psicológico_New\"] = data_dataframe[\"WHOQOL_Psicológico\"].str.split(';').str[-1].str.strip()\n",
    "\n",
    "    data_dataframe[\"WHOQOL_Psicológico_New\"] = data_dataframe[\"WHOQOL_Psicológico_New\"].str.replace(\",\",\".\")\n",
    "\n",
    "    data_dataframe[\"WHOQOL_Psicológico_New\"] = data_dataframe[\"WHOQOL_Psicológico_New\"].astype(float) \n",
    "\n",
    "    data_dataframe[\"WHOQOL_Psicológico_New\"] = data_dataframe[\"WHOQOL_Psicológico_New\"].fillna(data_dataframe[\"WHOQOL_Psicológico_New\"].median())\n",
    "\n",
    "    data_dataframe[\"WHOQOL_Social_New\"] = data_dataframe[\"WHOQOL_Social\"].str.split(';').str[-1].str.strip()\n",
    "\n",
    "    data_dataframe[\"WHOQOL_Social_New\"] = data_dataframe[\"WHOQOL_Social_New\"].str.replace(\",\",\".\")\n",
    "\n",
    "    data_dataframe[\"WHOQOL_Social_New\"] = data_dataframe[\"WHOQOL_Social_New\"].astype(float) \n",
    "\n",
    "    data_dataframe[\"WHOQOL_Social_New\"] = data_dataframe[\"WHOQOL_Social_New\"].fillna(data_dataframe[\"WHOQOL_Social_New\"].median())\n",
    "\n",
    "    data_dataframe[\"WHOQOL_Ambiental_New\"] = data_dataframe[\"WHOQOL_Ambiental\"].str.split(';').str[-1].str.strip()\n",
    "\n",
    "    data_dataframe[\"WHOQOL_Ambiental_New\"] = data_dataframe[\"WHOQOL_Ambiental_New\"].str.replace(\",\",\".\")\n",
    "\n",
    "    data_dataframe[\"WHOQOL_Ambiental_New\"] = data_dataframe[\"WHOQOL_Ambiental_New\"].astype(float) \n",
    "\n",
    "    data_dataframe[\"WHOQOL_Ambiental_New\"] = data_dataframe[\"WHOQOL_Ambiental_New\"].fillna(data_dataframe[\"WHOQOL_Ambiental_New\"].median())\n",
    "\n",
    "    data_dataframe[\"COMUNICARE_Problemas Abertos Bool\"] = data_dataframe[\"COMUNICARE_Problemas Abertos\"].notnull().astype(int)\n",
    "\n",
    "    data_dataframe[\"COMUNICARE_Problemas Abertos Bool\"].fillna(0, inplace=True)\n",
    "\n",
    "    data_dataframe[\"TWILIO_Mensagens Inbound\"].fillna(0, inplace=True)\n",
    "\n",
    "    data_dataframe[\"TWILIO_Data Última Mensagens Inbound\"] = pd.to_datetime(data_dataframe[\"TWILIO_Data Última Mensagens Inbound\"])\n",
    "\n",
    "    data_dataframe[\"TWILIO_Data Última Mensagens Inbound Tempo Passado\"] = datetime.now() - data_dataframe[\"TWILIO_Data Última Mensagens Inbound\"]\n",
    "\n",
    "    data_dataframe[\"TWILIO_Data Última Mensagens Inbound Tempo Passado\"].fillna('', inplace=True)\n",
    "\n",
    "    data_dataframe[\"TWILIO_Data Última Mensagens Inbound Tempo Passado\"] = data_dataframe[\"TWILIO_Data Última Mensagens Inbound Tempo Passado\"].astype(str)\n",
    "\n",
    "    data_dataframe[\"TWILIO_Data Última Mensagens Inbound Tempo Passado\"] = data_dataframe[\"TWILIO_Data Última Mensagens Inbound Tempo Passado\"].str.extract('(\\d+) days').astype(float)\n",
    "\n",
    "    data_dataframe[\"TWILIO_Data Última Mensagens Inbound Recente\"] = data_dataframe[\"TWILIO_Data Última Mensagens Inbound Tempo Passado\"] < data_dataframe[\"TWILIO_Data Última Mensagens Inbound Tempo Passado\"].median()\n",
    "    data_dataframe[\"TWILIO_Data Última Mensagens Inbound Recente\"].fillna(0)\n",
    "    data_dataframe[\"TWILIO_Data Última Mensagens Inbound Recente\"].replace(True, 1, inplace=True)\n",
    "    data_dataframe[\"TWILIO_Data Última Mensagens Inbound Recente\"].replace(False, 0, inplace=True)\n",
    "\n",
    "    data_dataframe = data_dataframe.drop(columns=[\"WHOQOL_Ambiental\",\"WHOQOL_Social\",\"WHOQOL_Físico\",\"WHOQOL_Psicológico\",\"COMUNICARE_Problemas Abertos\",\"TWILIO_Data Última Mensagens Inbound\",\"ATENDIMENTOS_AGENDA_Datas Psicoterapia\",\"TWILIO_Data Última Mensagens Inbound Tempo Passado\"])\n",
    "    \n",
    "    # preprocessing 3\n",
    "    for indice, valor in data_dataframe[\"FUNIL_ASSINATURA_PIPEDRIVE_lost_time\"].items():\n",
    "        if pd.notna(valor) == False: \n",
    "            if pd.notna(data_dataframe.loc[indice, \"PESSOA_PIPEDRIVE_contract_end_date\"]):\n",
    "                data_dataframe.loc[indice, \"FUNIL_ASSINATURA_PIPEDRIVE_lost_time\"] = data_dataframe.loc[indice, \"PESSOA_PIPEDRIVE_contract_end_date\"]\n",
    "\n",
    "    data_dataframe[\"FUNIL_ASSINATURA_PIPEDRIVE_lost_time\"].fillna(dt.date.today(), inplace=True)\n",
    "\n",
    "    for indice, valor in data_dataframe[\"FUNIL_ASSINATURA_PIPEDRIVE_lost_time\"].items():\n",
    "        index = str(data_dataframe.loc[indice, \"FUNIL_ASSINATURA_PIPEDRIVE_lost_time\"]).find(\";\")\n",
    "        if index != -1:\n",
    "            data_dataframe.loc[indice, \"FUNIL_ASSINATURA_PIPEDRIVE_lost_time\"] = data_dataframe.loc[indice, \"FUNIL_ASSINATURA_PIPEDRIVE_lost_time\"][:index]\n",
    "\n",
    "    for indice, valor in data_dataframe[\"FUNIL_ASSINATURA_PIPEDRIVE_lost_time\"].items():\n",
    "        tamanho = len(str(data_dataframe.loc[indice, \"FUNIL_ASSINATURA_PIPEDRIVE_lost_time\"]))\n",
    "        if tamanho > 10:\n",
    "            data_dataframe.loc[indice, \"FUNIL_ASSINATURA_PIPEDRIVE_lost_time\"] = data_dataframe.loc[indice, \"FUNIL_ASSINATURA_PIPEDRIVE_lost_time\"][:10]\t\n",
    "\n",
    "    for indice, valor in data_dataframe[\"FUNIL_ASSINATURA_PIPEDRIVE_lost_time\"].items():\n",
    "        data_dataframe.loc[indice, \"FUNIL_ASSINATURA_PIPEDRIVE_lost_time\"] = pd.to_datetime(data_dataframe.loc[indice, \"FUNIL_ASSINATURA_PIPEDRIVE_lost_time\"], format='%Y-%m-%d', errors='coerce')\n",
    "        data_dataframe.loc[indice, \"FUNIL_ASSINATURA_PIPEDRIVE_lost_time\"] = data_dataframe.loc[indice, \"FUNIL_ASSINATURA_PIPEDRIVE_lost_time\"].strftime('%Y-%m-%d')\n",
    "\n",
    "    tempo_permanencia = []\n",
    "\n",
    "    for indice, valor in data_dataframe[\"FUNIL_ASSINATURA_PIPEDRIVE_start_of_service\"].items():\n",
    "        if pd.notna(valor):\n",
    "            index = data_dataframe.loc[indice, \"FUNIL_ASSINATURA_PIPEDRIVE_start_of_service\"].find(\";\")\n",
    "            if index != -1:\n",
    "                data_dataframe.loc[indice, \"FUNIL_ASSINATURA_PIPEDRIVE_start_of_service\"] = data_dataframe.loc[indice, \"FUNIL_ASSINATURA_PIPEDRIVE_start_of_service\"][:index]\n",
    "\n",
    "    for indice, valor in data_dataframe[\"FUNIL_ASSINATURA_PIPEDRIVE_lost_time\"].items():\n",
    "        if pd.notna(data_dataframe.loc[indice, \"FUNIL_ASSINATURA_PIPEDRIVE_start_of_service\"]):\n",
    "            tempo_1 = datetime.strptime(data_dataframe.loc[indice, \"FUNIL_ASSINATURA_PIPEDRIVE_lost_time\"], '%Y-%m-%d')\n",
    "            tempo_2 = datetime.strptime(data_dataframe.loc[indice, \"FUNIL_ASSINATURA_PIPEDRIVE_start_of_service\"], '%Y-%m-%d')\n",
    "            tempo_permanencia.append(str(tempo_1 - tempo_2))\n",
    "        else:\n",
    "            tempo_1 = datetime.strptime(data_dataframe.loc[indice, \"FUNIL_ASSINATURA_PIPEDRIVE_lost_time\"], '%Y-%m-%d')\n",
    "            tempo_2 = datetime.strptime(data_dataframe.loc[indice, \"PESSOA_PIPEDRIVE_contract_start_date\"], '%Y-%m-%d')\n",
    "            tempo_permanencia.append(str(tempo_1 - tempo_2))\n",
    "\n",
    "    data_dataframe['stay_time'] = tempo_permanencia\n",
    "\n",
    "    for indice, valor in data_dataframe[\"stay_time\"].items():\n",
    "        index = data_dataframe.loc[indice, \"stay_time\"].find(\",\")\n",
    "        if index != -1:\n",
    "            data_dataframe.loc[indice, \"stay_time\"] = data_dataframe.loc[indice, \"stay_time\"][:index]\n",
    "\n",
    "    for indice, valor in data_dataframe[\"FUNIL_ASSINATURA_PIPEDRIVE_lost_reason\"].items():\n",
    "        if pd.notna(valor):  \n",
    "            index = data_dataframe.loc[indice, \"FUNIL_ASSINATURA_PIPEDRIVE_lost_reason\"].find(\";\")\n",
    "            if index != -1: \n",
    "                data_dataframe.loc[indice, \"FUNIL_ASSINATURA_PIPEDRIVE_lost_reason\"] = data_dataframe.loc[indice, \"FUNIL_ASSINATURA_PIPEDRIVE_lost_reason\"][:index]\n",
    "        else:\n",
    "            data_dataframe.loc[indice, \"FUNIL_ASSINATURA_PIPEDRIVE_lost_reason\"] = \"Assinatura ativa\"\n",
    "            \n",
    "        contagem = data_dataframe[\"FUNIL_ASSINATURA_PIPEDRIVE_lost_reason\"].value_counts()\n",
    "\n",
    "        agrupamento = contagem[contagem < 20].index\n",
    "        data_dataframe.loc[data_dataframe[\"FUNIL_ASSINATURA_PIPEDRIVE_lost_reason\"].isin(agrupamento), \"FUNIL_ASSINATURA_PIPEDRIVE_lost_reason\"] = \"Outro\"\n",
    "\n",
    "    data_dataframe['FUNIL_ONBOARDING_PIPEDRIVE_add_time'].fillna('Não iniciado', inplace=True)\n",
    "\n",
    "    ultimos_estados = []\n",
    "\n",
    "    for indice, valor in data_dataframe[\"FUNIL_ONBOARDING_PIPEDRIVE_add_time\"].items():\n",
    "        if valor != \"Não iniciado\":\n",
    "            if pd.notna(data_dataframe.loc[indice, \"FUNIL_ONBOARDING_PIPEDRIVE_stay_in_pipeline_stages_welcome\"]):\n",
    "                if pd.notna(data_dataframe.loc[indice, \"FUNIL_ONBOARDING_PIPEDRIVE_stay_in_pipeline_stages_first_meeting\"]):\n",
    "                    if pd.notna(data_dataframe.loc[indice, \"FUNIL_ONBOARDING_PIPEDRIVE_stay_in_pipeline_stages_whoqol\"]):\n",
    "                        ultimos_estados.append(\"Questionário\")\n",
    "                    else:\n",
    "                        ultimos_estados.append(\"Primeira reunião\")\n",
    "                else:\n",
    "                    ultimos_estados.append(\"Boas-vindas\")\n",
    "            \n",
    "        else:\n",
    "            ultimos_estados.append(\"Não iniciado\")\n",
    "\n",
    "    data_dataframe[\"last_stage_concluded\"] = ultimos_estados\n",
    "\n",
    "    data_dataframe.drop([\"FUNIL_ONBOARDING_PIPEDRIVE_stay_in_pipeline_stages_welcome\", \"FUNIL_ONBOARDING_PIPEDRIVE_stay_in_pipeline_stages_first_meeting\", \"FUNIL_ONBOARDING_PIPEDRIVE_stay_in_pipeline_stages_whoqol\"], axis=1, inplace=True)\n",
    "\n",
    "    data_dataframe[\"FUNIL_ONBOARDING_PIPEDRIVE_status\"].fillna(\"Não iniciado\", inplace=True)\n",
    "\n",
    "    tempo = []\n",
    "\n",
    "    for indice, valor in data_dataframe[\"FUNIL_ONBOARDING_PIPEDRIVE_add_time\"].items():\n",
    "        if valor != \"Não iniciado\":\n",
    "            if pd.notna(data_dataframe.loc[indice, \"FUNIL_ONBOARDING_PIPEDRIVE_lost_time\"]) == True:\n",
    "                tempo.append(data_dataframe.loc[indice, \"FUNIL_ONBOARDING_PIPEDRIVE_lost_time\"])\n",
    "            elif pd.notna(data_dataframe.loc[indice, \"FUNIL_ONBOARDING_PIPEDRIVE_won_time\"]) == True:\n",
    "                tempo.append(data_dataframe.loc[indice, \"FUNIL_ONBOARDING_PIPEDRIVE_won_time\"])\n",
    "            else:\n",
    "                tempo.append(\"Em aberto\")\n",
    "        else:\n",
    "            tempo.append(\"Não iniciado\")\n",
    "\n",
    "    data_dataframe['process_time'] = tempo\n",
    "\n",
    "    data_dataframe.drop([\"FUNIL_ONBOARDING_PIPEDRIVE_won_time\", \"FUNIL_ONBOARDING_PIPEDRIVE_lost_time\"], axis=1, inplace=True)\n",
    "\n",
    "    data_dataframe[\"FUNIL_ONBOARDING_PIPEDRIVE_activities_count\"] = data_dataframe[\"FUNIL_ONBOARDING_PIPEDRIVE_activities_count\"].fillna(0)\n",
    "\n",
    "    data_dataframe[\"ATENDIMENTOS_AGENDA_Qde Atendimento Médico\"] = data_dataframe[\"ATENDIMENTOS_AGENDA_Qde Atendimento Médico\"].fillna(0)\n",
    "\n",
    "    data_dataframe[\"ATENDIMENTOS_AGENDA_Faltas Atendimento Médico\"] = data_dataframe[\"ATENDIMENTOS_AGENDA_Faltas Atendimento Médico\"].fillna(0)\n",
    "\n",
    "    data_dataframe[\"ATENDIMENTOS_AGENDA_Datas Atendimento Médico\"] = data_dataframe[\"ATENDIMENTOS_AGENDA_Datas Atendimento Médico\"].fillna(\"Nunca ocorreu\")\n",
    "\n",
    "    for indice, valor in data_dataframe[\"FUNIL_ONBOARDING_PIPEDRIVE_lost_reason\"].items():\n",
    "        if pd.notna(valor) == False:\n",
    "            if pd.notna(data_dataframe.loc[indice, \"FUNIL_ONBOARDING_PIPEDRIVE_status\"]) == False and pd.notna(data_dataframe.loc[indice, \"FUNIL_ONBOARDING_PIPEDRIVE_add_time\"]):\n",
    "                data_dataframe.loc[indice, \"FUNIL_ONBOARDING_PIPEDRIVE_lost_reason\"] = \"Processo em aberto\"\n",
    "            if data_dataframe.loc[indice, \"FUNIL_ONBOARDING_PIPEDRIVE_status\"] == \"won\":\n",
    "                data_dataframe.loc[indice, \"FUNIL_ONBOARDING_PIPEDRIVE_lost_reason\"] = \"Processo concluído\"\n",
    "            else:\n",
    "                data_dataframe.loc[indice, \"FUNIL_ONBOARDING_PIPEDRIVE_lost_reason\"] = \"Processo não iniciado\"\n",
    "\n",
    "        contagem = data_dataframe[\"FUNIL_ONBOARDING_PIPEDRIVE_lost_reason\"].value_counts()\n",
    "\n",
    "        agrupamento = contagem[contagem < 23].index\n",
    "        data_dataframe.loc[data_dataframe[\"FUNIL_ONBOARDING_PIPEDRIVE_lost_reason\"].isin(agrupamento), \"FUNIL_ONBOARDING_PIPEDRIVE_lost_reason\"] = \"Outro\"\n",
    "\n",
    "    data_dataframe[\"ATENDIMENTOS_AGENDA_Qde Atendimentos Acolhimento\"] = data_dataframe[\"ATENDIMENTOS_AGENDA_Qde Atendimentos Acolhimento\"].fillna(0)\n",
    "\n",
    "    data_dataframe[\"ATENDIMENTOS_AGENDA_Faltas Acolhimento\"] = data_dataframe[\"ATENDIMENTOS_AGENDA_Faltas Acolhimento\"].fillna(0)\n",
    "\n",
    "    data_dataframe[\"ATENDIMENTOS_AGENDA_Datas Acolhimento\"] = data_dataframe[\"ATENDIMENTOS_AGENDA_Datas Acolhimento\"].fillna(\"Nunca ocorreu\")\n",
    "\n",
    "    data_dataframe[\"ATENDIMENTOS_AGENDA_Qde Psicoterapia\"] = data_dataframe[\"ATENDIMENTOS_AGENDA_Qde Psicoterapia\"].fillna(0)\n",
    "\n",
    "    # preprocessing 4\n",
    "\n",
    "    data_dataframe[\"TWILIO_Mensagens Outbound\"].fillna(0, inplace=True)\n",
    "\n",
    "    data_dataframe[\"TWILIO_Data Última Mensagens Outbound\"] = pd.to_datetime(data_dataframe[\"TWILIO_Data Última Mensagens Outbound\"])\n",
    "\n",
    "    data_dataframe[\"TWILIO_Data Última Mensagens Outbound Tempo passado\"] = datetime.now() - data_dataframe[\"TWILIO_Data Última Mensagens Outbound\"]\n",
    "\n",
    "    data_dataframe[\"TWILIO_Data Última Mensagens Outbound Tempo passado\"].fillna('', inplace=True)\n",
    "    \n",
    "    data_dataframe[\"TWILIO_Data Última Mensagens Outbound Tempo passado\"] = data_dataframe[\"TWILIO_Data Última Mensagens Outbound Tempo passado\"].astype(str)\n",
    "\n",
    "    data_dataframe[\"TWILIO_Data Última Mensagens Outbound Tempo passado\"] = data_dataframe[\"TWILIO_Data Última Mensagens Outbound Tempo passado\"].str.extract('(\\d+) days').astype(float)\n",
    "\n",
    "    data_dataframe = data_dataframe.drop([\"TWILIO_Data Última Mensagens Outbound\"], axis=1)\n",
    "\n",
    "    data_dataframe[\"TWILIO_Data Última Mensagens Outbound Recente\"] = data_dataframe[\"TWILIO_Data Última Mensagens Outbound Tempo passado\"] < data_dataframe[\"TWILIO_Data Última Mensagens Outbound Tempo passado\"].median()\n",
    "    data_dataframe[\"TWILIO_Data Última Mensagens Outbound Recente\"].fillna(0)\n",
    "    data_dataframe[\"TWILIO_Data Última Mensagens Outbound Recente\"].replace(True, 1, inplace=True)\n",
    "    data_dataframe[\"TWILIO_Data Última Mensagens Outbound Recente\"].replace(False, 0, inplace=True)\n",
    "\n",
    "    data_dataframe = data_dataframe.drop([\"TWILIO_Data Última Mensagens Outbound Tempo passado\"], axis=1)\n",
    "\n",
    "    data_dataframe[\"TWILIO_Ligações Outbound\"].fillna(0, inplace=True)\n",
    "\n",
    "    data_dataframe[\"TWILIO_Data Última Ligações Outbound\"] = pd.to_datetime(data_dataframe[\"TWILIO_Data Última Ligações Outbound\"])\n",
    "\n",
    "    data_dataframe[\"TWILIO_Data Última Ligações Outbound Tempo passado\"] = datetime.now() - data_dataframe[\"TWILIO_Data Última Ligações Outbound\"]\n",
    "\n",
    "    data_dataframe[\"TWILIO_Data Última Ligações Outbound Tempo passado\"].fillna('', inplace=True)\n",
    "\n",
    "    data_dataframe[\"TWILIO_Data Última Ligações Outbound Tempo passado\"] = data_dataframe[\"TWILIO_Data Última Ligações Outbound Tempo passado\"].astype(str)\n",
    "\n",
    "    data_dataframe[\"TWILIO_Data Última Ligações Outbound Tempo passado\"] = data_dataframe[\"TWILIO_Data Última Ligações Outbound Tempo passado\"].str.extract('(\\d+) days').astype(float)\n",
    "\n",
    "    data_dataframe = data_dataframe.drop([\"TWILIO_Data Última Ligações Outbound\"], axis=1)\n",
    "\n",
    "    data_dataframe[\"TWILIO_Data Última Ligações Outbound Recente\"] = data_dataframe[\"TWILIO_Data Última Ligações Outbound Tempo passado\"] < data_dataframe[\"TWILIO_Data Última Ligações Outbound Tempo passado\"].median()\n",
    "    data_dataframe[\"TWILIO_Data Última Ligações Outbound Recente\"].fillna(0)\n",
    "    data_dataframe[\"TWILIO_Data Última Ligações Outbound Recente\"].replace(True, 1, inplace=True)\n",
    "    data_dataframe[\"TWILIO_Data Última Ligações Outbound Recente\"].replace(False, 0, inplace=True)\n",
    "\n",
    "    data_dataframe = data_dataframe.drop([\"TWILIO_Data Última Ligações Outbound Tempo passado\"], axis=1)\n",
    "\n",
    "    data_dataframe = data_dataframe.drop([\"COBRANÇA_VINDI_Qde Perfis de Pagamento Inativos\"], axis=1)\n",
    "\n",
    "    # preprocessing especials \n",
    "\n",
    "    data_dataframe = data_dataframe[data_dataframe['FUNIL_ASSINATURA_PIPEDRIVE_status'].isin(['won', 'lost'])]\n",
    "\n",
    "    data_dataframe = data_dataframe.drop(data_dataframe[(data_dataframe['FUNIL_ASSINATURA_PIPEDRIVE_status'] == 'won') & (~data_dataframe['PESSOA_PIPEDRIVE_contract_end_date'].isnull())].index)\n",
    "\n",
    "    data_dataframe = data_dataframe.drop(data_dataframe[(data_dataframe['FUNIL_ASSINATURA_PIPEDRIVE_status'] == 'lost') & (data_dataframe['PESSOA_PIPEDRIVE_contract_end_date'].isnull())].index)\n",
    "\n",
    "    #exportando df pronto\n",
    "\n",
    "    data_dataframe.to_csv('../notebooks/data/data-preprocessed.csv', index=False)\n",
    "\n",
    "    #     return data_dataframe\n",
    "    # except Exception:\n",
    "    #     print(\"DEU RUIM\")\n",
    "    #     return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../notebooks/data/Ana Health_Tabela Modelo Previsão Churn - Tabela.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COBRANÇA_VINDI_TWILIO_COMUNICARE_WHOQOL_ATENDIMENTOS_AGENDA_FUNIL_ONBOARDING_PIPEDRIVE_FUNIL_ASSINATURA_PIPEDRIVE_PESSOA_PIPEDRIVE_50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PESSOA, PIPEDRIVE</th>\n",
       "      <td>1022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unnamed: 1</th>\n",
       "      <td>1993-08-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unnamed: 4</th>\n",
       "      <td>Santa Catarina</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  COBRANÇA_VINDI_TWILIO_COMUNICARE_WHOQOL_ATENDIMENTOS_AGENDA_FUNIL_ONBOARDING_PIPEDRIVE_FUNIL_ASSINATURA_PIPEDRIVE_PESSOA_PIPEDRIVE_50\n",
       "PESSOA, PIPEDRIVE                                               1022                                                                                   \n",
       "Unnamed: 1                                                1993-08-03                                                                                   \n",
       "Unnamed: 2                                                        64                                                                                   \n",
       "Unnamed: 3                                                        80                                                                                   \n",
       "Unnamed: 4                                            Santa Catarina                                                                                   "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_merge.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['PESSOA_PIPEDRIVE_id_person_recommendation', 'PESSOA_PIPEDRIVE_Recebe Comunicados?', 'PESSOA_PIPEDRIVE_Interesses', 'PESSOA_PIPEDRIVE_Pontos de Atenção', 'FUNIL_ONBOARDING_PIPEDRIVE_id_label'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/Users/st4pzz/Desktop/insper_2023.2/SPRINT/sprint4-support-vector-team/src/scripts/teste.ipynb Célula 12\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/st4pzz/Desktop/insper_2023.2/SPRINT/sprint4-support-vector-team/src/scripts/teste.ipynb#X12sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m preprocessing(data)\n",
      "\u001b[1;32m/Users/st4pzz/Desktop/insper_2023.2/SPRINT/sprint4-support-vector-team/src/scripts/teste.ipynb Célula 12\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/st4pzz/Desktop/insper_2023.2/SPRINT/sprint4-support-vector-team/src/scripts/teste.ipynb#X12sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m data_dataframe \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(data_dataframe\u001b[39m.\u001b[39miloc[\u001b[39m50\u001b[39m])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/st4pzz/Desktop/insper_2023.2/SPRINT/sprint4-support-vector-team/src/scripts/teste.ipynb#X12sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m \u001b[39m# preprocessing 1\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/st4pzz/Desktop/insper_2023.2/SPRINT/sprint4-support-vector-team/src/scripts/teste.ipynb#X12sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m data_dataframe \u001b[39m=\u001b[39m data_dataframe\u001b[39m.\u001b[39;49mdrop([\u001b[39m\"\u001b[39;49m\u001b[39mPESSOA_PIPEDRIVE_id_person_recommendation\u001b[39;49m\u001b[39m\"\u001b[39;49m,\u001b[39m\"\u001b[39;49m\u001b[39mPESSOA_PIPEDRIVE_Recebe Comunicados?\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mPESSOA_PIPEDRIVE_Interesses\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mPESSOA_PIPEDRIVE_Pontos de Atenção\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mFUNIL_ONBOARDING_PIPEDRIVE_id_label\u001b[39;49m\u001b[39m\"\u001b[39;49m], axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/st4pzz/Desktop/insper_2023.2/SPRINT/sprint4-support-vector-team/src/scripts/teste.ipynb#X12sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m data_dataframe[\u001b[39m'\u001b[39m\u001b[39mPESSOA_PIPEDRIVE_birthdate\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mto_datetime(data_dataframe[\u001b[39m'\u001b[39m\u001b[39mPESSOA_PIPEDRIVE_birthdate\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/st4pzz/Desktop/insper_2023.2/SPRINT/sprint4-support-vector-team/src/scripts/teste.ipynb#X12sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m data_dataframe[\u001b[39m'\u001b[39m\u001b[39mPESSOA_PIPEDRIVE_age\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m data_dataframe[\u001b[39m'\u001b[39m\u001b[39mPESSOA_PIPEDRIVE_birthdate\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mapply(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/st4pzz/Desktop/insper_2023.2/SPRINT/sprint4-support-vector-team/src/scripts/teste.ipynb#X12sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m     \u001b[39mlambda\u001b[39;00m x: datetime\u001b[39m.\u001b[39mtoday()\u001b[39m.\u001b[39myear \u001b[39m-\u001b[39m x\u001b[39m.\u001b[39myear \u001b[39m-\u001b[39m ((datetime\u001b[39m.\u001b[39mtoday()\u001b[39m.\u001b[39mmonth, datetime\u001b[39m.\u001b[39mtoday()\u001b[39m.\u001b[39mday) \u001b[39m<\u001b[39m (x\u001b[39m.\u001b[39mmonth, x\u001b[39m.\u001b[39mday))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/st4pzz/Desktop/insper_2023.2/SPRINT/sprint4-support-vector-team/src/scripts/teste.ipynb#X12sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m )\n",
      "File \u001b[0;32m~/Desktop/insper_2023.2/SPRINT/sprint4-support-vector-team/env/lib/python3.9/site-packages/pandas/core/frame.py:5344\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   5196\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdrop\u001b[39m(\n\u001b[1;32m   5197\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   5198\u001b[0m     labels: IndexLabel \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5205\u001b[0m     errors: IgnoreRaise \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mraise\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   5206\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   5207\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   5208\u001b[0m \u001b[39m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[1;32m   5209\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5342\u001b[0m \u001b[39m            weight  1.0     0.8\u001b[39;00m\n\u001b[1;32m   5343\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 5344\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mdrop(\n\u001b[1;32m   5345\u001b[0m         labels\u001b[39m=\u001b[39;49mlabels,\n\u001b[1;32m   5346\u001b[0m         axis\u001b[39m=\u001b[39;49maxis,\n\u001b[1;32m   5347\u001b[0m         index\u001b[39m=\u001b[39;49mindex,\n\u001b[1;32m   5348\u001b[0m         columns\u001b[39m=\u001b[39;49mcolumns,\n\u001b[1;32m   5349\u001b[0m         level\u001b[39m=\u001b[39;49mlevel,\n\u001b[1;32m   5350\u001b[0m         inplace\u001b[39m=\u001b[39;49minplace,\n\u001b[1;32m   5351\u001b[0m         errors\u001b[39m=\u001b[39;49merrors,\n\u001b[1;32m   5352\u001b[0m     )\n",
      "File \u001b[0;32m~/Desktop/insper_2023.2/SPRINT/sprint4-support-vector-team/env/lib/python3.9/site-packages/pandas/core/generic.py:4711\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4709\u001b[0m \u001b[39mfor\u001b[39;00m axis, labels \u001b[39min\u001b[39;00m axes\u001b[39m.\u001b[39mitems():\n\u001b[1;32m   4710\u001b[0m     \u001b[39mif\u001b[39;00m labels \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 4711\u001b[0m         obj \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39;49m_drop_axis(labels, axis, level\u001b[39m=\u001b[39;49mlevel, errors\u001b[39m=\u001b[39;49merrors)\n\u001b[1;32m   4713\u001b[0m \u001b[39mif\u001b[39;00m inplace:\n\u001b[1;32m   4714\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[0;32m~/Desktop/insper_2023.2/SPRINT/sprint4-support-vector-team/env/lib/python3.9/site-packages/pandas/core/generic.py:4753\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[0;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[1;32m   4751\u001b[0m         new_axis \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39mdrop(labels, level\u001b[39m=\u001b[39mlevel, errors\u001b[39m=\u001b[39merrors)\n\u001b[1;32m   4752\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 4753\u001b[0m         new_axis \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39;49mdrop(labels, errors\u001b[39m=\u001b[39;49merrors)\n\u001b[1;32m   4754\u001b[0m     indexer \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39mget_indexer(new_axis)\n\u001b[1;32m   4756\u001b[0m \u001b[39m# Case for non-unique axis\u001b[39;00m\n\u001b[1;32m   4757\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/Desktop/insper_2023.2/SPRINT/sprint4-support-vector-team/env/lib/python3.9/site-packages/pandas/core/indexes/base.py:6992\u001b[0m, in \u001b[0;36mIndex.drop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   6990\u001b[0m \u001b[39mif\u001b[39;00m mask\u001b[39m.\u001b[39many():\n\u001b[1;32m   6991\u001b[0m     \u001b[39mif\u001b[39;00m errors \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m-> 6992\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mlabels[mask]\u001b[39m.\u001b[39mtolist()\u001b[39m}\u001b[39;00m\u001b[39m not found in axis\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   6993\u001b[0m     indexer \u001b[39m=\u001b[39m indexer[\u001b[39m~\u001b[39mmask]\n\u001b[1;32m   6994\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdelete(indexer)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['PESSOA_PIPEDRIVE_id_person_recommendation', 'PESSOA_PIPEDRIVE_Recebe Comunicados?', 'PESSOA_PIPEDRIVE_Interesses', 'PESSOA_PIPEDRIVE_Pontos de Atenção', 'FUNIL_ONBOARDING_PIPEDRIVE_id_label'] not found in axis\""
     ]
    }
   ],
   "source": [
    "preprocessing(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
