{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"../notebooks/data/Ana Health_Tabela Modelo Previsão Churn - Tabela.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_preprocessing import preprocessing,mergeHeader_Columns\n",
    "from data_feature_engineering import feature_engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PESSOA_PIPEDRIVE_id_person',\n",
       " 'PESSOA_PIPEDRIVE_birthdate',\n",
       " 'PESSOA_PIPEDRIVE_id_gender',\n",
       " 'PESSOA_PIPEDRIVE_id_marrital_status',\n",
       " 'PESSOA_PIPEDRIVE_state',\n",
       " 'PESSOA_PIPEDRIVE_city',\n",
       " 'PESSOA_PIPEDRIVE_postal_code',\n",
       " 'PESSOA_PIPEDRIVE_id_health_plan',\n",
       " 'PESSOA_PIPEDRIVE_id_person_recommendation',\n",
       " 'PESSOA_PIPEDRIVE_contract_start_date',\n",
       " 'PESSOA_PIPEDRIVE_contract_end_date',\n",
       " 'PESSOA_PIPEDRIVE_id_continuity_pf',\n",
       " 'PESSOA_PIPEDRIVE_Canal de Preferência',\n",
       " 'PESSOA_PIPEDRIVE_notes_count',\n",
       " 'PESSOA_PIPEDRIVE_done_activities_count',\n",
       " 'PESSOA_PIPEDRIVE_Recebe Comunicados?',\n",
       " 'PESSOA_PIPEDRIVE_Interesses',\n",
       " 'PESSOA_PIPEDRIVE_Pontos de Atenção',\n",
       " 'FUNIL_ASSINATURA_PIPEDRIVE_id_stage',\n",
       " 'FUNIL_ASSINATURA_PIPEDRIVE_id_org',\n",
       " 'FUNIL_ASSINATURA_PIPEDRIVE_status',\n",
       " 'FUNIL_ASSINATURA_PIPEDRIVE_start_of_service',\n",
       " 'FUNIL_ASSINATURA_PIPEDRIVE_lost_time',\n",
       " 'FUNIL_ASSINATURA_PIPEDRIVE_lost_reason',\n",
       " 'FUNIL_ONBOARDING_PIPEDRIVE_add_time',\n",
       " 'FUNIL_ONBOARDING_PIPEDRIVE_status',\n",
       " 'FUNIL_ONBOARDING_PIPEDRIVE_id_label',\n",
       " 'FUNIL_ONBOARDING_PIPEDRIVE_stay_in_pipeline_stages_welcome',\n",
       " 'FUNIL_ONBOARDING_PIPEDRIVE_stay_in_pipeline_stages_first_meeting',\n",
       " 'FUNIL_ONBOARDING_PIPEDRIVE_stay_in_pipeline_stages_whoqol',\n",
       " 'FUNIL_ONBOARDING_PIPEDRIVE_won_time',\n",
       " 'FUNIL_ONBOARDING_PIPEDRIVE_lost_time',\n",
       " 'FUNIL_ONBOARDING_PIPEDRIVE_lost_reason',\n",
       " 'FUNIL_ONBOARDING_PIPEDRIVE_activities_count',\n",
       " 'ATENDIMENTOS_AGENDA_Qde Todos Atendimentos',\n",
       " 'ATENDIMENTOS_AGENDA_Faltas Todos Atendimento',\n",
       " 'ATENDIMENTOS_AGENDA_Qde Atendimento Médico',\n",
       " 'ATENDIMENTOS_AGENDA_Faltas Atendimento Médico',\n",
       " 'ATENDIMENTOS_AGENDA_Datas Atendimento Médico',\n",
       " 'ATENDIMENTOS_AGENDA_Qde Atendimentos Acolhimento',\n",
       " 'ATENDIMENTOS_AGENDA_Faltas Acolhimento',\n",
       " 'ATENDIMENTOS_AGENDA_Datas Acolhimento',\n",
       " 'ATENDIMENTOS_AGENDA_Qde Psicoterapia',\n",
       " 'ATENDIMENTOS_AGENDA_Faltas Psicoterapia',\n",
       " 'ATENDIMENTOS_AGENDA_Datas Psicoterapia',\n",
       " 'ATENDIMENTOS_AGENDA_Qde Prescrições',\n",
       " 'ATENDIMENTOS_AGENDA_Datas Prescrição',\n",
       " 'WHOQOL_Qde Respostas WHOQOL',\n",
       " 'WHOQOL_Físico',\n",
       " 'WHOQOL_Psicológico',\n",
       " 'WHOQOL_Social',\n",
       " 'WHOQOL_Ambiental',\n",
       " 'COMUNICARE_Problemas Abertos',\n",
       " 'TWILIO_Mensagens Inbound',\n",
       " 'TWILIO_Data Última Mensagens Inbound',\n",
       " 'TWILIO_Mensagens Outbound',\n",
       " 'TWILIO_Data Última Mensagens Outbound',\n",
       " 'TWILIO_Ligações Inbound',\n",
       " 'TWILIO_Data Última Ligações Inbound',\n",
       " 'TWILIO_Ligações Outbound',\n",
       " 'TWILIO_Data Última Ligações Outbound',\n",
       " 'COBRANÇA_VINDI_Qde Total de Faturas',\n",
       " 'COBRANÇA_VINDI_Qde Total de Tentativas de Cobrança',\n",
       " 'COBRANÇA_VINDI_Método de Pagamento',\n",
       " 'COBRANÇA_VINDI_Valor Médio da Mensalidade',\n",
       " 'COBRANÇA_VINDI_Qde Total de Faturas Pagas após Vencimento',\n",
       " 'COBRANÇA_VINDI_Qde Total de Faturas Inadimpletes',\n",
       " 'COBRANÇA_VINDI_Valor Total Inadimplência',\n",
       " 'COBRANÇA_VINDI_Qde Perfis de Pagamento Inativos']"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_merge = mergeHeader_Columns(df)\n",
    "\n",
    "data_merge.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PESSOA_PIPEDRIVE_id_person', 'PESSOA_PIPEDRIVE_birthdate', 'PESSOA_PIPEDRIVE_id_gender', 'PESSOA_PIPEDRIVE_id_marrital_status', 'PESSOA_PIPEDRIVE_state', 'PESSOA_PIPEDRIVE_city', 'PESSOA_PIPEDRIVE_postal_code', 'PESSOA_PIPEDRIVE_id_health_plan', 'PESSOA_PIPEDRIVE_id_person_recommendation', 'PESSOA_PIPEDRIVE_contract_start_date', 'PESSOA_PIPEDRIVE_contract_end_date', 'PESSOA_PIPEDRIVE_id_continuity_pf', 'PESSOA_PIPEDRIVE_Canal de Preferência', 'PESSOA_PIPEDRIVE_notes_count', 'PESSOA_PIPEDRIVE_done_activities_count', 'PESSOA_PIPEDRIVE_Recebe Comunicados?', 'PESSOA_PIPEDRIVE_Interesses', 'PESSOA_PIPEDRIVE_Pontos de Atenção', 'FUNIL_ASSINATURA_PIPEDRIVE_id_stage', 'FUNIL_ASSINATURA_PIPEDRIVE_id_org', 'FUNIL_ASSINATURA_PIPEDRIVE_status', 'FUNIL_ASSINATURA_PIPEDRIVE_start_of_service', 'FUNIL_ASSINATURA_PIPEDRIVE_lost_time', 'FUNIL_ASSINATURA_PIPEDRIVE_lost_reason', 'FUNIL_ONBOARDING_PIPEDRIVE_add_time', 'FUNIL_ONBOARDING_PIPEDRIVE_status', 'FUNIL_ONBOARDING_PIPEDRIVE_id_label', 'FUNIL_ONBOARDING_PIPEDRIVE_stay_in_pipeline_stages_welcome', 'FUNIL_ONBOARDING_PIPEDRIVE_stay_in_pipeline_stages_first_meeting', 'FUNIL_ONBOARDING_PIPEDRIVE_stay_in_pipeline_stages_whoqol', 'FUNIL_ONBOARDING_PIPEDRIVE_won_time', 'FUNIL_ONBOARDING_PIPEDRIVE_lost_time', 'FUNIL_ONBOARDING_PIPEDRIVE_lost_reason', 'FUNIL_ONBOARDING_PIPEDRIVE_activities_count', 'ATENDIMENTOS_AGENDA_Qde Todos Atendimentos', 'ATENDIMENTOS_AGENDA_Faltas Todos Atendimento', 'ATENDIMENTOS_AGENDA_Qde Atendimento Médico', 'ATENDIMENTOS_AGENDA_Faltas Atendimento Médico', 'ATENDIMENTOS_AGENDA_Datas Atendimento Médico', 'ATENDIMENTOS_AGENDA_Qde Atendimentos Acolhimento', 'ATENDIMENTOS_AGENDA_Faltas Acolhimento', 'ATENDIMENTOS_AGENDA_Datas Acolhimento', 'ATENDIMENTOS_AGENDA_Qde Psicoterapia', 'ATENDIMENTOS_AGENDA_Faltas Psicoterapia', 'ATENDIMENTOS_AGENDA_Datas Psicoterapia', 'ATENDIMENTOS_AGENDA_Qde Prescrições', 'ATENDIMENTOS_AGENDA_Datas Prescrição', 'WHOQOL_Qde Respostas WHOQOL', 'WHOQOL_Físico', 'WHOQOL_Psicológico', 'WHOQOL_Social', 'WHOQOL_Ambiental', 'COMUNICARE_Problemas Abertos', 'TWILIO_Mensagens Inbound', 'TWILIO_Data Última Mensagens Inbound', 'TWILIO_Mensagens Outbound', 'TWILIO_Data Última Mensagens Outbound', 'TWILIO_Ligações Inbound', 'TWILIO_Data Última Ligações Inbound', 'TWILIO_Ligações Outbound', 'TWILIO_Data Última Ligações Outbound', 'COBRANÇA_VINDI_Qde Total de Faturas', 'COBRANÇA_VINDI_Qde Total de Tentativas de Cobrança', 'COBRANÇA_VINDI_Método de Pagamento', 'COBRANÇA_VINDI_Valor Médio da Mensalidade', 'COBRANÇA_VINDI_Qde Total de Faturas Pagas após Vencimento', 'COBRANÇA_VINDI_Qde Total de Faturas Inadimpletes', 'COBRANÇA_VINDI_Valor Total Inadimplência', 'COBRANÇA_VINDI_Qde Perfis de Pagamento Inativos']\n",
      "69\n",
      "(1, 69)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['PESSOA_PIPEDRIVE_id_person',\n",
       " 'PESSOA_PIPEDRIVE_birthdate',\n",
       " 'PESSOA_PIPEDRIVE_id_gender',\n",
       " 'PESSOA_PIPEDRIVE_id_marrital_status',\n",
       " 'PESSOA_PIPEDRIVE_state',\n",
       " 'PESSOA_PIPEDRIVE_city',\n",
       " 'PESSOA_PIPEDRIVE_postal_code',\n",
       " 'PESSOA_PIPEDRIVE_id_health_plan',\n",
       " 'PESSOA_PIPEDRIVE_id_person_recommendation',\n",
       " 'PESSOA_PIPEDRIVE_contract_start_date',\n",
       " 'PESSOA_PIPEDRIVE_contract_end_date',\n",
       " 'PESSOA_PIPEDRIVE_id_continuity_pf',\n",
       " 'PESSOA_PIPEDRIVE_Canal de Preferência',\n",
       " 'PESSOA_PIPEDRIVE_notes_count',\n",
       " 'PESSOA_PIPEDRIVE_done_activities_count',\n",
       " 'PESSOA_PIPEDRIVE_Recebe Comunicados?',\n",
       " 'PESSOA_PIPEDRIVE_Interesses',\n",
       " 'PESSOA_PIPEDRIVE_Pontos de Atenção',\n",
       " 'FUNIL_ASSINATURA_PIPEDRIVE_id_stage',\n",
       " 'FUNIL_ASSINATURA_PIPEDRIVE_id_org',\n",
       " 'FUNIL_ASSINATURA_PIPEDRIVE_status',\n",
       " 'FUNIL_ASSINATURA_PIPEDRIVE_start_of_service',\n",
       " 'FUNIL_ASSINATURA_PIPEDRIVE_lost_time',\n",
       " 'FUNIL_ASSINATURA_PIPEDRIVE_lost_reason',\n",
       " 'FUNIL_ONBOARDING_PIPEDRIVE_add_time',\n",
       " 'FUNIL_ONBOARDING_PIPEDRIVE_status',\n",
       " 'FUNIL_ONBOARDING_PIPEDRIVE_id_label',\n",
       " 'FUNIL_ONBOARDING_PIPEDRIVE_stay_in_pipeline_stages_welcome',\n",
       " 'FUNIL_ONBOARDING_PIPEDRIVE_stay_in_pipeline_stages_first_meeting',\n",
       " 'FUNIL_ONBOARDING_PIPEDRIVE_stay_in_pipeline_stages_whoqol',\n",
       " 'FUNIL_ONBOARDING_PIPEDRIVE_won_time',\n",
       " 'FUNIL_ONBOARDING_PIPEDRIVE_lost_time',\n",
       " 'FUNIL_ONBOARDING_PIPEDRIVE_lost_reason',\n",
       " 'FUNIL_ONBOARDING_PIPEDRIVE_activities_count',\n",
       " 'ATENDIMENTOS_AGENDA_Qde Todos Atendimentos',\n",
       " 'ATENDIMENTOS_AGENDA_Faltas Todos Atendimento',\n",
       " 'ATENDIMENTOS_AGENDA_Qde Atendimento Médico',\n",
       " 'ATENDIMENTOS_AGENDA_Faltas Atendimento Médico',\n",
       " 'ATENDIMENTOS_AGENDA_Datas Atendimento Médico',\n",
       " 'ATENDIMENTOS_AGENDA_Qde Atendimentos Acolhimento',\n",
       " 'ATENDIMENTOS_AGENDA_Faltas Acolhimento',\n",
       " 'ATENDIMENTOS_AGENDA_Datas Acolhimento',\n",
       " 'ATENDIMENTOS_AGENDA_Qde Psicoterapia',\n",
       " 'ATENDIMENTOS_AGENDA_Faltas Psicoterapia',\n",
       " 'ATENDIMENTOS_AGENDA_Datas Psicoterapia',\n",
       " 'ATENDIMENTOS_AGENDA_Qde Prescrições',\n",
       " 'ATENDIMENTOS_AGENDA_Datas Prescrição',\n",
       " 'WHOQOL_Qde Respostas WHOQOL',\n",
       " 'WHOQOL_Físico',\n",
       " 'WHOQOL_Psicológico',\n",
       " 'WHOQOL_Social',\n",
       " 'WHOQOL_Ambiental',\n",
       " 'COMUNICARE_Problemas Abertos',\n",
       " 'TWILIO_Mensagens Inbound',\n",
       " 'TWILIO_Data Última Mensagens Inbound',\n",
       " 'TWILIO_Mensagens Outbound',\n",
       " 'TWILIO_Data Última Mensagens Outbound',\n",
       " 'TWILIO_Ligações Inbound',\n",
       " 'TWILIO_Data Última Ligações Inbound',\n",
       " 'TWILIO_Ligações Outbound',\n",
       " 'TWILIO_Data Última Ligações Outbound',\n",
       " 'COBRANÇA_VINDI_Qde Total de Faturas',\n",
       " 'COBRANÇA_VINDI_Qde Total de Tentativas de Cobrança',\n",
       " 'COBRANÇA_VINDI_Método de Pagamento',\n",
       " 'COBRANÇA_VINDI_Valor Médio da Mensalidade',\n",
       " 'COBRANÇA_VINDI_Qde Total de Faturas Pagas após Vencimento',\n",
       " 'COBRANÇA_VINDI_Qde Total de Faturas Inadimpletes',\n",
       " 'COBRANÇA_VINDI_Valor Total Inadimplência',\n",
       " 'COBRANÇA_VINDI_Qde Perfis de Pagamento Inativos']"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "with open(\"../api/colunas.txt\", \"r\") as arquivo:\n",
    "    # Leia o conteúdo do arquivo e remova espaços em branco e quebras de linha\n",
    "    nomes_lista = arquivo.readlines()\n",
    "\n",
    "\n",
    "nomes_lista = [string.replace(',', '').replace('\\n', '')for string in nomes_lista]\n",
    "\n",
    "print(nomes_lista)\n",
    "# Agora, a variável 'nomes' contém os nomes em uma lista Python\n",
    "\n",
    "\n",
    "print(len(nomes_lista))\n",
    "\n",
    "data_dataframe = pd.read_csv(\"../notebooks/data/Ana Health_Tabela Modelo Previsão Churn - Tabela.csv\")\n",
    "data_dataframe = pd.DataFrame(data_dataframe.iloc[50, :]).T\n",
    "\n",
    "\n",
    "data_dataframe.columns = nomes_lista\n",
    "\n",
    "print(data_dataframe.shape)\n",
    "data_dataframe.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50    NaN\n",
       "Name: PESSOA_PIPEDRIVE_id_person_recommendation, dtype: object"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dataframe[\"PESSOA_PIPEDRIVE_id_person_recommendation\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['PESSOA_PIPEDRIVE_id_person_recommendation', 'PESSOA_PIPEDRIVE_Recebe Comunicados?', 'PESSOA_PIPEDRIVE_Interesses', 'PESSOA_PIPEDRIVE_Pontos de Atenção', 'FUNIL_ONBOARDING_PIPEDRIVE_id_label'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/Users/st4pzz/Desktop/insper_2023.2/SPRINT/sprint4-support-vector-team/src/scripts/teste.ipynb Célula 5\u001b[0m line \u001b[0;36m6\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/st4pzz/Desktop/insper_2023.2/SPRINT/sprint4-support-vector-team/src/scripts/teste.ipynb#X16sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mimpute\u001b[39;00m \u001b[39mimport\u001b[39;00m SimpleImputer\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/st4pzz/Desktop/insper_2023.2/SPRINT/sprint4-support-vector-team/src/scripts/teste.ipynb#X16sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/st4pzz/Desktop/insper_2023.2/SPRINT/sprint4-support-vector-team/src/scripts/teste.ipynb#X16sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m data_dataframe \u001b[39m=\u001b[39m data_dataframe\u001b[39m.\u001b[39;49mdrop([\u001b[39m\"\u001b[39;49m\u001b[39mPESSOA_PIPEDRIVE_id_person_recommendation\u001b[39;49m\u001b[39m\"\u001b[39;49m,\u001b[39m\"\u001b[39;49m\u001b[39mPESSOA_PIPEDRIVE_Recebe Comunicados?\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mPESSOA_PIPEDRIVE_Interesses\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mPESSOA_PIPEDRIVE_Pontos de Atenção\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mFUNIL_ONBOARDING_PIPEDRIVE_id_label\u001b[39;49m\u001b[39m\"\u001b[39;49m], axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/st4pzz/Desktop/insper_2023.2/SPRINT/sprint4-support-vector-team/src/scripts/teste.ipynb#X16sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m data_dataframe[\u001b[39m'\u001b[39m\u001b[39mPESSOA_PIPEDRIVE_birthdate\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mto_datetime(data_dataframe[\u001b[39m'\u001b[39m\u001b[39mPESSOA_PIPEDRIVE_birthdate\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/st4pzz/Desktop/insper_2023.2/SPRINT/sprint4-support-vector-team/src/scripts/teste.ipynb#X16sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m data_dataframe[\u001b[39m'\u001b[39m\u001b[39mPESSOA_PIPEDRIVE_age\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m data_dataframe[\u001b[39m'\u001b[39m\u001b[39mPESSOA_PIPEDRIVE_birthdate\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mapply(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/st4pzz/Desktop/insper_2023.2/SPRINT/sprint4-support-vector-team/src/scripts/teste.ipynb#X16sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     \u001b[39mlambda\u001b[39;00m x: datetime\u001b[39m.\u001b[39mtoday()\u001b[39m.\u001b[39myear \u001b[39m-\u001b[39m x\u001b[39m.\u001b[39myear \u001b[39m-\u001b[39m ((datetime\u001b[39m.\u001b[39mtoday()\u001b[39m.\u001b[39mmonth, datetime\u001b[39m.\u001b[39mtoday()\u001b[39m.\u001b[39mday) \u001b[39m<\u001b[39m (x\u001b[39m.\u001b[39mmonth, x\u001b[39m.\u001b[39mday))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/st4pzz/Desktop/insper_2023.2/SPRINT/sprint4-support-vector-team/src/scripts/teste.ipynb#X16sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m )\n",
      "File \u001b[0;32m~/Desktop/insper_2023.2/SPRINT/sprint4-support-vector-team/env/lib/python3.9/site-packages/pandas/core/frame.py:5344\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   5196\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdrop\u001b[39m(\n\u001b[1;32m   5197\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   5198\u001b[0m     labels: IndexLabel \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5205\u001b[0m     errors: IgnoreRaise \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mraise\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   5206\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   5207\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   5208\u001b[0m \u001b[39m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[1;32m   5209\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5342\u001b[0m \u001b[39m            weight  1.0     0.8\u001b[39;00m\n\u001b[1;32m   5343\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 5344\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mdrop(\n\u001b[1;32m   5345\u001b[0m         labels\u001b[39m=\u001b[39;49mlabels,\n\u001b[1;32m   5346\u001b[0m         axis\u001b[39m=\u001b[39;49maxis,\n\u001b[1;32m   5347\u001b[0m         index\u001b[39m=\u001b[39;49mindex,\n\u001b[1;32m   5348\u001b[0m         columns\u001b[39m=\u001b[39;49mcolumns,\n\u001b[1;32m   5349\u001b[0m         level\u001b[39m=\u001b[39;49mlevel,\n\u001b[1;32m   5350\u001b[0m         inplace\u001b[39m=\u001b[39;49minplace,\n\u001b[1;32m   5351\u001b[0m         errors\u001b[39m=\u001b[39;49merrors,\n\u001b[1;32m   5352\u001b[0m     )\n",
      "File \u001b[0;32m~/Desktop/insper_2023.2/SPRINT/sprint4-support-vector-team/env/lib/python3.9/site-packages/pandas/core/generic.py:4711\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4709\u001b[0m \u001b[39mfor\u001b[39;00m axis, labels \u001b[39min\u001b[39;00m axes\u001b[39m.\u001b[39mitems():\n\u001b[1;32m   4710\u001b[0m     \u001b[39mif\u001b[39;00m labels \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 4711\u001b[0m         obj \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39;49m_drop_axis(labels, axis, level\u001b[39m=\u001b[39;49mlevel, errors\u001b[39m=\u001b[39;49merrors)\n\u001b[1;32m   4713\u001b[0m \u001b[39mif\u001b[39;00m inplace:\n\u001b[1;32m   4714\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[0;32m~/Desktop/insper_2023.2/SPRINT/sprint4-support-vector-team/env/lib/python3.9/site-packages/pandas/core/generic.py:4753\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[0;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[1;32m   4751\u001b[0m         new_axis \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39mdrop(labels, level\u001b[39m=\u001b[39mlevel, errors\u001b[39m=\u001b[39merrors)\n\u001b[1;32m   4752\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 4753\u001b[0m         new_axis \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39;49mdrop(labels, errors\u001b[39m=\u001b[39;49merrors)\n\u001b[1;32m   4754\u001b[0m     indexer \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39mget_indexer(new_axis)\n\u001b[1;32m   4756\u001b[0m \u001b[39m# Case for non-unique axis\u001b[39;00m\n\u001b[1;32m   4757\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/Desktop/insper_2023.2/SPRINT/sprint4-support-vector-team/env/lib/python3.9/site-packages/pandas/core/indexes/base.py:6992\u001b[0m, in \u001b[0;36mIndex.drop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   6990\u001b[0m \u001b[39mif\u001b[39;00m mask\u001b[39m.\u001b[39many():\n\u001b[1;32m   6991\u001b[0m     \u001b[39mif\u001b[39;00m errors \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m-> 6992\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mlabels[mask]\u001b[39m.\u001b[39mtolist()\u001b[39m}\u001b[39;00m\u001b[39m not found in axis\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   6993\u001b[0m     indexer \u001b[39m=\u001b[39m indexer[\u001b[39m~\u001b[39mmask]\n\u001b[1;32m   6994\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdelete(indexer)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['PESSOA_PIPEDRIVE_id_person_recommendation', 'PESSOA_PIPEDRIVE_Recebe Comunicados?', 'PESSOA_PIPEDRIVE_Interesses', 'PESSOA_PIPEDRIVE_Pontos de Atenção', 'FUNIL_ONBOARDING_PIPEDRIVE_id_label'] not found in axis\""
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "import numpy as np\n",
    "\n",
    "data_dataframe = data_dataframe.drop([\"PESSOA_PIPEDRIVE_id_person_recommendation\",\"PESSOA_PIPEDRIVE_Recebe Comunicados?\", \"PESSOA_PIPEDRIVE_Interesses\", \"PESSOA_PIPEDRIVE_Pontos de Atenção\", \"FUNIL_ONBOARDING_PIPEDRIVE_id_label\"], axis=1)\n",
    "\n",
    "data_dataframe['PESSOA_PIPEDRIVE_birthdate'] = pd.to_datetime(data_dataframe['PESSOA_PIPEDRIVE_birthdate'])\n",
    "data_dataframe['PESSOA_PIPEDRIVE_age'] = data_dataframe['PESSOA_PIPEDRIVE_birthdate'].apply(\n",
    "    lambda x: datetime.today().year - x.year - ((datetime.today().month, datetime.today().day) < (x.month, x.day))\n",
    ")\n",
    "\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "data_dataframe['PESSOA_PIPEDRIVE_age'] = imputer.fit_transform(data_dataframe['PESSOA_PIPEDRIVE_age'].values.reshape(-1, 1))\n",
    "data_dataframe['PESSOA_PIPEDRIVE_age'] = np.round(data_dataframe['PESSOA_PIPEDRIVE_age']).astype(int)\n",
    "\n",
    "data_dataframe = data_dataframe.drop(['PESSOA_PIPEDRIVE_birthdate'], axis=1 )\n",
    "\n",
    "rows_to_drop = data_dataframe[data_dataframe[\"PESSOA_PIPEDRIVE_id_gender\"].isin([117,110,111])]\n",
    "data_dataframe = data_dataframe.drop(rows_to_drop.index, axis=0)\n",
    "data_dataframe[\"PESSOA_PIPEDRIVE_id_gender\"].fillna(64, inplace=True)\n",
    "data_dataframe[\"PESSOA_PIPEDRIVE_id_marrital_status\"].fillna(80, inplace=True)\n",
    "\n",
    "\n",
    "data_dataframe[\"PESSOA_PIPEDRIVE_state\"].fillna(data_dataframe[\"PESSOA_PIPEDRIVE_state\"].mode()[0], inplace=True)\n",
    "\n",
    "\n",
    "data_dataframe[\"PESSOA_PIPEDRIVE_city\"].fillna(data_dataframe[\"PESSOA_PIPEDRIVE_city\"].mode()[0], inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "data_dataframe['PESSOA_PIPEDRIVE_id_health_plan'].fillna(data_dataframe['PESSOA_PIPEDRIVE_id_health_plan'].mode()[0], inplace=True)\n",
    "data_dataframe['PESSOA_PIPEDRIVE_has_public_health_plan'] = data_dataframe['PESSOA_PIPEDRIVE_id_health_plan'].apply(lambda x: 1 if int(x) == 412 else 0)\n",
    "data_dataframe = data_dataframe.drop(['PESSOA_PIPEDRIVE_id_health_plan'], axis=1)\n",
    "data_dataframe[\"PESSOA_PIPEDRIVE_tem_data_dataframe_de_termino_de_contrato\"] = data_dataframe[\"PESSOA_PIPEDRIVE_contract_end_date\"].apply(lambda x: 0 if pd.isna(x) else 1)\n",
    "data_dataframe.drop([\"PESSOA_PIPEDRIVE_id_continuity_pf\"], axis=1, inplace=True)\n",
    "data_dataframe[\"PESSOA_PIPEDRIVE_Canal de Preferência\"].fillna(0, inplace=True)\n",
    "data_dataframe[\"PESSOA_PIPEDRIVE_Tem_Canal_de_Preferência\"] = data_dataframe[\"PESSOA_PIPEDRIVE_Canal de Preferência\"].apply(lambda x: 1 if int(x) > 0  else 0)\n",
    "data_dataframe[\"PESSOA_PIPEDRIVE_has_notes\"] = data_dataframe[\"PESSOA_PIPEDRIVE_notes_count\"].apply(lambda x: 1 if int(x) > 0 else 0)\n",
    "\n",
    "# preprocessing 2\n",
    "data_dataframe = data_dataframe.drop([\"ATENDIMENTOS_AGENDA_Faltas Psicoterapia\",\"TWILIO_Ligações Inbound\", \"TWILIO_Data Última Ligações Inbound\",\"COBRANÇA_VINDI_Qde Total de Faturas\",\"COBRANÇA_VINDI_Qde Total de Tentativas de Cobrança\",\"COBRANÇA_VINDI_Método de Pagamento\",\"COBRANÇA_VINDI_Valor Médio da Mensalidade\",\"COBRANÇA_VINDI_Qde Total de Faturas Pagas após Vencimento\",\"COBRANÇA_VINDI_Qde Total de Faturas Inadimpletes\",\"COBRANÇA_VINDI_Valor Total Inadimplência\"], axis=1)\n",
    "\n",
    "data_dataframe[\"ATENDIMENTOS_AGENDA_Qde Psicoterapia\"].fillna(0, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "data_dataframe = data_dataframe.drop(columns=\"WHOQOL_Qde Respostas WHOQOL\")\n",
    "\n",
    "data_dataframe[\"WHOQOL_Físico_New\"] = data_dataframe[\"WHOQOL_Físico\"].str.split(';').str[-1].str.strip()\n",
    "\n",
    "data_dataframe[\"WHOQOL_Físico_New\"] = data_dataframe[\"WHOQOL_Físico_New\"].str.replace(\",\",\".\")\n",
    "\n",
    "data_dataframe[\"WHOQOL_Físico_New\"] = data_dataframe[\"WHOQOL_Físico_New\"].astype(float) \n",
    "\n",
    "data_dataframe[\"WHOQOL_Físico_New\"] = data_dataframe[\"WHOQOL_Físico_New\"].fillna(data_dataframe[\"WHOQOL_Físico_New\"].median())\n",
    "\n",
    "data_dataframe[\"WHOQOL_Psicológico_New\"] = data_dataframe[\"WHOQOL_Psicológico\"].str.split(';').str[-1].str.strip()\n",
    "\n",
    "data_dataframe[\"WHOQOL_Psicológico_New\"] = data_dataframe[\"WHOQOL_Psicológico_New\"].str.replace(\",\",\".\")\n",
    "\n",
    "data_dataframe[\"WHOQOL_Psicológico_New\"] = data_dataframe[\"WHOQOL_Psicológico_New\"].astype(float) \n",
    "\n",
    "data_dataframe[\"WHOQOL_Psicológico_New\"] = data_dataframe[\"WHOQOL_Psicológico_New\"].fillna(data_dataframe[\"WHOQOL_Psicológico_New\"].median())\n",
    "\n",
    "data_dataframe[\"WHOQOL_Social_New\"] = data_dataframe[\"WHOQOL_Social\"].str.split(';').str[-1].str.strip()\n",
    "\n",
    "data_dataframe[\"WHOQOL_Social_New\"] = data_dataframe[\"WHOQOL_Social_New\"].str.replace(\",\",\".\")\n",
    "\n",
    "data_dataframe[\"WHOQOL_Social_New\"] = data_dataframe[\"WHOQOL_Social_New\"].astype(float) \n",
    "\n",
    "data_dataframe[\"WHOQOL_Social_New\"] = data_dataframe[\"WHOQOL_Social_New\"].fillna(data_dataframe[\"WHOQOL_Social_New\"].median())\n",
    "\n",
    "data_dataframe[\"WHOQOL_Ambiental_New\"] = data_dataframe[\"WHOQOL_Ambiental\"].str.split(';').str[-1].str.strip()\n",
    "\n",
    "data_dataframe[\"WHOQOL_Ambiental_New\"] = data_dataframe[\"WHOQOL_Ambiental_New\"].str.replace(\",\",\".\")\n",
    "\n",
    "data_dataframe[\"WHOQOL_Ambiental_New\"] = data_dataframe[\"WHOQOL_Ambiental_New\"].astype(float) \n",
    "\n",
    "data_dataframe[\"WHOQOL_Ambiental_New\"] = data_dataframe[\"WHOQOL_Ambiental_New\"].fillna(data_dataframe[\"WHOQOL_Ambiental_New\"].median())\n",
    "\n",
    "data_dataframe[\"COMUNICARE_Problemas Abertos Bool\"] = data_dataframe[\"COMUNICARE_Problemas Abertos\"].notnull().astype(int)\n",
    "\n",
    "data_dataframe[\"COMUNICARE_Problemas Abertos Bool\"].fillna(0, inplace=True)\n",
    "\n",
    "data_dataframe[\"TWILIO_Mensagens Inbound\"].fillna(0, inplace=True)\n",
    "\n",
    "data_dataframe[\"TWILIO_Data Última Mensagens Inbound\"] = pd.to_datetime(data_dataframe[\"TWILIO_Data Última Mensagens Inbound\"])\n",
    "\n",
    "data_dataframe[\"TWILIO_Data Última Mensagens Inbound Tempo Passado\"] = datetime.now() - data_dataframe[\"TWILIO_Data Última Mensagens Inbound\"]\n",
    "\n",
    "data_dataframe[\"TWILIO_Data Última Mensagens Inbound Tempo Passado\"].fillna('', inplace=True)\n",
    "\n",
    "data_dataframe[\"TWILIO_Data Última Mensagens Inbound Tempo Passado\"] = data_dataframe[\"TWILIO_Data Última Mensagens Inbound Tempo Passado\"].astype(str)\n",
    "\n",
    "data_dataframe[\"TWILIO_Data Última Mensagens Inbound Tempo Passado\"] = data_dataframe[\"TWILIO_Data Última Mensagens Inbound Tempo Passado\"].str.extract('(\\d+) days').astype(float)\n",
    "\n",
    "data_dataframe[\"TWILIO_Data Última Mensagens Inbound Recente\"] = data_dataframe[\"TWILIO_Data Última Mensagens Inbound Tempo Passado\"] < data_dataframe[\"TWILIO_Data Última Mensagens Inbound Tempo Passado\"].median()\n",
    "data_dataframe[\"TWILIO_Data Última Mensagens Inbound Recente\"].fillna(0)\n",
    "data_dataframe[\"TWILIO_Data Última Mensagens Inbound Recente\"].replace(True, 1, inplace=True)\n",
    "data_dataframe[\"TWILIO_Data Última Mensagens Inbound Recente\"].replace(False, 0, inplace=True)\n",
    "\n",
    "data_dataframe = data_dataframe.drop(columns=[\"WHOQOL_Ambiental\",\"WHOQOL_Social\",\"WHOQOL_Físico\",\"WHOQOL_Psicológico\",\"COMUNICARE_Problemas Abertos\",\"TWILIO_Data Última Mensagens Inbound\",\"ATENDIMENTOS_AGENDA_Datas Psicoterapia\",\"TWILIO_Data Última Mensagens Inbound Tempo Passado\"])\n",
    "\n",
    "# preprocessing 3\n",
    "for indice, valor in data_dataframe[\"FUNIL_ASSINATURA_PIPEDRIVE_lost_time\"].items():\n",
    "    if pd.notna(valor) == False: \n",
    "        if pd.notna(data_dataframe.loc[indice, \"PESSOA_PIPEDRIVE_contract_end_date\"]):\n",
    "            data_dataframe.loc[indice, \"FUNIL_ASSINATURA_PIPEDRIVE_lost_time\"] = data_dataframe.loc[indice, \"PESSOA_PIPEDRIVE_contract_end_date\"]\n",
    "\n",
    "data_dataframe[\"FUNIL_ASSINATURA_PIPEDRIVE_lost_time\"].fillna(datetime.date.today(), inplace=True)\n",
    "\n",
    "for indice, valor in data_dataframe[\"FUNIL_ASSINATURA_PIPEDRIVE_lost_time\"].items():\n",
    "    index = str(data_dataframe.loc[indice, \"FUNIL_ASSINATURA_PIPEDRIVE_lost_time\"]).find(\";\")\n",
    "    if index != -1:\n",
    "        data_dataframe.loc[indice, \"FUNIL_ASSINATURA_PIPEDRIVE_lost_time\"] = data_dataframe.loc[indice, \"FUNIL_ASSINATURA_PIPEDRIVE_lost_time\"][:index]\n",
    "\n",
    "for indice, valor in data_dataframe[\"FUNIL_ASSINATURA_PIPEDRIVE_lost_time\"].items():\n",
    "    tamanho = len(str(data_dataframe.loc[indice, \"FUNIL_ASSINATURA_PIPEDRIVE_lost_time\"]))\n",
    "    if tamanho > 10:\n",
    "        data_dataframe.loc[indice, \"FUNIL_ASSINATURA_PIPEDRIVE_lost_time\"] = data_dataframe.loc[indice, \"FUNIL_ASSINATURA_PIPEDRIVE_lost_time\"][:10]\t\n",
    "\n",
    "for indice, valor in data_dataframe[\"FUNIL_ASSINATURA_PIPEDRIVE_lost_time\"].items():\n",
    "    data_dataframe.loc[indice, \"FUNIL_ASSINATURA_PIPEDRIVE_lost_time\"] = pd.to_datetime(data_dataframe.loc[indice, \"FUNIL_ASSINATURA_PIPEDRIVE_lost_time\"], format='%Y-%m-%d', errors='coerce')\n",
    "    data_dataframe.loc[indice, \"FUNIL_ASSINATURA_PIPEDRIVE_lost_time\"] = data_dataframe.loc[indice, \"FUNIL_ASSINATURA_PIPEDRIVE_lost_time\"].strftime('%Y-%m-%d')\n",
    "\n",
    "tempo_permanencia = []\n",
    "\n",
    "for indice, valor in data_dataframe[\"FUNIL_ASSINATURA_PIPEDRIVE_start_of_service\"].items():\n",
    "    if pd.notna(valor):\n",
    "        index = data_dataframe.loc[indice, \"FUNIL_ASSINATURA_PIPEDRIVE_start_of_service\"].find(\";\")\n",
    "        if index != -1:\n",
    "            data_dataframe.loc[indice, \"FUNIL_ASSINATURA_PIPEDRIVE_start_of_service\"] = data_dataframe.loc[indice, \"FUNIL_ASSINATURA_PIPEDRIVE_start_of_service\"][:index]\n",
    "\n",
    "for indice, valor in data_dataframe[\"FUNIL_ASSINATURA_PIPEDRIVE_lost_time\"].items():\n",
    "    if pd.notna(data_dataframe.loc[indice, \"FUNIL_ASSINATURA_PIPEDRIVE_start_of_service\"]):\n",
    "        tempo_1 = datetime.strptime(data_dataframe.loc[indice, \"FUNIL_ASSINATURA_PIPEDRIVE_lost_time\"], '%Y-%m-%d')\n",
    "        tempo_2 = datetime.strptime(data_dataframe.loc[indice, \"FUNIL_ASSINATURA_PIPEDRIVE_start_of_service\"], '%Y-%m-%d')\n",
    "        tempo_permanencia.append(str(tempo_1 - tempo_2))\n",
    "    else:\n",
    "        tempo_1 = datetime.strptime(data_dataframe.loc[indice, \"FUNIL_ASSINATURA_PIPEDRIVE_lost_time\"], '%Y-%m-%d')\n",
    "        tempo_2 = datetime.strptime(data_dataframe.loc[indice, \"PESSOA_PIPEDRIVE_contract_start_date\"], '%Y-%m-%d')\n",
    "        tempo_permanencia.append(str(tempo_1 - tempo_2))\n",
    "\n",
    "data_dataframe['stay_time'] = tempo_permanencia\n",
    "\n",
    "for indice, valor in data_dataframe[\"stay_time\"].items():\n",
    "    index = data_dataframe.loc[indice, \"stay_time\"].find(\",\")\n",
    "    if index != -1:\n",
    "        data_dataframe.loc[indice, \"stay_time\"] = data_dataframe.loc[indice, \"stay_time\"][:index]\n",
    "\n",
    "for indice, valor in data_dataframe[\"FUNIL_ASSINATURA_PIPEDRIVE_lost_reason\"].items():\n",
    "    if pd.notna(valor):  \n",
    "        index = data_dataframe.loc[indice, \"FUNIL_ASSINATURA_PIPEDRIVE_lost_reason\"].find(\";\")\n",
    "        if index != -1: \n",
    "            data_dataframe.loc[indice, \"FUNIL_ASSINATURA_PIPEDRIVE_lost_reason\"] = data_dataframe.loc[indice, \"FUNIL_ASSINATURA_PIPEDRIVE_lost_reason\"][:index]\n",
    "    else:\n",
    "        data_dataframe.loc[indice, \"FUNIL_ASSINATURA_PIPEDRIVE_lost_reason\"] = \"Assinatura ativa\"\n",
    "        \n",
    "    contagem = data_dataframe[\"FUNIL_ASSINATURA_PIPEDRIVE_lost_reason\"].value_counts()\n",
    "\n",
    "    agrupamento = contagem[contagem < 20].index\n",
    "    data_dataframe.loc[data_dataframe[\"FUNIL_ASSINATURA_PIPEDRIVE_lost_reason\"].isin(agrupamento), \"FUNIL_ASSINATURA_PIPEDRIVE_lost_reason\"] = \"Outro\"\n",
    "\n",
    "data_dataframe['FUNIL_ONBOARDING_PIPEDRIVE_add_time'].fillna('Não iniciado', inplace=True)\n",
    "\n",
    "ultimos_estados = []\n",
    "\n",
    "for indice, valor in data_dataframe[\"FUNIL_ONBOARDING_PIPEDRIVE_add_time\"].items():\n",
    "    if valor != \"Não iniciado\":\n",
    "        if pd.notna(data_dataframe.loc[indice, \"FUNIL_ONBOARDING_PIPEDRIVE_stay_in_pipeline_stages_welcome\"]):\n",
    "            if pd.notna(data_dataframe.loc[indice, \"FUNIL_ONBOARDING_PIPEDRIVE_stay_in_pipeline_stages_first_meeting\"]):\n",
    "                if pd.notna(data_dataframe.loc[indice, \"FUNIL_ONBOARDING_PIPEDRIVE_stay_in_pipeline_stages_whoqol\"]):\n",
    "                    ultimos_estados.append(\"Questionário\")\n",
    "                else:\n",
    "                    ultimos_estados.append(\"Primeira reunião\")\n",
    "            else:\n",
    "                ultimos_estados.append(\"Boas-vindas\")\n",
    "        \n",
    "    else:\n",
    "        ultimos_estados.append(\"Não iniciado\")\n",
    "\n",
    "data_dataframe[\"last_stage_concluded\"] = ultimos_estados\n",
    "\n",
    "data_dataframe.drop([\"FUNIL_ONBOARDING_PIPEDRIVE_stay_in_pipeline_stages_welcome\", \"FUNIL_ONBOARDING_PIPEDRIVE_stay_in_pipeline_stages_first_meeting\", \"FUNIL_ONBOARDING_PIPEDRIVE_stay_in_pipeline_stages_whoqol\"], axis=1, inplace=True)\n",
    "\n",
    "data_dataframe[\"FUNIL_ONBOARDING_PIPEDRIVE_status\"].fillna(\"Não iniciado\", inplace=True)\n",
    "\n",
    "tempo = []\n",
    "\n",
    "for indice, valor in data_dataframe[\"FUNIL_ONBOARDING_PIPEDRIVE_add_time\"].items():\n",
    "    if valor != \"Não iniciado\":\n",
    "        if pd.notna(data_dataframe.loc[indice, \"FUNIL_ONBOARDING_PIPEDRIVE_lost_time\"]) == True:\n",
    "            tempo.append(data_dataframe.loc[indice, \"FUNIL_ONBOARDING_PIPEDRIVE_lost_time\"])\n",
    "        elif pd.notna(data_dataframe.loc[indice, \"FUNIL_ONBOARDING_PIPEDRIVE_won_time\"]) == True:\n",
    "            tempo.append(data_dataframe.loc[indice, \"FUNIL_ONBOARDING_PIPEDRIVE_won_time\"])\n",
    "        else:\n",
    "            tempo.append(\"Em aberto\")\n",
    "    else:\n",
    "        tempo.append(\"Não iniciado\")\n",
    "\n",
    "data_dataframe['process_time'] = tempo\n",
    "\n",
    "data_dataframe.drop([\"FUNIL_ONBOARDING_PIPEDRIVE_won_time\", \"FUNIL_ONBOARDING_PIPEDRIVE_lost_time\"], axis=1, inplace=True)\n",
    "\n",
    "data_dataframe[\"FUNIL_ONBOARDING_PIPEDRIVE_activities_count\"] = data_dataframe[\"FUNIL_ONBOARDING_PIPEDRIVE_activities_count\"].fillna(0)\n",
    "\n",
    "data_dataframe[\"ATENDIMENTOS_AGENDA_Qde Atendimento Médico\"] = data_dataframe[\"ATENDIMENTOS_AGENDA_Qde Atendimento Médico\"].fillna(0)\n",
    "\n",
    "data_dataframe[\"ATENDIMENTOS_AGENDA_Faltas Atendimento Médico\"] = data_dataframe[\"ATENDIMENTOS_AGENDA_Faltas Atendimento Médico\"].fillna(0)\n",
    "\n",
    "data_dataframe[\"ATENDIMENTOS_AGENDA_Datas Atendimento Médico\"] = data_dataframe[\"ATENDIMENTOS_AGENDA_Datas Atendimento Médico\"].fillna(\"Nunca ocorreu\")\n",
    "\n",
    "for indice, valor in data_dataframe[\"FUNIL_ONBOARDING_PIPEDRIVE_lost_reason\"].items():\n",
    "    if pd.notna(valor) == False:\n",
    "        if pd.notna(data_dataframe.loc[indice, \"FUNIL_ONBOARDING_PIPEDRIVE_status\"]) == False and pd.notna(data_dataframe.loc[indice, \"FUNIL_ONBOARDING_PIPEDRIVE_add_time\"]):\n",
    "            data_dataframe.loc[indice, \"FUNIL_ONBOARDING_PIPEDRIVE_lost_reason\"] = \"Processo em aberto\"\n",
    "        if data_dataframe.loc[indice, \"FUNIL_ONBOARDING_PIPEDRIVE_status\"] == \"won\":\n",
    "            data_dataframe.loc[indice, \"FUNIL_ONBOARDING_PIPEDRIVE_lost_reason\"] = \"Processo concluído\"\n",
    "        else:\n",
    "            data_dataframe.loc[indice, \"FUNIL_ONBOARDING_PIPEDRIVE_lost_reason\"] = \"Processo não iniciado\"\n",
    "\n",
    "    contagem = data_dataframe[\"FUNIL_ONBOARDING_PIPEDRIVE_lost_reason\"].value_counts()\n",
    "\n",
    "    agrupamento = contagem[contagem < 23].index\n",
    "    data_dataframe.loc[data_dataframe[\"FUNIL_ONBOARDING_PIPEDRIVE_lost_reason\"].isin(agrupamento), \"FUNIL_ONBOARDING_PIPEDRIVE_lost_reason\"] = \"Outro\"\n",
    "\n",
    "data_dataframe[\"ATENDIMENTOS_AGENDA_Qde Atendimentos Acolhimento\"] = data_dataframe[\"ATENDIMENTOS_AGENDA_Qde Atendimentos Acolhimento\"].fillna(0)\n",
    "\n",
    "data_dataframe[\"ATENDIMENTOS_AGENDA_Faltas Acolhimento\"] = data_dataframe[\"ATENDIMENTOS_AGENDA_Faltas Acolhimento\"].fillna(0)\n",
    "\n",
    "data_dataframe[\"ATENDIMENTOS_AGENDA_Datas Acolhimento\"] = data_dataframe[\"ATENDIMENTOS_AGENDA_Datas Acolhimento\"].fillna(\"Nunca ocorreu\")\n",
    "\n",
    "data_dataframe[\"ATENDIMENTOS_AGENDA_Qde Psicoterapia\"] = data_dataframe[\"ATENDIMENTOS_AGENDA_Qde Psicoterapia\"].fillna(0)\n",
    "\n",
    "# preprocessing 4\n",
    "\n",
    "data_dataframe[\"TWILIO_Mensagens Outbound\"].fillna(0, inplace=True)\n",
    "\n",
    "data_dataframe[\"TWILIO_Data Última Mensagens Outbound\"] = pd.to_datetime(data_dataframe[\"TWILIO_Data Última Mensagens Outbound\"])\n",
    "\n",
    "data_dataframe[\"TWILIO_Data Última Mensagens Outbound Tempo passado\"] = datetime.now() - data_dataframe[\"TWILIO_Data Última Mensagens Outbound\"]\n",
    "\n",
    "data_dataframe[\"TWILIO_Data Última Mensagens Outbound Tempo passado\"].fillna('', inplace=True)\n",
    "\n",
    "data_dataframe[\"TWILIO_Data Última Mensagens Outbound Tempo passado\"] = data_dataframe[\"TWILIO_Data Última Mensagens Outbound Tempo passado\"].astype(str)\n",
    "\n",
    "data_dataframe[\"TWILIO_Data Última Mensagens Outbound Tempo passado\"] = data_dataframe[\"TWILIO_Data Última Mensagens Outbound Tempo passado\"].str.extract('(\\d+) days').astype(float)\n",
    "\n",
    "data_dataframe = data_dataframe.drop([\"TWILIO_Data Última Mensagens Outbound\"], axis=1)\n",
    "\n",
    "data_dataframe[\"TWILIO_Data Última Mensagens Outbound Recente\"] = data_dataframe[\"TWILIO_Data Última Mensagens Outbound Tempo passado\"] < data_dataframe[\"TWILIO_Data Última Mensagens Outbound Tempo passado\"].median()\n",
    "data_dataframe[\"TWILIO_Data Última Mensagens Outbound Recente\"].fillna(0)\n",
    "data_dataframe[\"TWILIO_Data Última Mensagens Outbound Recente\"].replace(True, 1, inplace=True)\n",
    "data_dataframe[\"TWILIO_Data Última Mensagens Outbound Recente\"].replace(False, 0, inplace=True)\n",
    "\n",
    "data_dataframe = data_dataframe.drop([\"TWILIO_Data Última Mensagens Outbound Tempo passado\"], axis=1)\n",
    "\n",
    "data_dataframe[\"TWILIO_Ligações Outbound\"].fillna(0, inplace=True)\n",
    "\n",
    "data_dataframe[\"TWILIO_Data Última Ligações Outbound\"] = pd.to_datetime(data_dataframe[\"TWILIO_Data Última Ligações Outbound\"])\n",
    "\n",
    "data_dataframe[\"TWILIO_Data Última Ligações Outbound Tempo passado\"] = datetime.now() - data_dataframe[\"TWILIO_Data Última Ligações Outbound\"]\n",
    "\n",
    "data_dataframe[\"TWILIO_Data Última Ligações Outbound Tempo passado\"].fillna('', inplace=True)\n",
    "\n",
    "data_dataframe[\"TWILIO_Data Última Ligações Outbound Tempo passado\"] = data_dataframe[\"TWILIO_Data Última Ligações Outbound Tempo passado\"].astype(str)\n",
    "\n",
    "data_dataframe[\"TWILIO_Data Última Ligações Outbound Tempo passado\"] = data_dataframe[\"TWILIO_Data Última Ligações Outbound Tempo passado\"].str.extract('(\\d+) days').astype(float)\n",
    "\n",
    "data_dataframe = data_dataframe.drop([\"TWILIO_Data Última Ligações Outbound\"], axis=1)\n",
    "\n",
    "data_dataframe[\"TWILIO_Data Última Ligações Outbound Recente\"] = data_dataframe[\"TWILIO_Data Última Ligações Outbound Tempo passado\"] < data_dataframe[\"TWILIO_Data Última Ligações Outbound Tempo passado\"].median()\n",
    "data_dataframe[\"TWILIO_Data Última Ligações Outbound Recente\"].fillna(0)\n",
    "data_dataframe[\"TWILIO_Data Última Ligações Outbound Recente\"].replace(True, 1, inplace=True)\n",
    "data_dataframe[\"TWILIO_Data Última Ligações Outbound Recente\"].replace(False, 0, inplace=True)\n",
    "\n",
    "data_dataframe = data_dataframe.drop([\"TWILIO_Data Última Ligações Outbound Tempo passado\"], axis=1)\n",
    "\n",
    "data_dataframe = data_dataframe.drop([\"COBRANÇA_VINDI_Qde Perfis de Pagamento Inativos\"], axis=1)\n",
    "\n",
    "# preprocessing especials \n",
    "\n",
    "data_dataframe = data_dataframe[data_dataframe['FUNIL_ASSINATURA_PIPEDRIVE_status'].isin(['won', 'lost'])]\n",
    "\n",
    "data_dataframe = data_dataframe.drop(data_dataframe[(data_dataframe['FUNIL_ASSINATURA_PIPEDRIVE_status'] == 'won') & (~data_dataframe['PESSOA_PIPEDRIVE_contract_end_date'].isnull())].index)\n",
    "\n",
    "data_dataframe = data_dataframe.drop(data_dataframe[(data_dataframe['FUNIL_ASSINATURA_PIPEDRIVE_status'] == 'lost') & (data_dataframe['PESSOA_PIPEDRIVE_contract_end_date'].isnull())].index)\n",
    "\n",
    "#exportando df pronto\n",
    "\n",
    "data_dataframe.to_csv('../notebooks/data/data-preprocessed.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEU RUIM\n"
     ]
    }
   ],
   "source": [
    "df_pimba = preprocessing(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data-engineering.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/st4pzz/Desktop/insper_2023.2/SPRINT/sprint4-support-vector-team/src/scripts/teste.ipynb Célula 5\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/st4pzz/Desktop/insper_2023.2/SPRINT/sprint4-support-vector-team/src/scripts/teste.ipynb#W3sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39m\"\u001b[39;49m\u001b[39mdata-engineering.csv\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m~/Desktop/insper_2023.2/SPRINT/sprint4-support-vector-team/env/lib/python3.9/site-packages/pandas/io/parsers/readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    944\u001b[0m     dtype_backend\u001b[39m=\u001b[39mdtype_backend,\n\u001b[1;32m    945\u001b[0m )\n\u001b[1;32m    946\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 948\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/Desktop/insper_2023.2/SPRINT/sprint4-support-vector-team/env/lib/python3.9/site-packages/pandas/io/parsers/readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    608\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m    610\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 611\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    613\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[1;32m    614\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/Desktop/insper_2023.2/SPRINT/sprint4-support-vector-team/env/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1445\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m   1447\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1448\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[0;32m~/Desktop/insper_2023.2/SPRINT/sprint4-support-vector-team/env/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1703\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode:\n\u001b[1;32m   1704\u001b[0m         mode \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m-> 1705\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[1;32m   1706\u001b[0m     f,\n\u001b[1;32m   1707\u001b[0m     mode,\n\u001b[1;32m   1708\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1709\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1710\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[1;32m   1711\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[1;32m   1712\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1713\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1714\u001b[0m )\n\u001b[1;32m   1715\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1716\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/Desktop/insper_2023.2/SPRINT/sprint4-support-vector-team/env/lib/python3.9/site-packages/pandas/io/common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    858\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    859\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    860\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[1;32m    862\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[0;32m--> 863\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[1;32m    864\u001b[0m             handle,\n\u001b[1;32m    865\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[1;32m    866\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[1;32m    867\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[1;32m    868\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    869\u001b[0m         )\n\u001b[1;32m    870\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    871\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[1;32m    872\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data-engineering.csv'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"data-engineering.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'FUNIL_ASSINATURA_PIPEDRIVE_id_stage'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/Desktop/insper_2023.2/SPRINT/sprint4-support-vector-team/env/lib/python3.9/site-packages/pandas/core/indexes/base.py:3790\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3789\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3790\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   3791\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:152\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:181\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'FUNIL_ASSINATURA_PIPEDRIVE_id_stage'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/Users/st4pzz/Desktop/insper_2023.2/SPRINT/sprint4-support-vector-team/src/scripts/teste.ipynb Célula 5\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/st4pzz/Desktop/insper_2023.2/SPRINT/sprint4-support-vector-team/src/scripts/teste.ipynb#X24sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m df[\u001b[39m\"\u001b[39;49m\u001b[39mFUNIL_ASSINATURA_PIPEDRIVE_id_stage\u001b[39;49m\u001b[39m\"\u001b[39;49m]\u001b[39m.\u001b[39mvalue_counts()\n",
      "File \u001b[0;32m~/Desktop/insper_2023.2/SPRINT/sprint4-support-vector-team/env/lib/python3.9/site-packages/pandas/core/frame.py:3893\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3891\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   3892\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3893\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[1;32m   3894\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3895\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/Desktop/insper_2023.2/SPRINT/sprint4-support-vector-team/env/lib/python3.9/site-packages/pandas/core/indexes/base.py:3797\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3792\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(casted_key, \u001b[39mslice\u001b[39m) \u001b[39mor\u001b[39;00m (\n\u001b[1;32m   3793\u001b[0m         \u001b[39misinstance\u001b[39m(casted_key, abc\u001b[39m.\u001b[39mIterable)\n\u001b[1;32m   3794\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39many\u001b[39m(\u001b[39misinstance\u001b[39m(x, \u001b[39mslice\u001b[39m) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m casted_key)\n\u001b[1;32m   3795\u001b[0m     ):\n\u001b[1;32m   3796\u001b[0m         \u001b[39mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3797\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3798\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3799\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3800\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3801\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3802\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'FUNIL_ASSINATURA_PIPEDRIVE_id_stage'"
     ]
    }
   ],
   "source": [
    "df[\"FUNIL_ASSINATURA_PIPEDRIVE_id_stage\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PESSOA_PIPEDRIVE_Canal de Preferência\n",
       "0      571\n",
       "239    379\n",
       "238     12\n",
       "360     11\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"PESSOA_PIPEDRIVE_Canal de Preferência\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Estado_Mato Grosso do Sul</th>\n",
       "      <th>Estado_Minas Gerais</th>\n",
       "      <th>Estado_Paraná</th>\n",
       "      <th>Estado_Paraíba</th>\n",
       "      <th>Estado_Pará</th>\n",
       "      <th>Estado_Pernambuco</th>\n",
       "      <th>Estado_Piauí</th>\n",
       "      <th>Estado_Rio Grande do Norte</th>\n",
       "      <th>Estado_Rio Grande do Sul</th>\n",
       "      <th>Estado_Rio de Janeiro</th>\n",
       "      <th>Estado_Santa Catarina</th>\n",
       "      <th>Estado_Sergipe</th>\n",
       "      <th>Estado_State of Amazonas</th>\n",
       "      <th>Estado_São Paulo</th>\n",
       "      <th>PESSOA_PIPEDRIVE_city Codificada</th>\n",
       "      <th>status_lost</th>\n",
       "      <th>status_won</th>\n",
       "      <th>lost_reason_Outro</th>\n",
       "      <th>lost_reason_[Assinatura] Cancelamento por inadimplência</th>\n",
       "      <th>lost_reason_[Assinatura] Desligamento</th>\n",
       "      <th>lost_reason_[Assinatura] Empresa cancelou o benefício da Ana</th>\n",
       "      <th>lost_reason_[Assinatura] Está sem tempo para conciliar os atendimentos</th>\n",
       "      <th>lost_reason_[Assinatura] Não quer seguir com a Ana</th>\n",
       "      <th>lost_reason_[Assinatura] Precisou cortar custos</th>\n",
       "      <th>Status_Não iniciado</th>\n",
       "      <th>Status_lost</th>\n",
       "      <th>Status_open</th>\n",
       "      <th>Status_won</th>\n",
       "      <th>lost_reason_Outro.1</th>\n",
       "      <th>lost_reason_[Associade] Cancelou assinatura</th>\n",
       "      <th>lost_reason_[Onboarding] Não retornou aos contatos de resgate</th>\n",
       "      <th>lost_reason_[Onboarding] Não tem interesse em seguir nas etapas do onboarding</th>\n",
       "      <th>stage_Boas-vindas</th>\n",
       "      <th>stage_Não iniciado</th>\n",
       "      <th>stage_Primeira reunião</th>\n",
       "      <th>stage_Questionário</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>32</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>32</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Estado_Mato Grosso do Sul  ...  stage_Questionário\n",
       "0                      False  ...                True\n",
       "1                      False  ...                True\n",
       "2                      False  ...                True\n",
       "3                      False  ...                True\n",
       "4                      False  ...                True\n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[:,60:].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "\n",
    "def column_label_to_index(col_label):\n",
    "    col_index = 0\n",
    "    for c in col_label.upper():\n",
    "        col_index = col_index * 26 + (ord(c) - ord('A') + 1)\n",
    "    return col_index - 1\n",
    "\n",
    "def add_prefix_to_columns(dataframe, prefix):\n",
    "    for col in dataframe.columns:\n",
    "        new_col_name = prefix + str(col)\n",
    "        dataframe.rename(columns={col: new_col_name}, inplace=True)\n",
    "\n",
    "\n",
    "def mergeHeader_Columns(data):\n",
    "    add_prefix_to_columns(data, 'PESSOA_PIPEDRIVE_')\n",
    "    add_prefix_to_columns(data, 'FUNIL_ASSINATURA_PIPEDRIVE_')\n",
    "    add_prefix_to_columns(data, 'FUNIL_ONBOARDING_PIPEDRIVE_')\n",
    "    add_prefix_to_columns(data, 'ATENDIMENTOS_AGENDA_')\n",
    "    add_prefix_to_columns(data, 'WHOQOL_')\n",
    "    add_prefix_to_columns(data, 'COMUNICARE_')\n",
    "    add_prefix_to_columns(data, 'TWILIO_')\n",
    "    add_prefix_to_columns(data, 'COBRANÇA_VINDI_')\n",
    "\n",
    "    return data\n",
    "\n",
    "def preprocessing(data_dataframe):\n",
    "    from sklearn.impute import SimpleImputer\n",
    "\n",
    "    # try:\n",
    "    data_dataframe = mergeHeader_Columns(data_dataframe)\n",
    "    data_dataframe = pd.DataFrame(data_dataframe.iloc[50])\n",
    "    # preprocessing 1\n",
    "    data_dataframe = data_dataframe.drop([\"PESSOA_PIPEDRIVE_id_person_recommendation\",\"PESSOA_PIPEDRIVE_Recebe Comunicados?\", \"PESSOA_PIPEDRIVE_Interesses\", \"PESSOA_PIPEDRIVE_Pontos de Atenção\", \"FUNIL_ONBOARDING_PIPEDRIVE_id_label\"], axis=1)\n",
    "\n",
    "    data_dataframe['PESSOA_PIPEDRIVE_birthdate'] = pd.to_datetime(data_dataframe['PESSOA_PIPEDRIVE_birthdate'])\n",
    "    data_dataframe['PESSOA_PIPEDRIVE_age'] = data_dataframe['PESSOA_PIPEDRIVE_birthdate'].apply(\n",
    "        lambda x: datetime.today().year - x.year - ((datetime.today().month, datetime.today().day) < (x.month, x.day))\n",
    "    )\n",
    "\n",
    "    imputer = SimpleImputer(strategy='mean')\n",
    "    data_dataframe['PESSOA_PIPEDRIVE_age'] = imputer.fit_transform(data_dataframe['PESSOA_PIPEDRIVE_age'].values.reshape(-1, 1))\n",
    "    data_dataframe['PESSOA_PIPEDRIVE_age'] = np.round(data_dataframe['PESSOA_PIPEDRIVE_age']).astype(int)\n",
    "\n",
    "    data_dataframe = data_dataframe.drop(['PESSOA_PIPEDRIVE_birthdate'], axis=1 )\n",
    "\n",
    "    rows_to_drop = data_dataframe[data_dataframe[\"PESSOA_PIPEDRIVE_id_gender\"].isin([117,110,111])]\n",
    "    data_dataframe = data_dataframe.drop(rows_to_drop.index, axis=0)\n",
    "    data_dataframe[\"PESSOA_PIPEDRIVE_id_gender\"].fillna(64, inplace=True)\n",
    "    data_dataframe[\"PESSOA_PIPEDRIVE_id_marrital_status\"].fillna(80, inplace=True)\n",
    "\n",
    "    \n",
    "    data_dataframe[\"PESSOA_PIPEDRIVE_state\"].fillna(data_dataframe[\"PESSOA_PIPEDRIVE_state\"].mode()[0], inplace=True)\n",
    "\n",
    "\n",
    "    data_dataframe[\"PESSOA_PIPEDRIVE_city\"].fillna(data_dataframe[\"PESSOA_PIPEDRIVE_city\"].mode()[0], inplace=True)\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    data_dataframe['PESSOA_PIPEDRIVE_id_health_plan'].fillna(data_dataframe['PESSOA_PIPEDRIVE_id_health_plan'].mode()[0], inplace=True)\n",
    "    data_dataframe['PESSOA_PIPEDRIVE_has_public_health_plan'] = data_dataframe['PESSOA_PIPEDRIVE_id_health_plan'].apply(lambda x: 1 if int(x) == 412 else 0)\n",
    "    data_dataframe = data_dataframe.drop(['PESSOA_PIPEDRIVE_id_health_plan'], axis=1)\n",
    "    data_dataframe[\"PESSOA_PIPEDRIVE_tem_data_dataframe_de_termino_de_contrato\"] = data_dataframe[\"PESSOA_PIPEDRIVE_contract_end_date\"].apply(lambda x: 0 if pd.isna(x) else 1)\n",
    "    data_dataframe.drop([\"PESSOA_PIPEDRIVE_id_continuity_pf\"], axis=1, inplace=True)\n",
    "    data_dataframe[\"PESSOA_PIPEDRIVE_Canal de Preferência\"].fillna(0, inplace=True)\n",
    "    data_dataframe[\"PESSOA_PIPEDRIVE_Tem_Canal_de_Preferência\"] = data_dataframe[\"PESSOA_PIPEDRIVE_Canal de Preferência\"].apply(lambda x: 1 if int(x) > 0  else 0)\n",
    "    data_dataframe[\"PESSOA_PIPEDRIVE_has_notes\"] = data_dataframe[\"PESSOA_PIPEDRIVE_notes_count\"].apply(lambda x: 1 if int(x) > 0 else 0)\n",
    "    \n",
    "    # preprocessing 2\n",
    "    data_dataframe = data_dataframe.drop([\"ATENDIMENTOS_AGENDA_Faltas Psicoterapia\",\"TWILIO_Ligações Inbound\", \"TWILIO_Data Última Ligações Inbound\",\"COBRANÇA_VINDI_Qde Total de Faturas\",\"COBRANÇA_VINDI_Qde Total de Tentativas de Cobrança\",\"COBRANÇA_VINDI_Método de Pagamento\",\"COBRANÇA_VINDI_Valor Médio da Mensalidade\",\"COBRANÇA_VINDI_Qde Total de Faturas Pagas após Vencimento\",\"COBRANÇA_VINDI_Qde Total de Faturas Inadimpletes\",\"COBRANÇA_VINDI_Valor Total Inadimplência\"], axis=1)\n",
    "\n",
    "    data_dataframe[\"ATENDIMENTOS_AGENDA_Qde Psicoterapia\"].fillna(0, inplace=True)\n",
    "    \n",
    "\n",
    "\n",
    "    data_dataframe = data_dataframe.drop(columns=\"WHOQOL_Qde Respostas WHOQOL\")\n",
    "\n",
    "    data_dataframe[\"WHOQOL_Físico_New\"] = data_dataframe[\"WHOQOL_Físico\"].str.split(';').str[-1].str.strip()\n",
    "\n",
    "    data_dataframe[\"WHOQOL_Físico_New\"] = data_dataframe[\"WHOQOL_Físico_New\"].str.replace(\",\",\".\")\n",
    "\n",
    "    data_dataframe[\"WHOQOL_Físico_New\"] = data_dataframe[\"WHOQOL_Físico_New\"].astype(float) \n",
    "\n",
    "    data_dataframe[\"WHOQOL_Físico_New\"] = data_dataframe[\"WHOQOL_Físico_New\"].fillna(data_dataframe[\"WHOQOL_Físico_New\"].median())\n",
    "\n",
    "    data_dataframe[\"WHOQOL_Psicológico_New\"] = data_dataframe[\"WHOQOL_Psicológico\"].str.split(';').str[-1].str.strip()\n",
    "\n",
    "    data_dataframe[\"WHOQOL_Psicológico_New\"] = data_dataframe[\"WHOQOL_Psicológico_New\"].str.replace(\",\",\".\")\n",
    "\n",
    "    data_dataframe[\"WHOQOL_Psicológico_New\"] = data_dataframe[\"WHOQOL_Psicológico_New\"].astype(float) \n",
    "\n",
    "    data_dataframe[\"WHOQOL_Psicológico_New\"] = data_dataframe[\"WHOQOL_Psicológico_New\"].fillna(data_dataframe[\"WHOQOL_Psicológico_New\"].median())\n",
    "\n",
    "    data_dataframe[\"WHOQOL_Social_New\"] = data_dataframe[\"WHOQOL_Social\"].str.split(';').str[-1].str.strip()\n",
    "\n",
    "    data_dataframe[\"WHOQOL_Social_New\"] = data_dataframe[\"WHOQOL_Social_New\"].str.replace(\",\",\".\")\n",
    "\n",
    "    data_dataframe[\"WHOQOL_Social_New\"] = data_dataframe[\"WHOQOL_Social_New\"].astype(float) \n",
    "\n",
    "    data_dataframe[\"WHOQOL_Social_New\"] = data_dataframe[\"WHOQOL_Social_New\"].fillna(data_dataframe[\"WHOQOL_Social_New\"].median())\n",
    "\n",
    "    data_dataframe[\"WHOQOL_Ambiental_New\"] = data_dataframe[\"WHOQOL_Ambiental\"].str.split(';').str[-1].str.strip()\n",
    "\n",
    "    data_dataframe[\"WHOQOL_Ambiental_New\"] = data_dataframe[\"WHOQOL_Ambiental_New\"].str.replace(\",\",\".\")\n",
    "\n",
    "    data_dataframe[\"WHOQOL_Ambiental_New\"] = data_dataframe[\"WHOQOL_Ambiental_New\"].astype(float) \n",
    "\n",
    "    data_dataframe[\"WHOQOL_Ambiental_New\"] = data_dataframe[\"WHOQOL_Ambiental_New\"].fillna(data_dataframe[\"WHOQOL_Ambiental_New\"].median())\n",
    "\n",
    "    data_dataframe[\"COMUNICARE_Problemas Abertos Bool\"] = data_dataframe[\"COMUNICARE_Problemas Abertos\"].notnull().astype(int)\n",
    "\n",
    "    data_dataframe[\"COMUNICARE_Problemas Abertos Bool\"].fillna(0, inplace=True)\n",
    "\n",
    "    data_dataframe[\"TWILIO_Mensagens Inbound\"].fillna(0, inplace=True)\n",
    "\n",
    "    data_dataframe[\"TWILIO_Data Última Mensagens Inbound\"] = pd.to_datetime(data_dataframe[\"TWILIO_Data Última Mensagens Inbound\"])\n",
    "\n",
    "    data_dataframe[\"TWILIO_Data Última Mensagens Inbound Tempo Passado\"] = datetime.now() - data_dataframe[\"TWILIO_Data Última Mensagens Inbound\"]\n",
    "\n",
    "    data_dataframe[\"TWILIO_Data Última Mensagens Inbound Tempo Passado\"].fillna('', inplace=True)\n",
    "\n",
    "    data_dataframe[\"TWILIO_Data Última Mensagens Inbound Tempo Passado\"] = data_dataframe[\"TWILIO_Data Última Mensagens Inbound Tempo Passado\"].astype(str)\n",
    "\n",
    "    data_dataframe[\"TWILIO_Data Última Mensagens Inbound Tempo Passado\"] = data_dataframe[\"TWILIO_Data Última Mensagens Inbound Tempo Passado\"].str.extract('(\\d+) days').astype(float)\n",
    "\n",
    "    data_dataframe[\"TWILIO_Data Última Mensagens Inbound Recente\"] = data_dataframe[\"TWILIO_Data Última Mensagens Inbound Tempo Passado\"] < data_dataframe[\"TWILIO_Data Última Mensagens Inbound Tempo Passado\"].median()\n",
    "    data_dataframe[\"TWILIO_Data Última Mensagens Inbound Recente\"].fillna(0)\n",
    "    data_dataframe[\"TWILIO_Data Última Mensagens Inbound Recente\"].replace(True, 1, inplace=True)\n",
    "    data_dataframe[\"TWILIO_Data Última Mensagens Inbound Recente\"].replace(False, 0, inplace=True)\n",
    "\n",
    "    data_dataframe = data_dataframe.drop(columns=[\"WHOQOL_Ambiental\",\"WHOQOL_Social\",\"WHOQOL_Físico\",\"WHOQOL_Psicológico\",\"COMUNICARE_Problemas Abertos\",\"TWILIO_Data Última Mensagens Inbound\",\"ATENDIMENTOS_AGENDA_Datas Psicoterapia\",\"TWILIO_Data Última Mensagens Inbound Tempo Passado\"])\n",
    "    \n",
    "    # preprocessing 3\n",
    "    for indice, valor in data_dataframe[\"FUNIL_ASSINATURA_PIPEDRIVE_lost_time\"].items():\n",
    "        if pd.notna(valor) == False: \n",
    "            if pd.notna(data_dataframe.loc[indice, \"PESSOA_PIPEDRIVE_contract_end_date\"]):\n",
    "                data_dataframe.loc[indice, \"FUNIL_ASSINATURA_PIPEDRIVE_lost_time\"] = data_dataframe.loc[indice, \"PESSOA_PIPEDRIVE_contract_end_date\"]\n",
    "\n",
    "    data_dataframe[\"FUNIL_ASSINATURA_PIPEDRIVE_lost_time\"].fillna(dt.date.today(), inplace=True)\n",
    "\n",
    "    for indice, valor in data_dataframe[\"FUNIL_ASSINATURA_PIPEDRIVE_lost_time\"].items():\n",
    "        index = str(data_dataframe.loc[indice, \"FUNIL_ASSINATURA_PIPEDRIVE_lost_time\"]).find(\";\")\n",
    "        if index != -1:\n",
    "            data_dataframe.loc[indice, \"FUNIL_ASSINATURA_PIPEDRIVE_lost_time\"] = data_dataframe.loc[indice, \"FUNIL_ASSINATURA_PIPEDRIVE_lost_time\"][:index]\n",
    "\n",
    "    for indice, valor in data_dataframe[\"FUNIL_ASSINATURA_PIPEDRIVE_lost_time\"].items():\n",
    "        tamanho = len(str(data_dataframe.loc[indice, \"FUNIL_ASSINATURA_PIPEDRIVE_lost_time\"]))\n",
    "        if tamanho > 10:\n",
    "            data_dataframe.loc[indice, \"FUNIL_ASSINATURA_PIPEDRIVE_lost_time\"] = data_dataframe.loc[indice, \"FUNIL_ASSINATURA_PIPEDRIVE_lost_time\"][:10]\t\n",
    "\n",
    "    for indice, valor in data_dataframe[\"FUNIL_ASSINATURA_PIPEDRIVE_lost_time\"].items():\n",
    "        data_dataframe.loc[indice, \"FUNIL_ASSINATURA_PIPEDRIVE_lost_time\"] = pd.to_datetime(data_dataframe.loc[indice, \"FUNIL_ASSINATURA_PIPEDRIVE_lost_time\"], format='%Y-%m-%d', errors='coerce')\n",
    "        data_dataframe.loc[indice, \"FUNIL_ASSINATURA_PIPEDRIVE_lost_time\"] = data_dataframe.loc[indice, \"FUNIL_ASSINATURA_PIPEDRIVE_lost_time\"].strftime('%Y-%m-%d')\n",
    "\n",
    "    tempo_permanencia = []\n",
    "\n",
    "    for indice, valor in data_dataframe[\"FUNIL_ASSINATURA_PIPEDRIVE_start_of_service\"].items():\n",
    "        if pd.notna(valor):\n",
    "            index = data_dataframe.loc[indice, \"FUNIL_ASSINATURA_PIPEDRIVE_start_of_service\"].find(\";\")\n",
    "            if index != -1:\n",
    "                data_dataframe.loc[indice, \"FUNIL_ASSINATURA_PIPEDRIVE_start_of_service\"] = data_dataframe.loc[indice, \"FUNIL_ASSINATURA_PIPEDRIVE_start_of_service\"][:index]\n",
    "\n",
    "    for indice, valor in data_dataframe[\"FUNIL_ASSINATURA_PIPEDRIVE_lost_time\"].items():\n",
    "        if pd.notna(data_dataframe.loc[indice, \"FUNIL_ASSINATURA_PIPEDRIVE_start_of_service\"]):\n",
    "            tempo_1 = datetime.strptime(data_dataframe.loc[indice, \"FUNIL_ASSINATURA_PIPEDRIVE_lost_time\"], '%Y-%m-%d')\n",
    "            tempo_2 = datetime.strptime(data_dataframe.loc[indice, \"FUNIL_ASSINATURA_PIPEDRIVE_start_of_service\"], '%Y-%m-%d')\n",
    "            tempo_permanencia.append(str(tempo_1 - tempo_2))\n",
    "        else:\n",
    "            tempo_1 = datetime.strptime(data_dataframe.loc[indice, \"FUNIL_ASSINATURA_PIPEDRIVE_lost_time\"], '%Y-%m-%d')\n",
    "            tempo_2 = datetime.strptime(data_dataframe.loc[indice, \"PESSOA_PIPEDRIVE_contract_start_date\"], '%Y-%m-%d')\n",
    "            tempo_permanencia.append(str(tempo_1 - tempo_2))\n",
    "\n",
    "    data_dataframe['stay_time'] = tempo_permanencia\n",
    "\n",
    "    for indice, valor in data_dataframe[\"stay_time\"].items():\n",
    "        index = data_dataframe.loc[indice, \"stay_time\"].find(\",\")\n",
    "        if index != -1:\n",
    "            data_dataframe.loc[indice, \"stay_time\"] = data_dataframe.loc[indice, \"stay_time\"][:index]\n",
    "\n",
    "    for indice, valor in data_dataframe[\"FUNIL_ASSINATURA_PIPEDRIVE_lost_reason\"].items():\n",
    "        if pd.notna(valor):  \n",
    "            index = data_dataframe.loc[indice, \"FUNIL_ASSINATURA_PIPEDRIVE_lost_reason\"].find(\";\")\n",
    "            if index != -1: \n",
    "                data_dataframe.loc[indice, \"FUNIL_ASSINATURA_PIPEDRIVE_lost_reason\"] = data_dataframe.loc[indice, \"FUNIL_ASSINATURA_PIPEDRIVE_lost_reason\"][:index]\n",
    "        else:\n",
    "            data_dataframe.loc[indice, \"FUNIL_ASSINATURA_PIPEDRIVE_lost_reason\"] = \"Assinatura ativa\"\n",
    "            \n",
    "        contagem = data_dataframe[\"FUNIL_ASSINATURA_PIPEDRIVE_lost_reason\"].value_counts()\n",
    "\n",
    "        agrupamento = contagem[contagem < 20].index\n",
    "        data_dataframe.loc[data_dataframe[\"FUNIL_ASSINATURA_PIPEDRIVE_lost_reason\"].isin(agrupamento), \"FUNIL_ASSINATURA_PIPEDRIVE_lost_reason\"] = \"Outro\"\n",
    "\n",
    "    data_dataframe['FUNIL_ONBOARDING_PIPEDRIVE_add_time'].fillna('Não iniciado', inplace=True)\n",
    "\n",
    "    ultimos_estados = []\n",
    "\n",
    "    for indice, valor in data_dataframe[\"FUNIL_ONBOARDING_PIPEDRIVE_add_time\"].items():\n",
    "        if valor != \"Não iniciado\":\n",
    "            if pd.notna(data_dataframe.loc[indice, \"FUNIL_ONBOARDING_PIPEDRIVE_stay_in_pipeline_stages_welcome\"]):\n",
    "                if pd.notna(data_dataframe.loc[indice, \"FUNIL_ONBOARDING_PIPEDRIVE_stay_in_pipeline_stages_first_meeting\"]):\n",
    "                    if pd.notna(data_dataframe.loc[indice, \"FUNIL_ONBOARDING_PIPEDRIVE_stay_in_pipeline_stages_whoqol\"]):\n",
    "                        ultimos_estados.append(\"Questionário\")\n",
    "                    else:\n",
    "                        ultimos_estados.append(\"Primeira reunião\")\n",
    "                else:\n",
    "                    ultimos_estados.append(\"Boas-vindas\")\n",
    "            \n",
    "        else:\n",
    "            ultimos_estados.append(\"Não iniciado\")\n",
    "\n",
    "    data_dataframe[\"last_stage_concluded\"] = ultimos_estados\n",
    "\n",
    "    data_dataframe.drop([\"FUNIL_ONBOARDING_PIPEDRIVE_stay_in_pipeline_stages_welcome\", \"FUNIL_ONBOARDING_PIPEDRIVE_stay_in_pipeline_stages_first_meeting\", \"FUNIL_ONBOARDING_PIPEDRIVE_stay_in_pipeline_stages_whoqol\"], axis=1, inplace=True)\n",
    "\n",
    "    data_dataframe[\"FUNIL_ONBOARDING_PIPEDRIVE_status\"].fillna(\"Não iniciado\", inplace=True)\n",
    "\n",
    "    tempo = []\n",
    "\n",
    "    for indice, valor in data_dataframe[\"FUNIL_ONBOARDING_PIPEDRIVE_add_time\"].items():\n",
    "        if valor != \"Não iniciado\":\n",
    "            if pd.notna(data_dataframe.loc[indice, \"FUNIL_ONBOARDING_PIPEDRIVE_lost_time\"]) == True:\n",
    "                tempo.append(data_dataframe.loc[indice, \"FUNIL_ONBOARDING_PIPEDRIVE_lost_time\"])\n",
    "            elif pd.notna(data_dataframe.loc[indice, \"FUNIL_ONBOARDING_PIPEDRIVE_won_time\"]) == True:\n",
    "                tempo.append(data_dataframe.loc[indice, \"FUNIL_ONBOARDING_PIPEDRIVE_won_time\"])\n",
    "            else:\n",
    "                tempo.append(\"Em aberto\")\n",
    "        else:\n",
    "            tempo.append(\"Não iniciado\")\n",
    "\n",
    "    data_dataframe['process_time'] = tempo\n",
    "\n",
    "    data_dataframe.drop([\"FUNIL_ONBOARDING_PIPEDRIVE_won_time\", \"FUNIL_ONBOARDING_PIPEDRIVE_lost_time\"], axis=1, inplace=True)\n",
    "\n",
    "    data_dataframe[\"FUNIL_ONBOARDING_PIPEDRIVE_activities_count\"] = data_dataframe[\"FUNIL_ONBOARDING_PIPEDRIVE_activities_count\"].fillna(0)\n",
    "\n",
    "    data_dataframe[\"ATENDIMENTOS_AGENDA_Qde Atendimento Médico\"] = data_dataframe[\"ATENDIMENTOS_AGENDA_Qde Atendimento Médico\"].fillna(0)\n",
    "\n",
    "    data_dataframe[\"ATENDIMENTOS_AGENDA_Faltas Atendimento Médico\"] = data_dataframe[\"ATENDIMENTOS_AGENDA_Faltas Atendimento Médico\"].fillna(0)\n",
    "\n",
    "    data_dataframe[\"ATENDIMENTOS_AGENDA_Datas Atendimento Médico\"] = data_dataframe[\"ATENDIMENTOS_AGENDA_Datas Atendimento Médico\"].fillna(\"Nunca ocorreu\")\n",
    "\n",
    "    for indice, valor in data_dataframe[\"FUNIL_ONBOARDING_PIPEDRIVE_lost_reason\"].items():\n",
    "        if pd.notna(valor) == False:\n",
    "            if pd.notna(data_dataframe.loc[indice, \"FUNIL_ONBOARDING_PIPEDRIVE_status\"]) == False and pd.notna(data_dataframe.loc[indice, \"FUNIL_ONBOARDING_PIPEDRIVE_add_time\"]):\n",
    "                data_dataframe.loc[indice, \"FUNIL_ONBOARDING_PIPEDRIVE_lost_reason\"] = \"Processo em aberto\"\n",
    "            if data_dataframe.loc[indice, \"FUNIL_ONBOARDING_PIPEDRIVE_status\"] == \"won\":\n",
    "                data_dataframe.loc[indice, \"FUNIL_ONBOARDING_PIPEDRIVE_lost_reason\"] = \"Processo concluído\"\n",
    "            else:\n",
    "                data_dataframe.loc[indice, \"FUNIL_ONBOARDING_PIPEDRIVE_lost_reason\"] = \"Processo não iniciado\"\n",
    "\n",
    "        contagem = data_dataframe[\"FUNIL_ONBOARDING_PIPEDRIVE_lost_reason\"].value_counts()\n",
    "\n",
    "        agrupamento = contagem[contagem < 23].index\n",
    "        data_dataframe.loc[data_dataframe[\"FUNIL_ONBOARDING_PIPEDRIVE_lost_reason\"].isin(agrupamento), \"FUNIL_ONBOARDING_PIPEDRIVE_lost_reason\"] = \"Outro\"\n",
    "\n",
    "    data_dataframe[\"ATENDIMENTOS_AGENDA_Qde Atendimentos Acolhimento\"] = data_dataframe[\"ATENDIMENTOS_AGENDA_Qde Atendimentos Acolhimento\"].fillna(0)\n",
    "\n",
    "    data_dataframe[\"ATENDIMENTOS_AGENDA_Faltas Acolhimento\"] = data_dataframe[\"ATENDIMENTOS_AGENDA_Faltas Acolhimento\"].fillna(0)\n",
    "\n",
    "    data_dataframe[\"ATENDIMENTOS_AGENDA_Datas Acolhimento\"] = data_dataframe[\"ATENDIMENTOS_AGENDA_Datas Acolhimento\"].fillna(\"Nunca ocorreu\")\n",
    "\n",
    "    data_dataframe[\"ATENDIMENTOS_AGENDA_Qde Psicoterapia\"] = data_dataframe[\"ATENDIMENTOS_AGENDA_Qde Psicoterapia\"].fillna(0)\n",
    "\n",
    "    # preprocessing 4\n",
    "\n",
    "    data_dataframe[\"TWILIO_Mensagens Outbound\"].fillna(0, inplace=True)\n",
    "\n",
    "    data_dataframe[\"TWILIO_Data Última Mensagens Outbound\"] = pd.to_datetime(data_dataframe[\"TWILIO_Data Última Mensagens Outbound\"])\n",
    "\n",
    "    data_dataframe[\"TWILIO_Data Última Mensagens Outbound Tempo passado\"] = datetime.now() - data_dataframe[\"TWILIO_Data Última Mensagens Outbound\"]\n",
    "\n",
    "    data_dataframe[\"TWILIO_Data Última Mensagens Outbound Tempo passado\"].fillna('', inplace=True)\n",
    "    \n",
    "    data_dataframe[\"TWILIO_Data Última Mensagens Outbound Tempo passado\"] = data_dataframe[\"TWILIO_Data Última Mensagens Outbound Tempo passado\"].astype(str)\n",
    "\n",
    "    data_dataframe[\"TWILIO_Data Última Mensagens Outbound Tempo passado\"] = data_dataframe[\"TWILIO_Data Última Mensagens Outbound Tempo passado\"].str.extract('(\\d+) days').astype(float)\n",
    "\n",
    "    data_dataframe = data_dataframe.drop([\"TWILIO_Data Última Mensagens Outbound\"], axis=1)\n",
    "\n",
    "    data_dataframe[\"TWILIO_Data Última Mensagens Outbound Recente\"] = data_dataframe[\"TWILIO_Data Última Mensagens Outbound Tempo passado\"] < data_dataframe[\"TWILIO_Data Última Mensagens Outbound Tempo passado\"].median()\n",
    "    data_dataframe[\"TWILIO_Data Última Mensagens Outbound Recente\"].fillna(0)\n",
    "    data_dataframe[\"TWILIO_Data Última Mensagens Outbound Recente\"].replace(True, 1, inplace=True)\n",
    "    data_dataframe[\"TWILIO_Data Última Mensagens Outbound Recente\"].replace(False, 0, inplace=True)\n",
    "\n",
    "    data_dataframe = data_dataframe.drop([\"TWILIO_Data Última Mensagens Outbound Tempo passado\"], axis=1)\n",
    "\n",
    "    data_dataframe[\"TWILIO_Ligações Outbound\"].fillna(0, inplace=True)\n",
    "\n",
    "    data_dataframe[\"TWILIO_Data Última Ligações Outbound\"] = pd.to_datetime(data_dataframe[\"TWILIO_Data Última Ligações Outbound\"])\n",
    "\n",
    "    data_dataframe[\"TWILIO_Data Última Ligações Outbound Tempo passado\"] = datetime.now() - data_dataframe[\"TWILIO_Data Última Ligações Outbound\"]\n",
    "\n",
    "    data_dataframe[\"TWILIO_Data Última Ligações Outbound Tempo passado\"].fillna('', inplace=True)\n",
    "\n",
    "    data_dataframe[\"TWILIO_Data Última Ligações Outbound Tempo passado\"] = data_dataframe[\"TWILIO_Data Última Ligações Outbound Tempo passado\"].astype(str)\n",
    "\n",
    "    data_dataframe[\"TWILIO_Data Última Ligações Outbound Tempo passado\"] = data_dataframe[\"TWILIO_Data Última Ligações Outbound Tempo passado\"].str.extract('(\\d+) days').astype(float)\n",
    "\n",
    "    data_dataframe = data_dataframe.drop([\"TWILIO_Data Última Ligações Outbound\"], axis=1)\n",
    "\n",
    "    data_dataframe[\"TWILIO_Data Última Ligações Outbound Recente\"] = data_dataframe[\"TWILIO_Data Última Ligações Outbound Tempo passado\"] < data_dataframe[\"TWILIO_Data Última Ligações Outbound Tempo passado\"].median()\n",
    "    data_dataframe[\"TWILIO_Data Última Ligações Outbound Recente\"].fillna(0)\n",
    "    data_dataframe[\"TWILIO_Data Última Ligações Outbound Recente\"].replace(True, 1, inplace=True)\n",
    "    data_dataframe[\"TWILIO_Data Última Ligações Outbound Recente\"].replace(False, 0, inplace=True)\n",
    "\n",
    "    data_dataframe = data_dataframe.drop([\"TWILIO_Data Última Ligações Outbound Tempo passado\"], axis=1)\n",
    "\n",
    "    data_dataframe = data_dataframe.drop([\"COBRANÇA_VINDI_Qde Perfis de Pagamento Inativos\"], axis=1)\n",
    "\n",
    "    # preprocessing especials \n",
    "\n",
    "    data_dataframe = data_dataframe[data_dataframe['FUNIL_ASSINATURA_PIPEDRIVE_status'].isin(['won', 'lost'])]\n",
    "\n",
    "    data_dataframe = data_dataframe.drop(data_dataframe[(data_dataframe['FUNIL_ASSINATURA_PIPEDRIVE_status'] == 'won') & (~data_dataframe['PESSOA_PIPEDRIVE_contract_end_date'].isnull())].index)\n",
    "\n",
    "    data_dataframe = data_dataframe.drop(data_dataframe[(data_dataframe['FUNIL_ASSINATURA_PIPEDRIVE_status'] == 'lost') & (data_dataframe['PESSOA_PIPEDRIVE_contract_end_date'].isnull())].index)\n",
    "\n",
    "    #exportando df pronto\n",
    "\n",
    "    data_dataframe.to_csv('../notebooks/data/data-preprocessed.csv', index=False)\n",
    "\n",
    "    #     return data_dataframe\n",
    "    # except Exception:\n",
    "    #     print(\"DEU RUIM\")\n",
    "    #     return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../notebooks/data/Ana Health_Tabela Modelo Previsão Churn - Tabela.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COBRANÇA_VINDI_TWILIO_COMUNICARE_WHOQOL_ATENDIMENTOS_AGENDA_FUNIL_ONBOARDING_PIPEDRIVE_FUNIL_ASSINATURA_PIPEDRIVE_PESSOA_PIPEDRIVE_50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PESSOA, PIPEDRIVE</th>\n",
       "      <td>1022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unnamed: 1</th>\n",
       "      <td>1993-08-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unnamed: 4</th>\n",
       "      <td>Santa Catarina</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  COBRANÇA_VINDI_TWILIO_COMUNICARE_WHOQOL_ATENDIMENTOS_AGENDA_FUNIL_ONBOARDING_PIPEDRIVE_FUNIL_ASSINATURA_PIPEDRIVE_PESSOA_PIPEDRIVE_50\n",
       "PESSOA, PIPEDRIVE                                               1022                                                                                   \n",
       "Unnamed: 1                                                1993-08-03                                                                                   \n",
       "Unnamed: 2                                                        64                                                                                   \n",
       "Unnamed: 3                                                        80                                                                                   \n",
       "Unnamed: 4                                            Santa Catarina                                                                                   "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_merge.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['PESSOA_PIPEDRIVE_id_person_recommendation', 'PESSOA_PIPEDRIVE_Recebe Comunicados?', 'PESSOA_PIPEDRIVE_Interesses', 'PESSOA_PIPEDRIVE_Pontos de Atenção', 'FUNIL_ONBOARDING_PIPEDRIVE_id_label'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/Users/st4pzz/Desktop/insper_2023.2/SPRINT/sprint4-support-vector-team/src/scripts/teste.ipynb Célula 12\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/st4pzz/Desktop/insper_2023.2/SPRINT/sprint4-support-vector-team/src/scripts/teste.ipynb#X12sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m preprocessing(data)\n",
      "\u001b[1;32m/Users/st4pzz/Desktop/insper_2023.2/SPRINT/sprint4-support-vector-team/src/scripts/teste.ipynb Célula 12\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/st4pzz/Desktop/insper_2023.2/SPRINT/sprint4-support-vector-team/src/scripts/teste.ipynb#X12sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m data_dataframe \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(data_dataframe\u001b[39m.\u001b[39miloc[\u001b[39m50\u001b[39m])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/st4pzz/Desktop/insper_2023.2/SPRINT/sprint4-support-vector-team/src/scripts/teste.ipynb#X12sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m \u001b[39m# preprocessing 1\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/st4pzz/Desktop/insper_2023.2/SPRINT/sprint4-support-vector-team/src/scripts/teste.ipynb#X12sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m data_dataframe \u001b[39m=\u001b[39m data_dataframe\u001b[39m.\u001b[39;49mdrop([\u001b[39m\"\u001b[39;49m\u001b[39mPESSOA_PIPEDRIVE_id_person_recommendation\u001b[39;49m\u001b[39m\"\u001b[39;49m,\u001b[39m\"\u001b[39;49m\u001b[39mPESSOA_PIPEDRIVE_Recebe Comunicados?\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mPESSOA_PIPEDRIVE_Interesses\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mPESSOA_PIPEDRIVE_Pontos de Atenção\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mFUNIL_ONBOARDING_PIPEDRIVE_id_label\u001b[39;49m\u001b[39m\"\u001b[39;49m], axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/st4pzz/Desktop/insper_2023.2/SPRINT/sprint4-support-vector-team/src/scripts/teste.ipynb#X12sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m data_dataframe[\u001b[39m'\u001b[39m\u001b[39mPESSOA_PIPEDRIVE_birthdate\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mto_datetime(data_dataframe[\u001b[39m'\u001b[39m\u001b[39mPESSOA_PIPEDRIVE_birthdate\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/st4pzz/Desktop/insper_2023.2/SPRINT/sprint4-support-vector-team/src/scripts/teste.ipynb#X12sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m data_dataframe[\u001b[39m'\u001b[39m\u001b[39mPESSOA_PIPEDRIVE_age\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m data_dataframe[\u001b[39m'\u001b[39m\u001b[39mPESSOA_PIPEDRIVE_birthdate\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mapply(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/st4pzz/Desktop/insper_2023.2/SPRINT/sprint4-support-vector-team/src/scripts/teste.ipynb#X12sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m     \u001b[39mlambda\u001b[39;00m x: datetime\u001b[39m.\u001b[39mtoday()\u001b[39m.\u001b[39myear \u001b[39m-\u001b[39m x\u001b[39m.\u001b[39myear \u001b[39m-\u001b[39m ((datetime\u001b[39m.\u001b[39mtoday()\u001b[39m.\u001b[39mmonth, datetime\u001b[39m.\u001b[39mtoday()\u001b[39m.\u001b[39mday) \u001b[39m<\u001b[39m (x\u001b[39m.\u001b[39mmonth, x\u001b[39m.\u001b[39mday))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/st4pzz/Desktop/insper_2023.2/SPRINT/sprint4-support-vector-team/src/scripts/teste.ipynb#X12sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m )\n",
      "File \u001b[0;32m~/Desktop/insper_2023.2/SPRINT/sprint4-support-vector-team/env/lib/python3.9/site-packages/pandas/core/frame.py:5344\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   5196\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdrop\u001b[39m(\n\u001b[1;32m   5197\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   5198\u001b[0m     labels: IndexLabel \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5205\u001b[0m     errors: IgnoreRaise \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mraise\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   5206\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   5207\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   5208\u001b[0m \u001b[39m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[1;32m   5209\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5342\u001b[0m \u001b[39m            weight  1.0     0.8\u001b[39;00m\n\u001b[1;32m   5343\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 5344\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mdrop(\n\u001b[1;32m   5345\u001b[0m         labels\u001b[39m=\u001b[39;49mlabels,\n\u001b[1;32m   5346\u001b[0m         axis\u001b[39m=\u001b[39;49maxis,\n\u001b[1;32m   5347\u001b[0m         index\u001b[39m=\u001b[39;49mindex,\n\u001b[1;32m   5348\u001b[0m         columns\u001b[39m=\u001b[39;49mcolumns,\n\u001b[1;32m   5349\u001b[0m         level\u001b[39m=\u001b[39;49mlevel,\n\u001b[1;32m   5350\u001b[0m         inplace\u001b[39m=\u001b[39;49minplace,\n\u001b[1;32m   5351\u001b[0m         errors\u001b[39m=\u001b[39;49merrors,\n\u001b[1;32m   5352\u001b[0m     )\n",
      "File \u001b[0;32m~/Desktop/insper_2023.2/SPRINT/sprint4-support-vector-team/env/lib/python3.9/site-packages/pandas/core/generic.py:4711\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4709\u001b[0m \u001b[39mfor\u001b[39;00m axis, labels \u001b[39min\u001b[39;00m axes\u001b[39m.\u001b[39mitems():\n\u001b[1;32m   4710\u001b[0m     \u001b[39mif\u001b[39;00m labels \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 4711\u001b[0m         obj \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39;49m_drop_axis(labels, axis, level\u001b[39m=\u001b[39;49mlevel, errors\u001b[39m=\u001b[39;49merrors)\n\u001b[1;32m   4713\u001b[0m \u001b[39mif\u001b[39;00m inplace:\n\u001b[1;32m   4714\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[0;32m~/Desktop/insper_2023.2/SPRINT/sprint4-support-vector-team/env/lib/python3.9/site-packages/pandas/core/generic.py:4753\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[0;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[1;32m   4751\u001b[0m         new_axis \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39mdrop(labels, level\u001b[39m=\u001b[39mlevel, errors\u001b[39m=\u001b[39merrors)\n\u001b[1;32m   4752\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 4753\u001b[0m         new_axis \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39;49mdrop(labels, errors\u001b[39m=\u001b[39;49merrors)\n\u001b[1;32m   4754\u001b[0m     indexer \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39mget_indexer(new_axis)\n\u001b[1;32m   4756\u001b[0m \u001b[39m# Case for non-unique axis\u001b[39;00m\n\u001b[1;32m   4757\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/Desktop/insper_2023.2/SPRINT/sprint4-support-vector-team/env/lib/python3.9/site-packages/pandas/core/indexes/base.py:6992\u001b[0m, in \u001b[0;36mIndex.drop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   6990\u001b[0m \u001b[39mif\u001b[39;00m mask\u001b[39m.\u001b[39many():\n\u001b[1;32m   6991\u001b[0m     \u001b[39mif\u001b[39;00m errors \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m-> 6992\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mlabels[mask]\u001b[39m.\u001b[39mtolist()\u001b[39m}\u001b[39;00m\u001b[39m not found in axis\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   6993\u001b[0m     indexer \u001b[39m=\u001b[39m indexer[\u001b[39m~\u001b[39mmask]\n\u001b[1;32m   6994\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdelete(indexer)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['PESSOA_PIPEDRIVE_id_person_recommendation', 'PESSOA_PIPEDRIVE_Recebe Comunicados?', 'PESSOA_PIPEDRIVE_Interesses', 'PESSOA_PIPEDRIVE_Pontos de Atenção', 'FUNIL_ONBOARDING_PIPEDRIVE_id_label'] not found in axis\""
     ]
    }
   ],
   "source": [
    "preprocessing(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
