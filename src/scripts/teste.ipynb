{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"../notebooks/data/Ana Health_Tabela Modelo Previsão Churn - Tabela.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_preprocessing import preprocessing\n",
    "from data_feature_engineering import feature_engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = preprocessing(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data-engineering.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'FUNIL_ASSINATURA_PIPEDRIVE_id_stage'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/Desktop/insper_2023.2/SPRINT/sprint4-support-vector-team/env/lib/python3.9/site-packages/pandas/core/indexes/base.py:3790\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3789\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3790\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   3791\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:152\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:181\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'FUNIL_ASSINATURA_PIPEDRIVE_id_stage'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/Users/st4pzz/Desktop/insper_2023.2/SPRINT/sprint4-support-vector-team/src/scripts/teste.ipynb Célula 5\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/st4pzz/Desktop/insper_2023.2/SPRINT/sprint4-support-vector-team/src/scripts/teste.ipynb#X24sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m df[\u001b[39m\"\u001b[39;49m\u001b[39mFUNIL_ASSINATURA_PIPEDRIVE_id_stage\u001b[39;49m\u001b[39m\"\u001b[39;49m]\u001b[39m.\u001b[39mvalue_counts()\n",
      "File \u001b[0;32m~/Desktop/insper_2023.2/SPRINT/sprint4-support-vector-team/env/lib/python3.9/site-packages/pandas/core/frame.py:3893\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3891\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   3892\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3893\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[1;32m   3894\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3895\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/Desktop/insper_2023.2/SPRINT/sprint4-support-vector-team/env/lib/python3.9/site-packages/pandas/core/indexes/base.py:3797\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3792\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(casted_key, \u001b[39mslice\u001b[39m) \u001b[39mor\u001b[39;00m (\n\u001b[1;32m   3793\u001b[0m         \u001b[39misinstance\u001b[39m(casted_key, abc\u001b[39m.\u001b[39mIterable)\n\u001b[1;32m   3794\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39many\u001b[39m(\u001b[39misinstance\u001b[39m(x, \u001b[39mslice\u001b[39m) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m casted_key)\n\u001b[1;32m   3795\u001b[0m     ):\n\u001b[1;32m   3796\u001b[0m         \u001b[39mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3797\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3798\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3799\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3800\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3801\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3802\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'FUNIL_ASSINATURA_PIPEDRIVE_id_stage'"
     ]
    }
   ],
   "source": [
    "df[\"FUNIL_ASSINATURA_PIPEDRIVE_id_stage\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PESSOA_PIPEDRIVE_Canal de Preferência\n",
       "0      571\n",
       "239    379\n",
       "238     12\n",
       "360     11\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"PESSOA_PIPEDRIVE_Canal de Preferência\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Estado_Mato Grosso do Sul</th>\n",
       "      <th>Estado_Minas Gerais</th>\n",
       "      <th>Estado_Paraná</th>\n",
       "      <th>Estado_Paraíba</th>\n",
       "      <th>Estado_Pará</th>\n",
       "      <th>Estado_Pernambuco</th>\n",
       "      <th>Estado_Piauí</th>\n",
       "      <th>Estado_Rio Grande do Norte</th>\n",
       "      <th>Estado_Rio Grande do Sul</th>\n",
       "      <th>Estado_Rio de Janeiro</th>\n",
       "      <th>Estado_Santa Catarina</th>\n",
       "      <th>Estado_Sergipe</th>\n",
       "      <th>Estado_State of Amazonas</th>\n",
       "      <th>Estado_São Paulo</th>\n",
       "      <th>PESSOA_PIPEDRIVE_city Codificada</th>\n",
       "      <th>status_lost</th>\n",
       "      <th>status_won</th>\n",
       "      <th>lost_reason_Outro</th>\n",
       "      <th>lost_reason_[Assinatura] Cancelamento por inadimplência</th>\n",
       "      <th>lost_reason_[Assinatura] Desligamento</th>\n",
       "      <th>lost_reason_[Assinatura] Empresa cancelou o benefício da Ana</th>\n",
       "      <th>lost_reason_[Assinatura] Está sem tempo para conciliar os atendimentos</th>\n",
       "      <th>lost_reason_[Assinatura] Não quer seguir com a Ana</th>\n",
       "      <th>lost_reason_[Assinatura] Precisou cortar custos</th>\n",
       "      <th>Status_Não iniciado</th>\n",
       "      <th>Status_lost</th>\n",
       "      <th>Status_open</th>\n",
       "      <th>Status_won</th>\n",
       "      <th>lost_reason_Outro.1</th>\n",
       "      <th>lost_reason_[Associade] Cancelou assinatura</th>\n",
       "      <th>lost_reason_[Onboarding] Não retornou aos contatos de resgate</th>\n",
       "      <th>lost_reason_[Onboarding] Não tem interesse em seguir nas etapas do onboarding</th>\n",
       "      <th>stage_Boas-vindas</th>\n",
       "      <th>stage_Não iniciado</th>\n",
       "      <th>stage_Primeira reunião</th>\n",
       "      <th>stage_Questionário</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>32</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>32</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Estado_Mato Grosso do Sul  ...  stage_Questionário\n",
       "0                      False  ...                True\n",
       "1                      False  ...                True\n",
       "2                      False  ...                True\n",
       "3                      False  ...                True\n",
       "4                      False  ...                True\n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[:,60:].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "\n",
    "def column_label_to_index(col_label):\n",
    "    col_index = 0\n",
    "    for c in col_label.upper():\n",
    "        col_index = col_index * 26 + (ord(c) - ord('A') + 1)\n",
    "    return col_index - 1\n",
    "\n",
    "def add_prefix_to_columns(dataframe, prefix):\n",
    "    for col in dataframe.columns:\n",
    "        new_col_name = prefix + str(col)\n",
    "        dataframe.rename(columns={col: new_col_name}, inplace=True)\n",
    "\n",
    "\n",
    "def mergeHeader_Columns(data):\n",
    "    add_prefix_to_columns(data, 'PESSOA_PIPEDRIVE_')\n",
    "    add_prefix_to_columns(data, 'FUNIL_ASSINATURA_PIPEDRIVE_')\n",
    "    add_prefix_to_columns(data, 'FUNIL_ONBOARDING_PIPEDRIVE_')\n",
    "    add_prefix_to_columns(data, 'ATENDIMENTOS_AGENDA_')\n",
    "    add_prefix_to_columns(data, 'WHOQOL_')\n",
    "    add_prefix_to_columns(data, 'COMUNICARE_')\n",
    "    add_prefix_to_columns(data, 'TWILIO_')\n",
    "    add_prefix_to_columns(data, 'COBRANÇA_VINDI_')\n",
    "\n",
    "    return data\n",
    "\n",
    "def preprocessing(data_dataframe):\n",
    "    from sklearn.impute import SimpleImputer\n",
    "\n",
    "    # try:\n",
    "    data_dataframe = mergeHeader_Columns(data_dataframe)\n",
    "    data_dataframe = pd.DataFrame(data_dataframe.iloc[50])\n",
    "    # preprocessing 1\n",
    "    data_dataframe = data_dataframe.drop([\"PESSOA_PIPEDRIVE_id_person_recommendation\",\"PESSOA_PIPEDRIVE_Recebe Comunicados?\", \"PESSOA_PIPEDRIVE_Interesses\", \"PESSOA_PIPEDRIVE_Pontos de Atenção\", \"FUNIL_ONBOARDING_PIPEDRIVE_id_label\"], axis=1)\n",
    "\n",
    "    data_dataframe['PESSOA_PIPEDRIVE_birthdate'] = pd.to_datetime(data_dataframe['PESSOA_PIPEDRIVE_birthdate'])\n",
    "    data_dataframe['PESSOA_PIPEDRIVE_age'] = data_dataframe['PESSOA_PIPEDRIVE_birthdate'].apply(\n",
    "        lambda x: datetime.today().year - x.year - ((datetime.today().month, datetime.today().day) < (x.month, x.day))\n",
    "    )\n",
    "\n",
    "    imputer = SimpleImputer(strategy='mean')\n",
    "    data_dataframe['PESSOA_PIPEDRIVE_age'] = imputer.fit_transform(data_dataframe['PESSOA_PIPEDRIVE_age'].values.reshape(-1, 1))\n",
    "    data_dataframe['PESSOA_PIPEDRIVE_age'] = np.round(data_dataframe['PESSOA_PIPEDRIVE_age']).astype(int)\n",
    "\n",
    "    data_dataframe = data_dataframe.drop(['PESSOA_PIPEDRIVE_birthdate'], axis=1 )\n",
    "\n",
    "    rows_to_drop = data_dataframe[data_dataframe[\"PESSOA_PIPEDRIVE_id_gender\"].isin([117,110,111])]\n",
    "    data_dataframe = data_dataframe.drop(rows_to_drop.index, axis=0)\n",
    "    data_dataframe[\"PESSOA_PIPEDRIVE_id_gender\"].fillna(64, inplace=True)\n",
    "    data_dataframe[\"PESSOA_PIPEDRIVE_id_marrital_status\"].fillna(80, inplace=True)\n",
    "\n",
    "    \n",
    "    data_dataframe[\"PESSOA_PIPEDRIVE_state\"].fillna(data_dataframe[\"PESSOA_PIPEDRIVE_state\"].mode()[0], inplace=True)\n",
    "\n",
    "\n",
    "    data_dataframe[\"PESSOA_PIPEDRIVE_city\"].fillna(data_dataframe[\"PESSOA_PIPEDRIVE_city\"].mode()[0], inplace=True)\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    data_dataframe['PESSOA_PIPEDRIVE_id_health_plan'].fillna(data_dataframe['PESSOA_PIPEDRIVE_id_health_plan'].mode()[0], inplace=True)\n",
    "    data_dataframe['PESSOA_PIPEDRIVE_has_public_health_plan'] = data_dataframe['PESSOA_PIPEDRIVE_id_health_plan'].apply(lambda x: 1 if int(x) == 412 else 0)\n",
    "    data_dataframe = data_dataframe.drop(['PESSOA_PIPEDRIVE_id_health_plan'], axis=1)\n",
    "    data_dataframe[\"PESSOA_PIPEDRIVE_tem_data_dataframe_de_termino_de_contrato\"] = data_dataframe[\"PESSOA_PIPEDRIVE_contract_end_date\"].apply(lambda x: 0 if pd.isna(x) else 1)\n",
    "    data_dataframe.drop([\"PESSOA_PIPEDRIVE_id_continuity_pf\"], axis=1, inplace=True)\n",
    "    data_dataframe[\"PESSOA_PIPEDRIVE_Canal de Preferência\"].fillna(0, inplace=True)\n",
    "    data_dataframe[\"PESSOA_PIPEDRIVE_Tem_Canal_de_Preferência\"] = data_dataframe[\"PESSOA_PIPEDRIVE_Canal de Preferência\"].apply(lambda x: 1 if int(x) > 0  else 0)\n",
    "    data_dataframe[\"PESSOA_PIPEDRIVE_has_notes\"] = data_dataframe[\"PESSOA_PIPEDRIVE_notes_count\"].apply(lambda x: 1 if int(x) > 0 else 0)\n",
    "    \n",
    "    # preprocessing 2\n",
    "    data_dataframe = data_dataframe.drop([\"ATENDIMENTOS_AGENDA_Faltas Psicoterapia\",\"TWILIO_Ligações Inbound\", \"TWILIO_Data Última Ligações Inbound\",\"COBRANÇA_VINDI_Qde Total de Faturas\",\"COBRANÇA_VINDI_Qde Total de Tentativas de Cobrança\",\"COBRANÇA_VINDI_Método de Pagamento\",\"COBRANÇA_VINDI_Valor Médio da Mensalidade\",\"COBRANÇA_VINDI_Qde Total de Faturas Pagas após Vencimento\",\"COBRANÇA_VINDI_Qde Total de Faturas Inadimpletes\",\"COBRANÇA_VINDI_Valor Total Inadimplência\"], axis=1)\n",
    "\n",
    "    data_dataframe[\"ATENDIMENTOS_AGENDA_Qde Psicoterapia\"].fillna(0, inplace=True)\n",
    "    \n",
    "\n",
    "\n",
    "    data_dataframe = data_dataframe.drop(columns=\"WHOQOL_Qde Respostas WHOQOL\")\n",
    "\n",
    "    data_dataframe[\"WHOQOL_Físico_New\"] = data_dataframe[\"WHOQOL_Físico\"].str.split(';').str[-1].str.strip()\n",
    "\n",
    "    data_dataframe[\"WHOQOL_Físico_New\"] = data_dataframe[\"WHOQOL_Físico_New\"].str.replace(\",\",\".\")\n",
    "\n",
    "    data_dataframe[\"WHOQOL_Físico_New\"] = data_dataframe[\"WHOQOL_Físico_New\"].astype(float) \n",
    "\n",
    "    data_dataframe[\"WHOQOL_Físico_New\"] = data_dataframe[\"WHOQOL_Físico_New\"].fillna(data_dataframe[\"WHOQOL_Físico_New\"].median())\n",
    "\n",
    "    data_dataframe[\"WHOQOL_Psicológico_New\"] = data_dataframe[\"WHOQOL_Psicológico\"].str.split(';').str[-1].str.strip()\n",
    "\n",
    "    data_dataframe[\"WHOQOL_Psicológico_New\"] = data_dataframe[\"WHOQOL_Psicológico_New\"].str.replace(\",\",\".\")\n",
    "\n",
    "    data_dataframe[\"WHOQOL_Psicológico_New\"] = data_dataframe[\"WHOQOL_Psicológico_New\"].astype(float) \n",
    "\n",
    "    data_dataframe[\"WHOQOL_Psicológico_New\"] = data_dataframe[\"WHOQOL_Psicológico_New\"].fillna(data_dataframe[\"WHOQOL_Psicológico_New\"].median())\n",
    "\n",
    "    data_dataframe[\"WHOQOL_Social_New\"] = data_dataframe[\"WHOQOL_Social\"].str.split(';').str[-1].str.strip()\n",
    "\n",
    "    data_dataframe[\"WHOQOL_Social_New\"] = data_dataframe[\"WHOQOL_Social_New\"].str.replace(\",\",\".\")\n",
    "\n",
    "    data_dataframe[\"WHOQOL_Social_New\"] = data_dataframe[\"WHOQOL_Social_New\"].astype(float) \n",
    "\n",
    "    data_dataframe[\"WHOQOL_Social_New\"] = data_dataframe[\"WHOQOL_Social_New\"].fillna(data_dataframe[\"WHOQOL_Social_New\"].median())\n",
    "\n",
    "    data_dataframe[\"WHOQOL_Ambiental_New\"] = data_dataframe[\"WHOQOL_Ambiental\"].str.split(';').str[-1].str.strip()\n",
    "\n",
    "    data_dataframe[\"WHOQOL_Ambiental_New\"] = data_dataframe[\"WHOQOL_Ambiental_New\"].str.replace(\",\",\".\")\n",
    "\n",
    "    data_dataframe[\"WHOQOL_Ambiental_New\"] = data_dataframe[\"WHOQOL_Ambiental_New\"].astype(float) \n",
    "\n",
    "    data_dataframe[\"WHOQOL_Ambiental_New\"] = data_dataframe[\"WHOQOL_Ambiental_New\"].fillna(data_dataframe[\"WHOQOL_Ambiental_New\"].median())\n",
    "\n",
    "    data_dataframe[\"COMUNICARE_Problemas Abertos Bool\"] = data_dataframe[\"COMUNICARE_Problemas Abertos\"].notnull().astype(int)\n",
    "\n",
    "    data_dataframe[\"COMUNICARE_Problemas Abertos Bool\"].fillna(0, inplace=True)\n",
    "\n",
    "    data_dataframe[\"TWILIO_Mensagens Inbound\"].fillna(0, inplace=True)\n",
    "\n",
    "    data_dataframe[\"TWILIO_Data Última Mensagens Inbound\"] = pd.to_datetime(data_dataframe[\"TWILIO_Data Última Mensagens Inbound\"])\n",
    "\n",
    "    data_dataframe[\"TWILIO_Data Última Mensagens Inbound Tempo Passado\"] = datetime.now() - data_dataframe[\"TWILIO_Data Última Mensagens Inbound\"]\n",
    "\n",
    "    data_dataframe[\"TWILIO_Data Última Mensagens Inbound Tempo Passado\"].fillna('', inplace=True)\n",
    "\n",
    "    data_dataframe[\"TWILIO_Data Última Mensagens Inbound Tempo Passado\"] = data_dataframe[\"TWILIO_Data Última Mensagens Inbound Tempo Passado\"].astype(str)\n",
    "\n",
    "    data_dataframe[\"TWILIO_Data Última Mensagens Inbound Tempo Passado\"] = data_dataframe[\"TWILIO_Data Última Mensagens Inbound Tempo Passado\"].str.extract('(\\d+) days').astype(float)\n",
    "\n",
    "    data_dataframe[\"TWILIO_Data Última Mensagens Inbound Recente\"] = data_dataframe[\"TWILIO_Data Última Mensagens Inbound Tempo Passado\"] < data_dataframe[\"TWILIO_Data Última Mensagens Inbound Tempo Passado\"].median()\n",
    "    data_dataframe[\"TWILIO_Data Última Mensagens Inbound Recente\"].fillna(0)\n",
    "    data_dataframe[\"TWILIO_Data Última Mensagens Inbound Recente\"].replace(True, 1, inplace=True)\n",
    "    data_dataframe[\"TWILIO_Data Última Mensagens Inbound Recente\"].replace(False, 0, inplace=True)\n",
    "\n",
    "    data_dataframe = data_dataframe.drop(columns=[\"WHOQOL_Ambiental\",\"WHOQOL_Social\",\"WHOQOL_Físico\",\"WHOQOL_Psicológico\",\"COMUNICARE_Problemas Abertos\",\"TWILIO_Data Última Mensagens Inbound\",\"ATENDIMENTOS_AGENDA_Datas Psicoterapia\",\"TWILIO_Data Última Mensagens Inbound Tempo Passado\"])\n",
    "    \n",
    "    # preprocessing 3\n",
    "    for indice, valor in data_dataframe[\"FUNIL_ASSINATURA_PIPEDRIVE_lost_time\"].items():\n",
    "        if pd.notna(valor) == False: \n",
    "            if pd.notna(data_dataframe.loc[indice, \"PESSOA_PIPEDRIVE_contract_end_date\"]):\n",
    "                data_dataframe.loc[indice, \"FUNIL_ASSINATURA_PIPEDRIVE_lost_time\"] = data_dataframe.loc[indice, \"PESSOA_PIPEDRIVE_contract_end_date\"]\n",
    "\n",
    "    data_dataframe[\"FUNIL_ASSINATURA_PIPEDRIVE_lost_time\"].fillna(dt.date.today(), inplace=True)\n",
    "\n",
    "    for indice, valor in data_dataframe[\"FUNIL_ASSINATURA_PIPEDRIVE_lost_time\"].items():\n",
    "        index = str(data_dataframe.loc[indice, \"FUNIL_ASSINATURA_PIPEDRIVE_lost_time\"]).find(\";\")\n",
    "        if index != -1:\n",
    "            data_dataframe.loc[indice, \"FUNIL_ASSINATURA_PIPEDRIVE_lost_time\"] = data_dataframe.loc[indice, \"FUNIL_ASSINATURA_PIPEDRIVE_lost_time\"][:index]\n",
    "\n",
    "    for indice, valor in data_dataframe[\"FUNIL_ASSINATURA_PIPEDRIVE_lost_time\"].items():\n",
    "        tamanho = len(str(data_dataframe.loc[indice, \"FUNIL_ASSINATURA_PIPEDRIVE_lost_time\"]))\n",
    "        if tamanho > 10:\n",
    "            data_dataframe.loc[indice, \"FUNIL_ASSINATURA_PIPEDRIVE_lost_time\"] = data_dataframe.loc[indice, \"FUNIL_ASSINATURA_PIPEDRIVE_lost_time\"][:10]\t\n",
    "\n",
    "    for indice, valor in data_dataframe[\"FUNIL_ASSINATURA_PIPEDRIVE_lost_time\"].items():\n",
    "        data_dataframe.loc[indice, \"FUNIL_ASSINATURA_PIPEDRIVE_lost_time\"] = pd.to_datetime(data_dataframe.loc[indice, \"FUNIL_ASSINATURA_PIPEDRIVE_lost_time\"], format='%Y-%m-%d', errors='coerce')\n",
    "        data_dataframe.loc[indice, \"FUNIL_ASSINATURA_PIPEDRIVE_lost_time\"] = data_dataframe.loc[indice, \"FUNIL_ASSINATURA_PIPEDRIVE_lost_time\"].strftime('%Y-%m-%d')\n",
    "\n",
    "    tempo_permanencia = []\n",
    "\n",
    "    for indice, valor in data_dataframe[\"FUNIL_ASSINATURA_PIPEDRIVE_start_of_service\"].items():\n",
    "        if pd.notna(valor):\n",
    "            index = data_dataframe.loc[indice, \"FUNIL_ASSINATURA_PIPEDRIVE_start_of_service\"].find(\";\")\n",
    "            if index != -1:\n",
    "                data_dataframe.loc[indice, \"FUNIL_ASSINATURA_PIPEDRIVE_start_of_service\"] = data_dataframe.loc[indice, \"FUNIL_ASSINATURA_PIPEDRIVE_start_of_service\"][:index]\n",
    "\n",
    "    for indice, valor in data_dataframe[\"FUNIL_ASSINATURA_PIPEDRIVE_lost_time\"].items():\n",
    "        if pd.notna(data_dataframe.loc[indice, \"FUNIL_ASSINATURA_PIPEDRIVE_start_of_service\"]):\n",
    "            tempo_1 = datetime.strptime(data_dataframe.loc[indice, \"FUNIL_ASSINATURA_PIPEDRIVE_lost_time\"], '%Y-%m-%d')\n",
    "            tempo_2 = datetime.strptime(data_dataframe.loc[indice, \"FUNIL_ASSINATURA_PIPEDRIVE_start_of_service\"], '%Y-%m-%d')\n",
    "            tempo_permanencia.append(str(tempo_1 - tempo_2))\n",
    "        else:\n",
    "            tempo_1 = datetime.strptime(data_dataframe.loc[indice, \"FUNIL_ASSINATURA_PIPEDRIVE_lost_time\"], '%Y-%m-%d')\n",
    "            tempo_2 = datetime.strptime(data_dataframe.loc[indice, \"PESSOA_PIPEDRIVE_contract_start_date\"], '%Y-%m-%d')\n",
    "            tempo_permanencia.append(str(tempo_1 - tempo_2))\n",
    "\n",
    "    data_dataframe['stay_time'] = tempo_permanencia\n",
    "\n",
    "    for indice, valor in data_dataframe[\"stay_time\"].items():\n",
    "        index = data_dataframe.loc[indice, \"stay_time\"].find(\",\")\n",
    "        if index != -1:\n",
    "            data_dataframe.loc[indice, \"stay_time\"] = data_dataframe.loc[indice, \"stay_time\"][:index]\n",
    "\n",
    "    for indice, valor in data_dataframe[\"FUNIL_ASSINATURA_PIPEDRIVE_lost_reason\"].items():\n",
    "        if pd.notna(valor):  \n",
    "            index = data_dataframe.loc[indice, \"FUNIL_ASSINATURA_PIPEDRIVE_lost_reason\"].find(\";\")\n",
    "            if index != -1: \n",
    "                data_dataframe.loc[indice, \"FUNIL_ASSINATURA_PIPEDRIVE_lost_reason\"] = data_dataframe.loc[indice, \"FUNIL_ASSINATURA_PIPEDRIVE_lost_reason\"][:index]\n",
    "        else:\n",
    "            data_dataframe.loc[indice, \"FUNIL_ASSINATURA_PIPEDRIVE_lost_reason\"] = \"Assinatura ativa\"\n",
    "            \n",
    "        contagem = data_dataframe[\"FUNIL_ASSINATURA_PIPEDRIVE_lost_reason\"].value_counts()\n",
    "\n",
    "        agrupamento = contagem[contagem < 20].index\n",
    "        data_dataframe.loc[data_dataframe[\"FUNIL_ASSINATURA_PIPEDRIVE_lost_reason\"].isin(agrupamento), \"FUNIL_ASSINATURA_PIPEDRIVE_lost_reason\"] = \"Outro\"\n",
    "\n",
    "    data_dataframe['FUNIL_ONBOARDING_PIPEDRIVE_add_time'].fillna('Não iniciado', inplace=True)\n",
    "\n",
    "    ultimos_estados = []\n",
    "\n",
    "    for indice, valor in data_dataframe[\"FUNIL_ONBOARDING_PIPEDRIVE_add_time\"].items():\n",
    "        if valor != \"Não iniciado\":\n",
    "            if pd.notna(data_dataframe.loc[indice, \"FUNIL_ONBOARDING_PIPEDRIVE_stay_in_pipeline_stages_welcome\"]):\n",
    "                if pd.notna(data_dataframe.loc[indice, \"FUNIL_ONBOARDING_PIPEDRIVE_stay_in_pipeline_stages_first_meeting\"]):\n",
    "                    if pd.notna(data_dataframe.loc[indice, \"FUNIL_ONBOARDING_PIPEDRIVE_stay_in_pipeline_stages_whoqol\"]):\n",
    "                        ultimos_estados.append(\"Questionário\")\n",
    "                    else:\n",
    "                        ultimos_estados.append(\"Primeira reunião\")\n",
    "                else:\n",
    "                    ultimos_estados.append(\"Boas-vindas\")\n",
    "            \n",
    "        else:\n",
    "            ultimos_estados.append(\"Não iniciado\")\n",
    "\n",
    "    data_dataframe[\"last_stage_concluded\"] = ultimos_estados\n",
    "\n",
    "    data_dataframe.drop([\"FUNIL_ONBOARDING_PIPEDRIVE_stay_in_pipeline_stages_welcome\", \"FUNIL_ONBOARDING_PIPEDRIVE_stay_in_pipeline_stages_first_meeting\", \"FUNIL_ONBOARDING_PIPEDRIVE_stay_in_pipeline_stages_whoqol\"], axis=1, inplace=True)\n",
    "\n",
    "    data_dataframe[\"FUNIL_ONBOARDING_PIPEDRIVE_status\"].fillna(\"Não iniciado\", inplace=True)\n",
    "\n",
    "    tempo = []\n",
    "\n",
    "    for indice, valor in data_dataframe[\"FUNIL_ONBOARDING_PIPEDRIVE_add_time\"].items():\n",
    "        if valor != \"Não iniciado\":\n",
    "            if pd.notna(data_dataframe.loc[indice, \"FUNIL_ONBOARDING_PIPEDRIVE_lost_time\"]) == True:\n",
    "                tempo.append(data_dataframe.loc[indice, \"FUNIL_ONBOARDING_PIPEDRIVE_lost_time\"])\n",
    "            elif pd.notna(data_dataframe.loc[indice, \"FUNIL_ONBOARDING_PIPEDRIVE_won_time\"]) == True:\n",
    "                tempo.append(data_dataframe.loc[indice, \"FUNIL_ONBOARDING_PIPEDRIVE_won_time\"])\n",
    "            else:\n",
    "                tempo.append(\"Em aberto\")\n",
    "        else:\n",
    "            tempo.append(\"Não iniciado\")\n",
    "\n",
    "    data_dataframe['process_time'] = tempo\n",
    "\n",
    "    data_dataframe.drop([\"FUNIL_ONBOARDING_PIPEDRIVE_won_time\", \"FUNIL_ONBOARDING_PIPEDRIVE_lost_time\"], axis=1, inplace=True)\n",
    "\n",
    "    data_dataframe[\"FUNIL_ONBOARDING_PIPEDRIVE_activities_count\"] = data_dataframe[\"FUNIL_ONBOARDING_PIPEDRIVE_activities_count\"].fillna(0)\n",
    "\n",
    "    data_dataframe[\"ATENDIMENTOS_AGENDA_Qde Atendimento Médico\"] = data_dataframe[\"ATENDIMENTOS_AGENDA_Qde Atendimento Médico\"].fillna(0)\n",
    "\n",
    "    data_dataframe[\"ATENDIMENTOS_AGENDA_Faltas Atendimento Médico\"] = data_dataframe[\"ATENDIMENTOS_AGENDA_Faltas Atendimento Médico\"].fillna(0)\n",
    "\n",
    "    data_dataframe[\"ATENDIMENTOS_AGENDA_Datas Atendimento Médico\"] = data_dataframe[\"ATENDIMENTOS_AGENDA_Datas Atendimento Médico\"].fillna(\"Nunca ocorreu\")\n",
    "\n",
    "    for indice, valor in data_dataframe[\"FUNIL_ONBOARDING_PIPEDRIVE_lost_reason\"].items():\n",
    "        if pd.notna(valor) == False:\n",
    "            if pd.notna(data_dataframe.loc[indice, \"FUNIL_ONBOARDING_PIPEDRIVE_status\"]) == False and pd.notna(data_dataframe.loc[indice, \"FUNIL_ONBOARDING_PIPEDRIVE_add_time\"]):\n",
    "                data_dataframe.loc[indice, \"FUNIL_ONBOARDING_PIPEDRIVE_lost_reason\"] = \"Processo em aberto\"\n",
    "            if data_dataframe.loc[indice, \"FUNIL_ONBOARDING_PIPEDRIVE_status\"] == \"won\":\n",
    "                data_dataframe.loc[indice, \"FUNIL_ONBOARDING_PIPEDRIVE_lost_reason\"] = \"Processo concluído\"\n",
    "            else:\n",
    "                data_dataframe.loc[indice, \"FUNIL_ONBOARDING_PIPEDRIVE_lost_reason\"] = \"Processo não iniciado\"\n",
    "\n",
    "        contagem = data_dataframe[\"FUNIL_ONBOARDING_PIPEDRIVE_lost_reason\"].value_counts()\n",
    "\n",
    "        agrupamento = contagem[contagem < 23].index\n",
    "        data_dataframe.loc[data_dataframe[\"FUNIL_ONBOARDING_PIPEDRIVE_lost_reason\"].isin(agrupamento), \"FUNIL_ONBOARDING_PIPEDRIVE_lost_reason\"] = \"Outro\"\n",
    "\n",
    "    data_dataframe[\"ATENDIMENTOS_AGENDA_Qde Atendimentos Acolhimento\"] = data_dataframe[\"ATENDIMENTOS_AGENDA_Qde Atendimentos Acolhimento\"].fillna(0)\n",
    "\n",
    "    data_dataframe[\"ATENDIMENTOS_AGENDA_Faltas Acolhimento\"] = data_dataframe[\"ATENDIMENTOS_AGENDA_Faltas Acolhimento\"].fillna(0)\n",
    "\n",
    "    data_dataframe[\"ATENDIMENTOS_AGENDA_Datas Acolhimento\"] = data_dataframe[\"ATENDIMENTOS_AGENDA_Datas Acolhimento\"].fillna(\"Nunca ocorreu\")\n",
    "\n",
    "    data_dataframe[\"ATENDIMENTOS_AGENDA_Qde Psicoterapia\"] = data_dataframe[\"ATENDIMENTOS_AGENDA_Qde Psicoterapia\"].fillna(0)\n",
    "\n",
    "    # preprocessing 4\n",
    "\n",
    "    data_dataframe[\"TWILIO_Mensagens Outbound\"].fillna(0, inplace=True)\n",
    "\n",
    "    data_dataframe[\"TWILIO_Data Última Mensagens Outbound\"] = pd.to_datetime(data_dataframe[\"TWILIO_Data Última Mensagens Outbound\"])\n",
    "\n",
    "    data_dataframe[\"TWILIO_Data Última Mensagens Outbound Tempo passado\"] = datetime.now() - data_dataframe[\"TWILIO_Data Última Mensagens Outbound\"]\n",
    "\n",
    "    data_dataframe[\"TWILIO_Data Última Mensagens Outbound Tempo passado\"].fillna('', inplace=True)\n",
    "    \n",
    "    data_dataframe[\"TWILIO_Data Última Mensagens Outbound Tempo passado\"] = data_dataframe[\"TWILIO_Data Última Mensagens Outbound Tempo passado\"].astype(str)\n",
    "\n",
    "    data_dataframe[\"TWILIO_Data Última Mensagens Outbound Tempo passado\"] = data_dataframe[\"TWILIO_Data Última Mensagens Outbound Tempo passado\"].str.extract('(\\d+) days').astype(float)\n",
    "\n",
    "    data_dataframe = data_dataframe.drop([\"TWILIO_Data Última Mensagens Outbound\"], axis=1)\n",
    "\n",
    "    data_dataframe[\"TWILIO_Data Última Mensagens Outbound Recente\"] = data_dataframe[\"TWILIO_Data Última Mensagens Outbound Tempo passado\"] < data_dataframe[\"TWILIO_Data Última Mensagens Outbound Tempo passado\"].median()\n",
    "    data_dataframe[\"TWILIO_Data Última Mensagens Outbound Recente\"].fillna(0)\n",
    "    data_dataframe[\"TWILIO_Data Última Mensagens Outbound Recente\"].replace(True, 1, inplace=True)\n",
    "    data_dataframe[\"TWILIO_Data Última Mensagens Outbound Recente\"].replace(False, 0, inplace=True)\n",
    "\n",
    "    data_dataframe = data_dataframe.drop([\"TWILIO_Data Última Mensagens Outbound Tempo passado\"], axis=1)\n",
    "\n",
    "    data_dataframe[\"TWILIO_Ligações Outbound\"].fillna(0, inplace=True)\n",
    "\n",
    "    data_dataframe[\"TWILIO_Data Última Ligações Outbound\"] = pd.to_datetime(data_dataframe[\"TWILIO_Data Última Ligações Outbound\"])\n",
    "\n",
    "    data_dataframe[\"TWILIO_Data Última Ligações Outbound Tempo passado\"] = datetime.now() - data_dataframe[\"TWILIO_Data Última Ligações Outbound\"]\n",
    "\n",
    "    data_dataframe[\"TWILIO_Data Última Ligações Outbound Tempo passado\"].fillna('', inplace=True)\n",
    "\n",
    "    data_dataframe[\"TWILIO_Data Última Ligações Outbound Tempo passado\"] = data_dataframe[\"TWILIO_Data Última Ligações Outbound Tempo passado\"].astype(str)\n",
    "\n",
    "    data_dataframe[\"TWILIO_Data Última Ligações Outbound Tempo passado\"] = data_dataframe[\"TWILIO_Data Última Ligações Outbound Tempo passado\"].str.extract('(\\d+) days').astype(float)\n",
    "\n",
    "    data_dataframe = data_dataframe.drop([\"TWILIO_Data Última Ligações Outbound\"], axis=1)\n",
    "\n",
    "    data_dataframe[\"TWILIO_Data Última Ligações Outbound Recente\"] = data_dataframe[\"TWILIO_Data Última Ligações Outbound Tempo passado\"] < data_dataframe[\"TWILIO_Data Última Ligações Outbound Tempo passado\"].median()\n",
    "    data_dataframe[\"TWILIO_Data Última Ligações Outbound Recente\"].fillna(0)\n",
    "    data_dataframe[\"TWILIO_Data Última Ligações Outbound Recente\"].replace(True, 1, inplace=True)\n",
    "    data_dataframe[\"TWILIO_Data Última Ligações Outbound Recente\"].replace(False, 0, inplace=True)\n",
    "\n",
    "    data_dataframe = data_dataframe.drop([\"TWILIO_Data Última Ligações Outbound Tempo passado\"], axis=1)\n",
    "\n",
    "    data_dataframe = data_dataframe.drop([\"COBRANÇA_VINDI_Qde Perfis de Pagamento Inativos\"], axis=1)\n",
    "\n",
    "    # preprocessing especials \n",
    "\n",
    "    data_dataframe = data_dataframe[data_dataframe['FUNIL_ASSINATURA_PIPEDRIVE_status'].isin(['won', 'lost'])]\n",
    "\n",
    "    data_dataframe = data_dataframe.drop(data_dataframe[(data_dataframe['FUNIL_ASSINATURA_PIPEDRIVE_status'] == 'won') & (~data_dataframe['PESSOA_PIPEDRIVE_contract_end_date'].isnull())].index)\n",
    "\n",
    "    data_dataframe = data_dataframe.drop(data_dataframe[(data_dataframe['FUNIL_ASSINATURA_PIPEDRIVE_status'] == 'lost') & (data_dataframe['PESSOA_PIPEDRIVE_contract_end_date'].isnull())].index)\n",
    "\n",
    "    #exportando df pronto\n",
    "\n",
    "    data_dataframe.to_csv('../notebooks/data/data-preprocessed.csv', index=False)\n",
    "\n",
    "    #     return data_dataframe\n",
    "    # except Exception:\n",
    "    #     print(\"DEU RUIM\")\n",
    "    #     return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../notebooks/data/Ana Health_Tabela Modelo Previsão Churn - Tabela.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COBRANÇA_VINDI_TWILIO_COMUNICARE_WHOQOL_ATENDIMENTOS_AGENDA_FUNIL_ONBOARDING_PIPEDRIVE_FUNIL_ASSINATURA_PIPEDRIVE_PESSOA_PIPEDRIVE_50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PESSOA, PIPEDRIVE</th>\n",
       "      <td>1022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unnamed: 1</th>\n",
       "      <td>1993-08-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unnamed: 4</th>\n",
       "      <td>Santa Catarina</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  COBRANÇA_VINDI_TWILIO_COMUNICARE_WHOQOL_ATENDIMENTOS_AGENDA_FUNIL_ONBOARDING_PIPEDRIVE_FUNIL_ASSINATURA_PIPEDRIVE_PESSOA_PIPEDRIVE_50\n",
       "PESSOA, PIPEDRIVE                                               1022                                                                                   \n",
       "Unnamed: 1                                                1993-08-03                                                                                   \n",
       "Unnamed: 2                                                        64                                                                                   \n",
       "Unnamed: 3                                                        80                                                                                   \n",
       "Unnamed: 4                                            Santa Catarina                                                                                   "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_merge.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['PESSOA_PIPEDRIVE_id_person_recommendation', 'PESSOA_PIPEDRIVE_Recebe Comunicados?', 'PESSOA_PIPEDRIVE_Interesses', 'PESSOA_PIPEDRIVE_Pontos de Atenção', 'FUNIL_ONBOARDING_PIPEDRIVE_id_label'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/Users/st4pzz/Desktop/insper_2023.2/SPRINT/sprint4-support-vector-team/src/scripts/teste.ipynb Célula 12\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/st4pzz/Desktop/insper_2023.2/SPRINT/sprint4-support-vector-team/src/scripts/teste.ipynb#X12sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m preprocessing(data)\n",
      "\u001b[1;32m/Users/st4pzz/Desktop/insper_2023.2/SPRINT/sprint4-support-vector-team/src/scripts/teste.ipynb Célula 12\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/st4pzz/Desktop/insper_2023.2/SPRINT/sprint4-support-vector-team/src/scripts/teste.ipynb#X12sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m data_dataframe \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(data_dataframe\u001b[39m.\u001b[39miloc[\u001b[39m50\u001b[39m])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/st4pzz/Desktop/insper_2023.2/SPRINT/sprint4-support-vector-team/src/scripts/teste.ipynb#X12sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m \u001b[39m# preprocessing 1\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/st4pzz/Desktop/insper_2023.2/SPRINT/sprint4-support-vector-team/src/scripts/teste.ipynb#X12sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m data_dataframe \u001b[39m=\u001b[39m data_dataframe\u001b[39m.\u001b[39;49mdrop([\u001b[39m\"\u001b[39;49m\u001b[39mPESSOA_PIPEDRIVE_id_person_recommendation\u001b[39;49m\u001b[39m\"\u001b[39;49m,\u001b[39m\"\u001b[39;49m\u001b[39mPESSOA_PIPEDRIVE_Recebe Comunicados?\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mPESSOA_PIPEDRIVE_Interesses\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mPESSOA_PIPEDRIVE_Pontos de Atenção\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mFUNIL_ONBOARDING_PIPEDRIVE_id_label\u001b[39;49m\u001b[39m\"\u001b[39;49m], axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/st4pzz/Desktop/insper_2023.2/SPRINT/sprint4-support-vector-team/src/scripts/teste.ipynb#X12sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m data_dataframe[\u001b[39m'\u001b[39m\u001b[39mPESSOA_PIPEDRIVE_birthdate\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mto_datetime(data_dataframe[\u001b[39m'\u001b[39m\u001b[39mPESSOA_PIPEDRIVE_birthdate\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/st4pzz/Desktop/insper_2023.2/SPRINT/sprint4-support-vector-team/src/scripts/teste.ipynb#X12sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m data_dataframe[\u001b[39m'\u001b[39m\u001b[39mPESSOA_PIPEDRIVE_age\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m data_dataframe[\u001b[39m'\u001b[39m\u001b[39mPESSOA_PIPEDRIVE_birthdate\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mapply(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/st4pzz/Desktop/insper_2023.2/SPRINT/sprint4-support-vector-team/src/scripts/teste.ipynb#X12sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m     \u001b[39mlambda\u001b[39;00m x: datetime\u001b[39m.\u001b[39mtoday()\u001b[39m.\u001b[39myear \u001b[39m-\u001b[39m x\u001b[39m.\u001b[39myear \u001b[39m-\u001b[39m ((datetime\u001b[39m.\u001b[39mtoday()\u001b[39m.\u001b[39mmonth, datetime\u001b[39m.\u001b[39mtoday()\u001b[39m.\u001b[39mday) \u001b[39m<\u001b[39m (x\u001b[39m.\u001b[39mmonth, x\u001b[39m.\u001b[39mday))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/st4pzz/Desktop/insper_2023.2/SPRINT/sprint4-support-vector-team/src/scripts/teste.ipynb#X12sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m )\n",
      "File \u001b[0;32m~/Desktop/insper_2023.2/SPRINT/sprint4-support-vector-team/env/lib/python3.9/site-packages/pandas/core/frame.py:5344\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   5196\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdrop\u001b[39m(\n\u001b[1;32m   5197\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   5198\u001b[0m     labels: IndexLabel \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5205\u001b[0m     errors: IgnoreRaise \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mraise\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   5206\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   5207\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   5208\u001b[0m \u001b[39m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[1;32m   5209\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5342\u001b[0m \u001b[39m            weight  1.0     0.8\u001b[39;00m\n\u001b[1;32m   5343\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 5344\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mdrop(\n\u001b[1;32m   5345\u001b[0m         labels\u001b[39m=\u001b[39;49mlabels,\n\u001b[1;32m   5346\u001b[0m         axis\u001b[39m=\u001b[39;49maxis,\n\u001b[1;32m   5347\u001b[0m         index\u001b[39m=\u001b[39;49mindex,\n\u001b[1;32m   5348\u001b[0m         columns\u001b[39m=\u001b[39;49mcolumns,\n\u001b[1;32m   5349\u001b[0m         level\u001b[39m=\u001b[39;49mlevel,\n\u001b[1;32m   5350\u001b[0m         inplace\u001b[39m=\u001b[39;49minplace,\n\u001b[1;32m   5351\u001b[0m         errors\u001b[39m=\u001b[39;49merrors,\n\u001b[1;32m   5352\u001b[0m     )\n",
      "File \u001b[0;32m~/Desktop/insper_2023.2/SPRINT/sprint4-support-vector-team/env/lib/python3.9/site-packages/pandas/core/generic.py:4711\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4709\u001b[0m \u001b[39mfor\u001b[39;00m axis, labels \u001b[39min\u001b[39;00m axes\u001b[39m.\u001b[39mitems():\n\u001b[1;32m   4710\u001b[0m     \u001b[39mif\u001b[39;00m labels \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 4711\u001b[0m         obj \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39;49m_drop_axis(labels, axis, level\u001b[39m=\u001b[39;49mlevel, errors\u001b[39m=\u001b[39;49merrors)\n\u001b[1;32m   4713\u001b[0m \u001b[39mif\u001b[39;00m inplace:\n\u001b[1;32m   4714\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[0;32m~/Desktop/insper_2023.2/SPRINT/sprint4-support-vector-team/env/lib/python3.9/site-packages/pandas/core/generic.py:4753\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[0;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[1;32m   4751\u001b[0m         new_axis \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39mdrop(labels, level\u001b[39m=\u001b[39mlevel, errors\u001b[39m=\u001b[39merrors)\n\u001b[1;32m   4752\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 4753\u001b[0m         new_axis \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39;49mdrop(labels, errors\u001b[39m=\u001b[39;49merrors)\n\u001b[1;32m   4754\u001b[0m     indexer \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39mget_indexer(new_axis)\n\u001b[1;32m   4756\u001b[0m \u001b[39m# Case for non-unique axis\u001b[39;00m\n\u001b[1;32m   4757\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/Desktop/insper_2023.2/SPRINT/sprint4-support-vector-team/env/lib/python3.9/site-packages/pandas/core/indexes/base.py:6992\u001b[0m, in \u001b[0;36mIndex.drop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   6990\u001b[0m \u001b[39mif\u001b[39;00m mask\u001b[39m.\u001b[39many():\n\u001b[1;32m   6991\u001b[0m     \u001b[39mif\u001b[39;00m errors \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m-> 6992\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mlabels[mask]\u001b[39m.\u001b[39mtolist()\u001b[39m}\u001b[39;00m\u001b[39m not found in axis\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   6993\u001b[0m     indexer \u001b[39m=\u001b[39m indexer[\u001b[39m~\u001b[39mmask]\n\u001b[1;32m   6994\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdelete(indexer)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['PESSOA_PIPEDRIVE_id_person_recommendation', 'PESSOA_PIPEDRIVE_Recebe Comunicados?', 'PESSOA_PIPEDRIVE_Interesses', 'PESSOA_PIPEDRIVE_Pontos de Atenção', 'FUNIL_ONBOARDING_PIPEDRIVE_id_label'] not found in axis\""
     ]
    }
   ],
   "source": [
    "preprocessing(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
